1、缘由

    起因：

        单表
            数据量过大   ==>   SQL执行变慢（读写）     // 内存限制  ==>  buffer_pool 不够用  ->  无法存储 所有热点索引  ==>  频繁 淘汰/加载 索引   ->   频繁IO

        单库
            并发量低     ==>   单库 2000 QPS         // 单机 - MySQL实例


    解决方案：
        拆分  ->  分表  /  分库 + 分表


    目的：
        分表  ==>  大数据表  拆分为  N张小数据表    ->  解决   单表数据量大  ->  SQL执行慢的问题

        分库  ==>  部署到多台机器上                ->  解决   单库(单机) 并发量低


    示例：

        单表10亿

            经过分表后  ->  order_1、order_2、... order_1024      ->  单表100W    // hash(user_id)  均匀分布

                      ->  order_2019、order_2020、order_2021     ->  历史归档    // 按年划分

        这些表

            可以在      一个库      ->  只分表

            也可以分散到 多个库      ->  分库 + 分表


    本质上：

        手动分库分表  ->  手动构建 分布式DB      // 去中心化  ->   高扩展  ==>  扩容 ->  分担流量(并发)  +  分担存储(降低 单表数据量)


2、分表

    健康单表    ->    百万级
    单表最大    ->    千万级

    单表超过 千万级     ==>     分表        // 1个表  ->  1/N个 B+树      ==>  数据量过大  ->  B+树层级过高  ->  时间复杂度 上升


    ------------------------------------------------------------
    应用：

        order表  ->  order_1 、 order_2    ...   order_1024             // hash拆分   ->  hash(user_id)

        order表  ->  order_2019 、 order_2020 、 order_2021 ...         // 按年拆分



3、分库

    健康单库    ->    1000 QPS
    单库最大    ->    2000 QPS

    单库超过 2000QPS     ==>     分库             // 1个库   ->   1个 MySQL实例      ->  1台 物理主机
                                                -------------------------------------------------------------------------------------------
                                                分出的库  放一个MySQL实例(主机)中   ->   分了等于没分    ==>   主机的 内存、IO等硬件能力 并没有变大

                                                我们拆分  ==>  就是为了用多台机器  来分担单机压力     ->   你全放到一个机器 有毛用啊


    -------------------------------------------------
    应用：

        biz库  ->  biz_1、biz_2   ...   biz_10                  // hash拆分   ->  hash(user_id)

        biz库  ->  biz_2019、biz_2020、biz_2021  ...            // 按年拆分




4、分库分表

    分库分表            // 分布式DB + 集群

        分表  ->   分区存储        =>   类似单体应用拆分   ->   去中心化                     ->   提供了 高扩展性

        分库  ->   多实例部署      =>   类似集群扩容       ->   分担流量压力（路由 分发负载）   ->  提供了 高并发度



    优势

        1、并发支撑情况	    单机部署，扛不住高并发	                多机部署，提高并发度

        2、磁盘使用情况	    单机磁盘容量几乎撑满	                拆分为多库，DB磁盘 使用率大大降低

        3、SQL 执行性能	    单表数据量太大，SQL 越跑越慢	        单表数据量减少，SQL读写效率 明显提升



5、水平拆分              // 分表 + 分库

    1个库的表     ->      分散到 N个库                 // 1000W条数据   =>  横向切9刀  ->  分成10段  =>  分区存储到 10个库


    作用：

        1、存储更多数据

        2、提高并发度

        ----------------------------------------------------------------
        将数据分区存储 ->  均匀分布到多个库  =>  利用多个库 -> 抗住更高的并发

        分区存储（多个库）  ->   提高存储容量



6、垂直拆分             // 按业务建表        ==>     多字段 拆 N个表    ->   订单表、订单支付表、订单商品表


    1个多字段表     ->      N个表                     // 单表 100个字段    =>  垂直切3刀  ->  分成4段   =>  拆分为 4张小字段表


    应用：
        业务层面拆分      ->     字段拆分             // 多字段大表 拆小表   ->   订单表、订单支付表、订单商品表



7、中间件

    作用：
        按规则  ->  路由    ==>  找到 对应的库 + 对应的表                 // user_id / order_id / ...


    中间件：
        Cobar
        TDDL
        Atlas
        Sharding-jdbc
        Mycat




8、拆分规则

    1、hash

        按照某个字段 hash一下 均匀分散            // 较为常用   ->   数据均匀分布  +  流量均匀分布

        优点：
            平均分配每个库的 数据量和请求压力

        劣势：
            扩容麻烦  ->  重新hash   ->  数据迁移        // 类似 HashMap


    2、range

        每个库一段连续的数据   一般是按时间范围      // 一般较少用  ->  因为很容易产生热点问题，大量的流量都打在最新的数据上了     且每个库分布不均


        优势：
            扩容方便   ->   每个月准备一个库

        劣势：
            1、无法分担 并发压力  ->  大部分的请求，都是访问最新的数据（集中在最新库表）

            2、数据分布 也不均匀  ->  随每个月的流量而波动

