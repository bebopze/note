1、缘由

    起因：

        单表
            数据量过大   ==>   SQL执行变慢（读写）     // 内存限制  ==>  buffer_pool 不够用  ->  无法存储 所有热点索引  ==>  频繁 淘汰/加载 索引   ->   频繁IO

        单库
            并发量低     ==>   单库 2000 QPS         // 单机 - MySQL实例


    解决方案：
        拆分  ->  分表  /  分库 + 分表


    目的：
        分表  ==>  大数据表  拆分为  N张小数据表    ->  解决   单表数据量大  ->  SQL执行慢的问题

        分库  ==>  部署到多台机器上                ->  解决   单库(单机) 并发量低       // 前期先  逻辑分库  ->  放在同一实例上

                                                                                   //   ==>  数据量到一定规模后 ->  再将每个库 部署到不同物理主机上



    示例：

        单表10亿

            经过分表后  ->  order_1、order_2、... order_1024      ->  单表100W    // hash(user_id)  均匀分布

                      ->  order_2019、order_2020、order_2021     ->  历史归档    // 按年划分

        这些表

            可以在      一个库      ->  只分表

            也可以分散到 多个库      ->  分库 + 分表


    本质上：

        手动分库分表  ->  手动构建 分布式DB      // 去中心化  ->   高扩展  ==>  扩容 ->  分担流量(并发)  +  分担存储(降低 单表数据量)


2、分表

    健康单表    ->    百万级
    单表最大    ->    千万级

    单表超过 千万级     ==>     分表        // 1个表  ->  1/N个 B+树      ==>  数据量过大  ->  B+树层级过高  ->  时间复杂度 上升


    ------------------------------------------------------------
    应用：

        order表  ->  order_1 、 order_2    ...   order_1024             // hash拆分   ->  hash(user_id)

        order表  ->  order_2019 、 order_2020 、 order_2021 ...         // 按年拆分



3、分库

    健康单库    ->    1000 QPS
    单库最大    ->    2000 QPS

    单库超过 2000QPS     ==>     分库             // 1个库   ->   1个 MySQL实例      ->  1台 物理主机
                                                -------------------------------------------------------------------------------------------
                                                分出的库  放一个MySQL实例(主机)中   ->   分了等于没分    ==>   主机的 内存、IO等硬件能力 并没有变大

                                                我们拆分  ==>  就是为了用多台机器  来分担单机压力     ->   你全放到一个机器 有毛用啊


    -------------------------------------------------
    应用：

        biz库  ->  biz_1、biz_2   ...   biz_10                  // hash拆分   ->  hash(user_id)

        biz库  ->  biz_2019、biz_2020、biz_2021  ...            // 按年拆分




4、分库分表

    分库分表            // 分布式DB + 集群

        分表  ->   分区存储        =>   类似单体应用拆分   ->   去中心化                     ->   提供了 高扩展性

        分库  ->   多实例部署      =>   类似集群扩容       ->   分担流量压力（路由 分发负载）   ->  提供了 高并发度



    优势

        1、并发支撑情况	    单机部署，扛不住高并发	                多机部署，提高并发度

        2、磁盘使用情况	    单机磁盘容量几乎撑满	                拆分为多库，DB磁盘 使用率大大降低

        3、SQL 执行性能	    单表数据量太大，SQL 越跑越慢	        单表数据量减少，SQL读写效率 明显提升



5、水平拆分              // 分表 + 分库

    1个库的表     ->      分散到 N个库                 // 1000W条数据   =>  横向切9刀  ->  分成10段  =>  分区存储到 10个库


    作用：

        1、存储更多数据

        2、提高并发度

        ----------------------------------------------------------------
        将数据分区存储 ->  均匀分布到多个库  =>  利用多个库 -> 抗住更高的并发

        分区存储（多个库）  ->   提高存储容量



6、垂直拆分             // 按业务建表        ==>     多字段 拆 N个表    ->   订单表、订单支付表、订单商品表


    1个多字段表     ->      N个表                     // 单表 100个字段    =>  垂直切3刀  ->  分成4段   =>  拆分为 4张小字段表


    应用：
        业务层面拆分      ->     字段拆分             // 多字段大表 拆小表   ->   订单表、订单支付表、订单商品表



7、中间件

    作用：
        按规则  ->  路由    ==>  找到 对应的库 + 对应的表                 // user_id / order_id / ...


    中间件：
        Cobar
        TDDL
        Atlas
        Sharding-jdbc
        Mycat




8、拆分规则

    1、hash

        按照某个字段 hash一下 均匀分散            // 较为常用   ->   数据均匀分布  +  流量均匀分布

        优点：
            平均分配每个库的 数据量和请求压力

        劣势：
            扩容麻烦  ->  重新hash   ->  数据迁移        // 类似 HashMap


    2、range

        每个库一段连续的数据   一般是按时间范围      // 一般较少用  ->  因为很容易产生热点问题，大量的流量都打在最新的数据上了     且每个库分布不均


        优势：
            扩容方便   ->   每个月准备一个库

        劣势：
            1、无法分担 并发压力  ->  大部分的请求，都是访问最新的数据（集中在最新库表）

            2、数据分布 也不均匀  ->  随每个月的流量而波动




8、平滑过渡

    1、停机迁移

    2、双写

        1、同时写两个库   ->   老库  +  新库

        2、导数据

            读老库 ->  写入新库        // 需要 业务处理   ->  如：更新时间 判断   ->  写入/忽略/更新

        3、数据校验

            一般随机抽查  ->  check



9、动态扩缩容

    1、设定好几台数据库服务器，每台服务器上几个库，每个库多少个表

        推荐是 32 库 * 32 表，对于大部分公司来说，可能几年都够了

    2、路由的规则

        库   ->   orderId % 32

        表   ->   orderId / 32 % 32


    3、扩容的时候

        申请增加更多的数据库服务器，装好MySQL

        呈倍数扩容  ==>  4台服务器  ->  扩到8台  ->  再到16台


    4、由 DBA 负责将原先数据库服务器的库，迁移到新的数据库服务器上去

        库迁移是有一些便捷的工具的

    5、我们这边就是修改一下配置

        调整迁移的库所在数据库服务器的地址

    6、重新发布系统 上线

        原先的路由规则变都不用变，直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务


10、ID主键

    保证分库分表后ID的全局唯一性

        1、Snowflake算法

            0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000        // 64位 机器

             1bit   未使用

            41bit   毫秒级时间(41位的长度可以使用69年)

            5bit    datacenterId（机房ID）        // 最大只能是 32 以内      2^5 = 32

            5bit    workerId（机器ID）            // 2^5 = 32     ==>   机房ID + 机器ID  -> 10位 可替换为自定义逻辑   -> 2^10 = 1024个节点

            12bit   1个毫秒内的计数                // 12位的递增序号 支持每个节点每毫秒产生4096个ID序号            ->      2^12 = 4096



        2、美团Leaf（分布式ID生成系统）             // QPS近5万

        3、微信序列号生成器                        // QPS1000万以上

        4、百度开源的UidGenerator                 // （仅支持单机部署）使用Snowflake算法，单机QPS可达600万



    UUID的问题：

        1、生成的ID 最好具有单调递增性，也就是有序的     // 在系统设计时，ID 有可能成为排序的字段

        2、ID 有序也会提升数据的写入性能               // B+树 是有序的    ==>   有序 ->  顺序写

        3、它不具备业务含义                           // ID按自定义规则   ==>   生成时间、哪个机房的发号器、哪个业务服务...

        4、32位 字符串  ->  耗费空间


        场景：
            生成 Request ID 来标记单次请求           // 不依赖于任何第三方系统，所以在性能和可用性上都比较好




11、MySQL 的读写分离

    基于 主从复制架构   ==>   一个主库，挂多个从库   ->  只写主库，主库自动把数据同步到从库


    主从复制                            // binlog 同步

        1、主库将变更写入 binlog 日志

        2、从库连接到主库之后，从库有一个 IO 线程，将主库的 binlog 日志拷贝到自己本地，写入一个 relay 中继日志中

        3、接着从库中有一个 SQL线程 会从中继日志读取 binlog，然后执行 binlog 日志中的内容

            即：在从库执行一遍 相同SQL


    数据丢失
        只要数据写入了binlog（就算主库宕机）  ->  从库就可以完成同步

    主从延迟

        半同步复制  ->   写入主库  +  数据同步ack      // 写入主库时  +  强制同步 -> 成功 - 返回ack  ==>  才认可写入OK          - 只需1个从库同步成功ack 就认为OK

        并行复制   ->   从库开启多个线程，并行读取 relay log 中不同库的日志，然后并行重放不同库的日志，这是库级别的并行



    主从同步延时 解决方案：

        1、分库  ->  将一个主库拆分为多个主库

            每个主库的写并发就减少了几倍，此时主从延迟可以忽略不计


        2、打开 MySQL 支持的并行复制，多个库并行复制

            如果说某个库的写入并发就是特别高，单库写并发达到了 2000/s，并行复制还是没意义


        3、重写代码

            写代码的同学，要慎重，插入数据时立马查询可能查不到


        4、如果确实是存在 必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作

            对这个查询设置  直连主库           // 不推荐这种方法，你要是这么搞，读写分离的意义就丧失了


