1、为什么使用消息队列？

    场景有很多

    比较核心的有 3个：

        解耦                      // Pub/Sub 发布订阅

            BCD系统 都需要 A系统的 一份关键数据    ==>    丢到MQ   谁要谁自己去取   ->    再来几个EFG  也不用改动


        异步                      // 数据同步

            A接收一个请求 本地写数据(3ms)   ->   同时需要在 BCD系统也写入(300/400/500ms)   ->   （同步）慢   ==>   丢到 MQ  ->  BCD 异步写入



        削峰                      // 业务高峰期

            业务短暂搞活动   ->  请求数量突然暴增  ==>   丢到MQ    ->   异步处理     ==>    结果 ->  异步通知/站内信/客户端刷新拉取


2、消息队列有什么优点和缺点？

    优点：
        解耦、异步、削峰

    缺点：                         // 引入一个东西 ->  来解决一个问题的同时  ==>  会带来10个新的问题

        系统可用性降低        ->  MQ挂了

        复杂性               ->  MQ的维护、消息发送问题（超时、失败、重试、重复）、消费问题（失败、顺序、幂等）...

        一致性               ->  数据同步延迟、ABC成功 -> C失败





3、Kafka、ActiveMQ、RabbitMQ、RocketMQ 都有什么区别，以及适合哪些场景？

    ActiveMQ        万级                              ms级            主从架构      低概率丢失     Java       功能完备

    RabbitMQ        万级                              μs级（最快）    主从架构      基本不丢       erlang     高并发，低延时

    Kafka           10万级      topic几十/几百级      ms级           分布式架构      0丢失         Java       简单的MQ功能        大数据-实时计算/日志采集

    RocketMQ        10万级      topic几百/几千级      ms级           分布式架构      0丢失         Java       MQ功能较为完善      分布式，扩展性好




4、如何保证消息队列的高可用？

    RabbitMQ                            // 传统 消息队列      ==>    一个queue  ->  完整data

        单机

        普通集群模式（无高可用性）       ==>      数据单点存储     ->      A需要用到时，到B上 主动拉取   ->  B挂了，数据就丢了

        镜像集群模式（高可用性）         ==>      消息同步         ->      每个实例都有一份


        缺点：
            消息需要同步到所有机器     ->      带宽压力、性能开销
            非分布式                  ->      无扩展性            // 无法针对queue_1、queue_2 分别扩展  ->  每个机器 都包含所有queue的完整数据


    Kafka                               // 分布式 消息队列   ==>   分多个broker存储  =>   一个broker -> 存储部分data


        天然的分布式消息队列      ==>     一个 topic 的数据，是分散放在多个机器上的，每个机器只放一部分数据


        topic  ==>  分区存储（去中心化）  ->   topic data1/partition1/broker1   topic data2/partition2/broker2    topic data3/partition3/broker3



        高可用             // 0.8+版本

            broker（leader - follower）


        写数据

            写leader  ->  follower主动pull数据   =>  follower同步ok  ->  返回leader ack确认  ==>  所有follower ok - ack  ->  leader返回生产者ok

        消费
            读leader     ==>     所有follower都同步ok   ->  返回ack   =>  才会被读到



        优点：

            分布式     ->      可针对 指定partition-broker 扩展



5、如何保证消息不被重复消费？或者说，如何保证消息消费的幂等性？                    // 不能多

    业务端保证：

        zk         create znode     +   check

        redis      SET NX           +   check


        唯一约束

        乐观锁


    --------------------------------------------------------------------------------
    kafka的重复消费缘由：

        offset机制            // msg序号     ==>   每个消息 都有一个offset（序号）                    // __consumer_offsets

            消费后  ->  提交 已消费过的 消息offset(序号)    ->   已消费标记


        异常重启（断电/kill）

            部分已消费的offset  ->  未来得及提交  ->  重复消费




6、如何保证消息的可靠性传输？或者说，如何处理消息丢失的问题？                       // 不能少


    RabbitMQ：

        1、生产者   ==>   事务机制（同步）  /   confirm机制（异步）

            ------------------------------------------------------------------------------------
            1、事务机制                  // 同步  ->  阻塞

                生产者 开启事务  ->  发送消息   ->  发送成功（MQ返回ok）  ->  提交事务
                                             ->  发送失败（异常）      ->  回滚事务      ==>  重新发送

                缺点  ==>   太耗性能  ->  吞吐量下降

            ------------------------------------------------------------------------------------
            2、confirm机制            // 异步  ->  非阻塞

                分配唯一id  ->  写入MQ成功  ->  返回ack         （异步回调通知）
                           ->  写入MQ失败  ->  异步回调nack接口 （通知失败）


        2、MQ   ==>   开启 RabbitMQ持久化     =>    异常  ->  丢失少量数据

            ------------------------------------------------------------------------------------
            100% 不丢失：
                confirm机制  +  RabbitMQ持久化    ==>   写入MQ成功 + MQ刷盘成功   ->  返回ack


        3、消费者  ==>   关闭自动ack         ->    消费成功  +  手动ack




    kafka：

        生产者

            acks=all        ==>      leader数据 同步到 所有follower   ->  写入OK

            retries=MAX     ==>      一旦写入失败，就无限重试               // MAX  =>  给定一个很大的值，如1000  ->  无限重试的意思


        MQ
            故障：
                leader 数据同步 follower 之前挂了   ==>   新选举的leader 数据丢失

            排除：
                1、每个leader 必须有 至少2个follower                                 topic -> replication.factor>=2

                2、leader 至少感知到 有一个follower 还跟自己保持联系                   min.insync.replicas>=2


        消费者   ==>   关闭自动提交offset     ->   消费成功  +  手动提交offset



7、如何保证消息的顺序性？


    场景：
        MySQL -> MySQL          // sql执行顺序不能反


    错乱的原因：

        1、未按规则路由           ->      同一 queue-consumer / partition-consumer

        2、同一consumer内部      ->      多线程消费


    保证顺序消费：

        1、按规则路由            ->      同一 queue-consumer / partition-consumer

        2、同一consumer内部      ->      单线程消费    /  多（内存队列 - worker线程）


        3、最低效：
            单一      queue - consumer        // RabbitMQ
            单一  partition - consumer        // kafka


    --------------------------------------------------------------------------------------------------------------------
    RabbitMQ

        1、1个queue  ->  多个consumer

            consumer从MQ里面读取数据是有序的，但是每个consumer的执行时间是不固定的

            无法保证先读到消息的consumer一定先完成操作


        2、1个queue  ->  1个consumer

            consumer内部  ->  多线程消费

        -------------------------------------------------

        1、拆分多个queue   ==>   1个queue  ->  1个consumer

            单线程消费   ->  吞吐量下降


            间接 多线程消费                // 在消费者内部采用   ==>  多个（内存队列  ->  worker线程）

                1、创建多个内存队列          ->   每个队列 对应 一个worker线程

                2、按规则（order_id）       ->   将同一订单的(有序)消息   ->  路由至 同一内存队列

                3、每个内存队列内 消息有序   ->   对应单一worker线程 有序消费


        2、1个queue  ->  1个consumer

            在消费者内部采用   ==>  多个（内存队列  ->  线程）


    kafka

        1、一个topic  ->  多个（partition  ->  consumer）

            consumer内部  ->  多线程消费

        2、一个topic  ->  多个（partition  ->  consumer）

            不同的消费者去消费，但是每个consumer的执行时间是不固定的

            无法保证先读到消息的consumer一定先完成操作

        -------------------------------------------------

        1、一个topic  ->  多个（partition  ->  consumer）

            内部单线程消费


        2、一个topic  ->  多个（partition  ->  consumer）

            在消费者内部采用   ==>  多个（内存队列  ->  线程）




8、如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？

    过期

        RabbitMQ支持TTL   ==>  数据积压  ->    数据会直接搞丢

        数据重导  ==>   高峰期过了（晚上）   ->  丢失的数据查出来  ->    发送到MQ


    MQ写满                // 基本没救

        1、全部丢弃        // 临时程序 -> 消费一个丢弃一个，都不要了

        2、晚上再补        // 数据重导


    consumer异常   ->  数据积压

        1、修复consumer  ->  慢慢消费

        2、临时紧急扩容

            1、修复原consumer，并停掉全部consumer

            2、新建一个topic，并为其扩容原先10倍的 partition - consumer    // 相当于扩容10倍

            3、写一个临时的consumer分发程序    ->     消费积压的数据    ->    不做消费处理，直接丢到新的topic

            4、快速消费完成之后，恢复原先架构



9、如果让你写一个消息队列，该如何进行架构设计？说一下你的思路

    扩展性：
        分布式          ->     kafka      ->       partition - 扩展

    高可用：
        主从(多副本)     ->    kafka       ->      leader-follower  -  选举leader

    持久化：
        异步刷盘         ->    kafka       ->      批量提交 - 顺序写

    数据0丢失：

        生产者     ->      acks=all   +   retries=MAX

        MQ        ->      leader - follower

        消费者     ->      关闭自动提交offset   =>   消费完成  ->  手动提交offset





------------------------------------------------------------------------------------------------------------------------
PTP（点对点）、pub/sub（一对多）                                    - http://www.tianshouzhi.com/api/tutorials/rocketmq/407





------------------------------------------------------------------------------------------------------------------------
                                                                    - https://www.cnblogs.com/winkey4986/p/6836824.html

Pub/Sub、PTP 对比


 	                topic	                                                        Queue

概要	                Pub-Sub(发布/订阅)	                                        PTP(点对点)

有无状态	            topic数据默认是无状态的              	                        Queue数据是要实际介质保存的,如保存到数据库

完整性保障	        并不保证publisher发布的每条数据，Subscriber都能接受到	        Queue保证每条数据都能被receiver接收

消息是否会丢失	    一般来说publisher发布消息到某一个topic时                       Sender发送消息到目标Queue，receiver可以异步接收这个Queue上的消息
                    只有正在监听该topic地址的sub能够接收到消息                      Queue上的消息如果暂时没有receiver来取，也不会丢失
                    如果没有sub在监听，该topic就丢失了

消息发布接收策略	    一对多的消息发布接收策略                                        一对一的消息发布接收策略，一个sender发送的消息，只能有一个receiver接收
                    监听同一个topic地址的多个sub都能收到publisher发送的消息          receiver接收完后，通知服务器已接收，服务器对queue里的消息采取删除或其他操作
                    Sub接收完通知服务器.





========================================================================================================================
kafka消息 存储机制      ->    log文件形式存储（磁盘存储）                             ->      不是内存存储
========================================================================================================================

1、消息写入性能优化：

    1、顺序写

        kafka 采用顺序写  的方式存储数据

    2、零拷贝


        1、完全拷贝：

            OS：     磁盘   ->   内核-页缓存（read buffer）

            APP：    内核-页缓存（read buffer）   ->     用户空间     ->   内核-socket缓冲区

            OS：     内核socket缓冲区   ->   网卡缓冲区


            ===>   拷贝来、拷贝去   ->   数据完全发生改变



        2、sendfile

            内核-页缓存（read buffer）   ->   内核-socket缓冲区

            ------------------------------------------------------------------------------------------------------------
            现代的 unix 操作系统提供一个  优化的代码路径

               ===>   用于将数据从     内核-页缓存  --传输到-->  内核-socket缓冲区

            ------------------------------------------------------------------------------------------------------------
            linux   ->   sendfile       // Java   ->   FileChannel.transferTo

                使用 sendfile，只需要一次拷贝就行，允许操作系统将数据直接从页缓存发送到网络上
                在这个优化的路径中，只有最后一步将数据拷贝到网卡缓存中是需要的


2、日志的清除策略

    1、过期时间

        根据消息的保留时间，当消息在 kafka 中保存的时间超过了指定的时间，就会触发清理过程

    2、文件大小

        根据 topic 存储的数据大小，当 topic 所占的日志文件大小大于一定的阀值，则可以开始删除最旧的消息

        --------------------------------------------------------------------------------------------------------
        通过 log.retention.bytes 和 log.retention.hours 这两个参数来设置，当其中任意一个达到要求，都会执行删除

            默认的保留时间是：7 天

            kafka会启动一个后台线程，定期检查是否存在可以删除的消息


3、日志压缩策略

    通过这个功能可以有效的减少日志文件的大小，缓解磁盘紧张的情况


    在很多实际场景中：

        消息的 key 和 value 的值之间的对应关系是不断变化的，就像数据库中的数据会不断被修改一样

        消费者只关心 key 对应的最新的 value


    我们可以开启 kafka 的日志压缩功能：

        服务端会在后台启动Cleaner线程池，定期将相同的key进行合并，只保留最新的 value 值

