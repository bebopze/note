========================================================================================================================
1、SQL执行过程
========================================================================================================================

    客户端     ->      Server端
                                   ↗   查缓存（MySQL8 已废弃）

    ->  连接器（管理连接，权限验证）  ->  分析器（词法分析，语法分析）  ->  优化器（执行计划生成，索引选择） ->  执行器（操作引擎，返回结果）

    ->  存储引擎（存储数据，提供读写接口）



    MySQL：

        1、Server层                                   // 不同的存储引擎共用一个 Server 层，也就是 从连接器到执行器 的部分

            连接器、查询缓存、分析器、优化器、执行器等

            涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等）

            所有 跨存储引擎的功能 都在这一层实现，比如 存储过程、触发器、视图 等


        2、存储引擎层                                  // 存、取     插件式

            负责 数据的存储和提取

            其架构模式是 插件式 的，支持 InnoDB、MyISAM、Memory 等多个存储引擎

            最常用的存储引擎是 InnoDB



========================================================================================================================
2、日志                        // CRUD 记录
========================================================================================================================

    1、redo log              // 引擎层 日志、InnoDB 引擎特有的日志、crash-safe、事务

        作用：
            crash-safe、事务


        目的：         // 提高写入性能   ->  通过  crash-safe、事务  保证数据完整性

            每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高

                // 写入磁盘的操作 成本过高：   ->  写入 log file  ->  就直接返回 insert/update/delete 成功    ->  后台再从 log file  --同步至-->  磁盘

                    // 所有我们先写入 一个日志file，做个缓冲        // 类似 log4j日志

                    // 读取 log  ->  解析 log  ->  写入磁盘

                    // 再从log file中，更新到磁盘（ 因为直接写入磁盘，需要经过 IO、查询、更新、维护索引...  --->  成本较高  ->  时间较慢  -->  系统效率慢 ）


        优化：

            先写日志，再写磁盘       // 也就是先写粉板，等不忙的时候再写账本

                InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了

                同时，InnoDB 引擎会在适当（空闲）的时候，将这个操作记录更新到磁盘里面


        日志 存储：  // 本质就是一个  循环队列

            本质就是一个  循环队列
            --------------------------------------
            日志存储空间有限，记满了    ->  停下来（阻塞），批量处理一批  ->  写入磁盘  ->  清除已处理日志，腾出空间


        理解：

            类比 掌柜记账

                黑板记账(日志，写入内存)    ->  打烊后（系统空闲）核算，记入账本（写入磁盘）

            -----------------------------
            黑板写满了   ->  停下来，先核算一批，写入账本  ->  擦除 -> 重新黑板记账



        crash-safe：                 // redo log 记录在 file，也是一种物理存储   并不是在内存中   ->   只要记录在了粉板上，就具备 crash-safe 的能力了

            只要写入了 log file，就已经持久化到 file 文件中了

            log file 类似 log4j 的日志文件，也是 持久化存储在 物理磁盘 上

            就算 数据库异常崩溃，log file 依然存在

            重启后，继续 读取、解析log，再持久化到磁盘



        实现：

            "循环队列"   ->  本质上是一个 循环file

            checkpoint  ->  游标



    2、binlog            // Server层 日志   ->  所有引擎 公有     、  归档

        归档日志    ->  数据恢复




------------------------------------------------------------------------------------------------------------------------
redo log、binlog 区别：         // 都是log file   ->  类似 log4j 业务日志   ->   均存储在 物理磁盘

    redo log    ->  引擎层   日志       InnoDB 独有        固定大小   循环写入(覆盖)       ->  crash-safe

    binlog      ->  Server层 日志      公有日志            无大小限制 追加写入             ->  归档


------------------------------------------------------------------------------------------------------------------------
物理日志 redo log

    保证 crash-safe 能力

    innodb_flush_log_at_trx_commit 参数设置成 1      ->      表示每次事务的 redo log 都直接持久化到磁盘

        // 这个参数建议设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失



------------------------------------------------------------------------------------------------------------------------
两阶段提交：      // InnoDB

    redo log（prepare）   ->  binlog  ->  redo log（commit）

    为了 让两份日志 之间的逻辑一致    // 两类日志 职责功能 各不相同   ->  破坏一个，就会破坏 现有 逻辑 和 功能

    -----------------------
    本质上，从设计目的：

        redo log    负责 事务

        binlog      负责 归档恢复

        各司其职，相互配合，才提供(保证)了 Mysql InnoDB 的现有功能（crash-safe、事务、归档恢复）

        如果 你非要破坏 其中一个log，自然也就破坏了 现有逻辑和功能（crash-safe、事务、归档恢复）

    ---------------------------
    两阶段提交

        是  跨系统 维持数据逻辑一致性  时常用的一个方案

        即使你不做数据库内核开发，日常开发中也有可能会用到

        如：分布式事务 的 两阶段提交

------------------------------------------------------------------------------------------------------------------------
crash-safe、两阶段提交、事务

    InnoDB 为了 提高写入效率     ->  设计了 redo log

    为了解决 redo log 和 磁盘 数据的一致性问题     ->  设计了 crash-safe

    具体：

        两阶段提交   +   事务(状态 标记)

------------------------------------------------------------------------------------------------------------------------
数据恢复：       // 依靠 ->  数据库备份  +  binlog（归档日志）

    1、找到 最近的一次全量备份（如：一天一备，也就是昨晚），恢复至临时库

    2、从 备份的时间点 开始，将binlog取出来，重放到误删表的时刻

        binlog（归档日志） -> 恢复数据：
            从 最近一次全量备份 的时间点 开始；
            到 删库跑路        的时间点 结束；

    应用：

        1、误删恢复

        2、扩容    ->  搭建备库（全量备份 + binlog）


------------------------------------------------------------------------------------------------------------------------
binlog为什么说是逻辑日志呢？它里面的内容 也是 存储成物理文件，怎么说是逻辑 而不是物理

    这样理解：

        逻辑日志 可以给别的数据库，别的引擎使用，以及大家都 讲得通（认可）这个“逻辑”

        物理日志 就只有“我”自己能用，别人没有共享我的“物理格式”


------------------------------------------------------------------------------------------------------------------------
redo log 的持久化

    实际上，为了提高 redo log 的写入效率：

        并没有 每次都直接将 redo log 写入file

        而是放到buffer中，积攒多条 再一次性刷盘

        --------------------------------------------
        innodb_flush_log_at_trx_commit      0/1

            设置成 1       ->     每次事务的 redo log  都直接 持久化 到磁盘

            建议设置成 1    ->    可以保证 MySQL 异常重启之后 redo log 不丢失     --> 保证了 数据不丢失


------------------------------------------------------------------------------------------------------------------------
binlog 的持久化

    sync_binlog     0/1

        参数设置成 1        ->    表示每次事务的 binlog  都直接 持久化 到磁盘

        也建议设置成 1      ->    可以保证 MySQL 异常重启之后 binlog 不丢失


------------------------------------------------------------------------------------------------------------------------
binlog 还不能去掉

    1、redo log 只有InnoDB有，别的引擎没有

    2、redo log是循环写的，不持久保存，binlog 的“归档”这个功能，redolog是不具备的


    3、binlog 是MySQL 原生支持的，很多三方扩展、或现有的数据同步方案  强依赖了 binlog    // 主从同步 即是通过 解析 binlog 实现的


------------------------------------------------------------------------------------------------------------------------
redo log 和 binlog  两套日志 共存

    归根结底是 历史原因

        binlog      MySQL 原生自带

        redo log    InnoDB 三方公司开发   后来被 MySQL 合并到官方版本   造成了 二者共存的局面

                    // 既然是三方公司开发，也不好直接改你的 binlog

                    // 且改动原有的设计，成本也非常大，而且你还不是官方

                    // 最优方案自然是在 MySQL 提供的扩展插件（自定义 引擎扩展）上 重新开发一套log   ->  redo log


------------------------------------------------------------------------------------------------------------------------
crash-safe 崩溃恢复：

    redo log 里面的数据有两种状态，分别是：prepare、commit

    宕机后重启

        如果 redo log 里面的数据是 commit 状态，则commit

        如果是 prepare 状态，则需要根据 binlog 来确定  数据 是回滚还是提交

            如果 binlog 中已经记录了 prepare 状态数据的逻辑修改，则commit，否则需要回滚

            // 如果 修改 已经归档到 binlog，则此数据 必须提交，因为 下游的从库 会用到binlog，这样才能保证主从一致



------------------------------------------------------------------------------------------------------------------------
crash-safe 可能情况分析：

    1-prepare阶段     2-写binlog       3-commit

    当在 2之前 崩溃

        重启恢复：没有commit，且 binlog 中不完整/不存在            ->  rollback

        备份恢复：没有 binlog

        一致

    当在 3之前 崩溃

        重启恢复：虽没有commit，但满足 prepare 和 binlog完整       ->  commit

        备份恢复：有 binlog

        一致


------------------------------------------------------------------------------------------------------------------------
redo log 和 binlog 是如何关联的

    xid     ->      通过 事务ID 关联



========================================================================================================================
3、事务隔离
========================================================================================================================

    事务：
        ACID（Atomicity、Consistency、Isolation、Durability，即 原子性、一致性、隔离性、持久性）


------------------------------------------------------------------------------------------------------------------------
隔离级别：       // 主导权在自身，这里所说的隔离指  -->  自己的变更（A会话 的更新）  未提交前 是否允许  被别人看到（B会话）

                // 隔离级别 -> 全局共享参数     ====>  实际开发中，所有线程(会话) 都为同一个隔离级别      A事务 与 B事务 彼此是否可见  -->  可类比 多线程 下的可见性问题


    读未提交（read un-committed）：                // 非阻塞、能看到

        一个事务还没提交时，它做的变更就能被别的事务看到


    读已提交（read committed）：                   // 非阻塞、看不到

        一个事务提交之后，它做的变更才会被其他事务看到


    可重复读（repeatable read）：                  // 非阻塞、看不到      实现：缓存第一次读取的值（别人改数据的事务 已经提交，我在我的事务中也 根本不去读）

        一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的

        当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的


    串行化（serializable）：                       // 阻塞

        顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”

        当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行

        ----------------------------
        串行化只有在加『读锁』或者「写锁」的时候 才会尝试加锁，而 不是事务一开始 就进行加锁


------------------------------------------------------------------------------------------------------------------------
隔离级别 - 效率  的平衡：

    隔离 得越严实     ->      效率 就会越低

    因此很多时候，我们都要在 二者之间 寻找一个平衡点

------------------------------------------------------------------------------------------------------------------------
默认隔离级别：

    官方MySQL     ->   可重复读（repeatable read）

    阿里云RDS     ->   读已提交（read committed）

    --------------------------------------------
    Oracle       ->   读已提交（read committed）

------------------------------------------------------------------------------------------------------------------------
隔离级别的理解

    读未提交：   别人改数据的事务 尚未提交，我在我的事务中 也能读到
    读已提交：   别人改数据的事务 已经提交，我在我的事务中 才能读到
    可重复读：   别人改数据的事务 已经提交，我在我的事务中 也不去读      // 类似 快照

    串行：      我的事务尚未提交，别人就别想改数据                    // 读写、写写 -> 互斥     读读并行

    这4种隔离级别，并行性能依次降低，安全性依次提高

------------------------------------------------------------------------------------------------------------------------
隔离级别的理解

    对于我读别人

        1、判断依据  ->  commit

        2、我可以改变 自身隔离级别          ->  来获取别人 未提交的数据    （牺牲 安全性）


    对于别人读我

        1、我能主导的就是   ->  要不要commit

        2、他可以改变 自身隔离级别          ->  来获取我  未提交的数据     （牺牲 安全性）


    --------------------------------
    而最终拿到的结果，都是视图给(维护)的

------------------------------------------------------------------------------------------------------------------------
关于隔离级别的理解：

    1、read uncommitted

        可以看到未提交的数据（脏读），举个例子：别人说的话你都相信了，但是可能他只是说说，并不实际做。

    2、read committed

        读取提交的数据。但是，可能多次读取的数据结果不一致（不可重复读，幻读）。用读写的观点就是：读取的行数据，可以写。

    3、repeatable read（MySQL 默认隔离级别）

        可以重复读取，但有幻读

        读写观点：

            读取的数据行不可写，但是可以往表中新增数据

            在MySQL中，其他事务新增的数据，看不到，不会产生幻读

            采用多版本并发控制（MVCC）机制解决幻读问题

    4、serializable

        可读，不可写

        像Java中的锁，写数据必须等待另一个事务结束

------------------------------------------------------------------------------------------------------------------------
事务的可见性      // 目标事务 所在会话的隔离级别

    A 能否看到 B   ->   主导权在B （即：B 想不想让 A 看到）

        A事务 能否看到 B事务的变更   ->  取决于 B事务所在会话的 事务隔离级别

------------------------------------------------------------------------------------------------------------------------
视图          // select == 视图中的结果值   ->  数据库里面会创建一个视图，访问的时候 以视图的逻辑结果 为准

    1、读未提交（read un-committed）

        无视图 一说，直接返回记录的最新值


    2、读已提交（read committed）

        每次执行sql语句之前 创建新视图
        -----------------------------------------------
            RC级别下，MVCC视图会在 每一个语句前 创建一个

                所以在RC级别下，一个事务 是可以看到另外一个事务 已经提交的内容

                因为它在每一次查询之前 都会重新给数据 创建一个新的MVCC视图


    3、可重复读（repeatable read）

        每次创建事务的时候 创建视图
        -----------------------------------------------
            RR级别下，MVCC视图 在开始事务的时候 就创建好了

            这个视图 会一直使用，直到该事务结束


    4、串行化（serializable）

        加锁  ->  阻塞  ->  禁止并行访问


------------------------------------------------------------------------------------------------------------------------
undo log        // 每个 insert/update/delete  -->  redo log  +  undo log  +  binlog

    可回溯（历史版本 undo log）：     // 类似 git

        实际上每条记录 在更新的时候 都会同时记录一条 回滚操作

        记录上的最新值，通过回滚操作，都可以得到前一个状态的值


    关联倒推（版本）：

        1 -> 2 -> 3 -> ... -> 100

    rollback：

        1 <- 2 <- 3 <- ... <- 100

    删除：

        在不需要的时候才删除

        也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除

        什么时候才不需要了呢？就是当系统里 没有比这个回滚日志更早的 read-view 的时候

        ------------------------------
        当与此相关的所有事务 都已commit


    所以不要用长事务

        长事务意味着 系统里面会存在 很老的事务视图

            由于这些事务 随时可能访问 数据库里面的任何数据

            所以这个事务提交之前，数据库里面 它可能用到的回滚记录 都必须保留，这就会导致 大量占用存储空间

        长事务还占用锁资源

------------------------------------------------------------------------------------------------------------------------
在可重复读的隔离级别下，如何理解

当系统里没有比这个回滚日志更早的 read-view 的时候，这个 回滚日志 就会被删除？

- 这也是尽量 不要使用长事务 的主要原因

    比如：

    1、在某个时刻（今天上午9:00）开启了 一个事务A（对于可重复读隔离级别，此时一个视图 read-view A 也创建了）

        这是一个 很长很长 的事务...

    2、事务A 在今天上午 9:20 的时候，查询了一个记录 R1的一个字段f1 的值为 1

    3、今天上午9:25的时候，一个事务B（随之而来的read-view B）也被开启了，它更新了 R1.f1 的值为 2（同时也创建了一个 由2到1 的回滚日志）

        这是一个短事务，事务随后就被 commit 了

    4、今天上午9:30的时候，一个事务C（随之而来的read-view C）也被开启了，它更新了 R1.f1 的值为 3（同时也创建了一个 由3到2 的回滚日志）

        这是一个短事务，事务随后就被 commit 了

    ...

    5、到了下午3:00了，长事务A 还没有 commit

        为了保证事务 在执行期间看到的数据 在前后必须是一致的，那些 老的事务视图、回滚日志 就必须一直存在，这就占用了大量的存储空间


    源于此，我们应该尽量不要使用长事务


------------------------------------------------------------------------------------------------------------------------
多版本并发控制（MVCC）：

    不同时刻启动的事务 会有不同的 read-view


    把 一致性读、当前读和行锁 串起来


========================================================================================================================
InnoDB 的 事务和锁                                                        全部默认 auto_commit = 1
========================================================================================================================
------------------------------------------------------------------------------------------------------------------------
事务的启动 时机

    begin / start transaction 命令
        并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动

        这个操作不会启动一个事务，这个操作之后，第一个对数据库的操作才会真正启动一个事务

    start transaction with consistent snapshot
        马上启动一个事务

------------------------------------------------------------------------------------------------------------------------
一致性视图（事务启动）

    begin/start transaction
        一致性视图 是在执行 第一个快照读语句 时创建

    start transaction with consistent snapshot
        一致性视图 是在执行 start transaction with consistent snapshot 时创建

------------------------------------------------------------------------------------------------------------------------
begin / start transaction

    begin                   开启事务，标识一个事务的开始。
    start transaction       开启事务


    在MySQL里，begin 和 start transaction 是等价的

------------------------------------------------------------------------------------------------------------------------
auto_commit = 1
    MySQL会 隐式的 开启和关闭事务

显式使用 begin / start + 多条语句 + commit
    是为了表明  ->  这“多条语句”是 1 个事务


------------------------------------------------------------------------------------------------------------------------
定义一个事务                                // 全部默认 autocommit = 1

    显示  ->  手动 begin/commit

        可以聚合 多条SQL 在同一个事务中，原子操作


    隐式  ->  自动 begin/commit             // 默认 autocommit = 1

        这时候，一条SQL，就是一个事务

        执行SQL 之前，InnnoDB 自动添加 begin
        执行SQL 之后，InnnoDB 自动添加 commit

------------------------------------------------------------------------------------------------------------------------
MySQL的两个“视图”
    1、查询语句 虚拟表(view)
    2、InnoDB实现MVCC时的 一致性读视图(consisitent read view)


它没有物理结构

作用：
    事务执行期间，用来定义“我能看到什么数据”

------------------------------------------------------------------------------------------------------------------------
MVCC  快照

    1、快照 范围：
        整库

    2、快照 时间基点：
        事务 启动时      ->      就 “拍了个快照”

    3、快照 怎么实现的：

         transaction id

------------------------------------------------------------------------------------------------------------------------
行记录 多版本

    undo_log 实现
        V1、V2、V3 并不是物理上真实存在的，而是每次需要的时候根据当前版本和 undo log 计算出来的
        比如，需要 V2 的时候，就是通过 V4 依次执行 U3(undo_log 3)、U2(undo_log 2) 算出来

    每行数据都有多个版本，每次事务更新数据的时候，都会生成一个 新的数据版本
    并把 transaction_id 赋值给这个数据版本的 事务ID，记为 row trx_id

    版本中包含
        本次数据的值
        事务id
        还有一个引用（指向 上一个数据版本）

    表中的一行记录
        可能有多个版本 (row)，每个版本有自己的 row trx_id


------------------------------------------------------------------------------------------------------------------------
数据版本可见性规则

    事务视图数组  ->  未提交事务集合（活跃）

        InnoDB 每个事务启动时，都会 创建一个数组
            用来保存    ->      这个事务启动瞬间，当前正在 “活跃”的 所有事务ID
            “活跃”     ->      启动了，但还没提交


    row trx_id
        根据 事务启动的时间 递增        ->  有序

                                                             低水位           高水位
                                                               ↓               ↓
    trx_id 视图数组： 保存 trx_id（有序）      ->      已提交事务  | 未提交事务集合  | 未开始事务


    低水位：
        数组内 事务ID最小值

    高水位：
        当前系统 已创建的 事务id的最大值 + 1

------------------------------------------------------------------------------------------------------------------------
秒级 创建快照

    InnoDB 利用了 “所有数据都有多个版本” 的这个特性

    根据  时间基点  切割  ->   trx_id 数组            // trx_id 根据 时间先后，递增生成

        当前事务启动时 的 时刻基点  ->  定义 低水位   + 高水位      =====> 生成当前事务的 "快照"   ->  秒级

------------------------------------------------------------------------------------------------------------------------
快照 访问逻辑         // 一致性 读！！！

    在当前事务内，访问 行记录k：                   // 访问快照    ->  这里都是在说 可见性  --> 读      ==> update，是不受此约束的

        1、获取 行记录k 当前最新版本v4的 row trx_id = 25

        2、当前事务的 低水位 row trx_id = 18

        3、低水位trx_id 18  <  当前版本trx_id 25

        4、根据undo_log，拿到上一个版本v3，v3版本的 row trx_id = 11

        5、v3版本trx_id 11  <  低水位trx_id 18

        6、当前事务内，行记录k 的值为 v3版本的值

------------------------------------------------------------------------------------------------------------------------
事务可见性 分析规则                  // 上面👆是原理，实际分析太绕、太复杂

一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：

    1、版本未提交，不可见；
    2、版本已提交，但是是在视图创建后提交的，不可见；
    3、版本已提交，而且是在视图创建前提交的，可见。


========================================================================================================================
update 逻辑               // update -> 读最新值               ==> "当前读"
========================================================================================================================

事务视图的 update
    更新数据的时候，不再理会 "历史版本"， 直接读取 -> 当前(最新)值


“当前读”（current read）

    直接读取 -> 当前(最新)值
    ------------------------------
    update 都是 先读后写
    而这个读，只能读 当前(最新)值，称为“当前读”（current read）

========================================================================================================================
当前读             // 当前读  ->  读当前(最新)值        ==> 本质上是 加锁 -> 获取 被lock保护的资源 的最新值    -> 表现上，就是 不再理会 "历史版本"
========================================================================================================================

触发 当前读              // 读 最新值

    1、update 自动触发                   // 本质上也是 加锁 触发（默认加了 写锁）

    2、select 手动加锁 主动触发

        1、读锁（S 锁，共享锁）           ->  lock in share mode
        2、写锁（X 锁，排他锁）           ->  for update


除 update 外，select 加锁，也是 当前读

    select k from t where id=1   lock in share mode;
    select k from t where id=1   for update;

------------------------------------------------------------------------------------------------------------------------
当前读 的本质是 加锁(行锁)保护

    根据 两阶段锁协议
        如果A线程 持有锁 没释放
        而B线程 通过update/select 加锁(竞争锁)，触发 当前读 -> 想要获取 最新值

        此时，B线程-会阻塞，等待 A线程-释放锁

        ----------------------
        加锁角度分析：
            锁没释放    ->  锁等待

        结果角度：
            想要获取 最新值，而最新值还没提交，只能等待其提交

            --------------------------------------
            A线程 可commit，也可 rollback
            B线程，只能等待 A事务结束(commit/rollback)


------------------------------------------------------------------------------------------------------------------------
一致性读、当前读、行锁

    一致性读        快照值(历史值)       事务视图 快照                      ->  事务启动，创建 事务视图 快照 - trx_id 事务数组 快照

    当前读          当前值(最新值)       update、select加锁(行锁)           ->  update 行锁  、 select 行锁

    --------------------------------------------------------------------------------------------------------------------
    行锁            当前值(最新值)       通过加 update/select 行锁   ->   触发 "当前读"   -> 具体实现：通过(行)锁竞争，触发 lock wait



------------------------------------------------------------------------------------------------------------------------
一致性读


------------------------------------------------------------------------------------------------------------------------
事务隔离的本质实现: 两阶段锁协议 + MVCC

------------------------------------------------------------------------------------------------------------------------
事务的可重复读的能力是怎么实现的？

    可重复读 的核心就是 一致性读（consistent read）

    而事务 更新数据 的时候，只能用 当前读，如果 当前记录的行锁 被其他事务占用 的话，就需要进入 锁等待

------------------------------------------------------------------------------------------------------------------------
可重复读    ->      一致性读        - 快照

读已提交    ->      类似 可重复读
------------------------------------------------------------------------------------------------------------------------
区别：
    1、可重复读      ->      1个  一致性视图
    2、读已提交      ->      N个  视图                  // 1个SQL    ->  1个视图

    --------------------------------------------------------
    可重复读
        只需在 事务开始的时候 创建一致性视图，之后事务里的其他查询 都共用 这个一致性视图

    读已提交
        每一个语句执行前 都会重新 算出一个新的视图

------------------------------------------------------------------------------------------------------------------------
读已提交
    start transaction with consistent snapshot  ==  start transaction           // just事务标识，真正的事务 -> SQL执行前开启

    --------------------------------------------------------
    start transaction with consistent snapshot
        启动事务，并创建一个 持续整个事务的 一致性快照
        在[读已提交]隔离级别下，这个用法就没意义了
        等效于普通的 start transaction


------------------------------------------------------------------------------------------------------------------------
读已提交 VS 可重复读                        // 注意，这里都是在说 "读" - select

    从资源利用(视图维护)角度，就清晰了             // 维护视图，肯定是有成本的

        读已提交        每次select   ->  开启1个  新视图                 ->  数据安全(拿到最新 持久化值)      并发度 低

        可重复读        事务启动时    ->  开启1个  全局 一致性视图         ->  数据脏读(拿到 历史值)           并发度 高

------------------------------------------------------------------------------------------------------------------------
总结
    一致性读，会根据 row trx_id 和 一致性视图(<低水位) 确定数据版本的 可见性                   // 普通select语句，非加锁(当前读)

    可重复读    ->  查询只承认   在事务启动前 就 已经提交 完成的数据；    // 事务 前 提交
    读已提交    ->  查询只承认   在语句启动前 就 已经提交 完成的数据      // SQL 前 提交


    当前读，总是读取 已经提交完成 的 最新版本


------------------------------------------------------------------------------------------------------------------------
思考

    行数据，支持 可重复度(快照读) + 当前读

    表结构，为什么 不支持 可重复度(快照读)？

        因为，表结构，没有对应的 行数据，也没有 row trx_id（表结构 版本 -> undo_log），因此只能遵循 当前读 的逻辑.

        ------------------------------------------------------------
        想要实现，其实也是可以的，参考 行记录 的 一致性视图(快照)

            MySQL 8.0 已经可以把 表结构 放在 InnoDB 字典里了，也许以后会支持表结构的可重复读.






========================================================================================================================
4、索引
========================================================================================================================
功能：
    快速查询

------------------------------------------------------------------------------------------------------------------------
数据结构模型：

    1、hash表

        无序  ->      不支持区间查

            等值查     ->  O(1)

            区间查    ->  遍历 O(n)



    2、有序数组

        有序：

            等值、区间   ->  二分查找O(logN)

        缺点：

            插删 数组全量移位


    3、二叉搜索树                     // 瘦高

        有序：
            支持区间查

        ---------------
        查：
            O(logN)

        插、删：

            O(logN)

        ---------------
        缺点：

            二叉  ->  分支少     ===>  树高 过高（树高 = IO 次数）   ->  IO 多


    4、N叉树       // B+树                矮胖

        1200^3 ≈ 17亿

            root 数据块 总是在内存中，且第二层 也大概率在内存中

            最多只需要 3次 IO   ->   就能查找到 17亿表中的数据

------------------------------------------------------------------------------------------------------------------------
索引模型

    索引在 引擎层实现   ->      不同引擎，实现各不相同，并没有统一规范

------------------------------------------------------------------------------------------------------------------------
InnoDB 的索引模型

    主键索引    ->  整行数据

    普通索引    ->  ID（回表）


    尽量使用主键ID查询：

        普通索引查询  ->  拿到ID   --回表-->   主键索引 获取整行数据


    尽量使用 整型自增主键：

        从性能和存储空间方面考量，自增主键往往是更合理的选择

            bigint -> 8个字节

            主键ID 占用空间越小  ->  非主键索引 占用的空间越小


------------------------------------------------------------------------------------------------------------------------
联合索引

    节省空间    ->  多棵树（多个B+索引树），合并一颗树                       // 索引合并

    回表优化    ->  idx__idCard_name：  根据 id_card -> name  不用回表     // 索引冗余

------------------------------------------------------------------------------------------------------------------------
索引的维护

    页分裂/页合并：

        一个数据页满了

        按照B+Tree算法，新增加一个数据页，叫做页分裂，会导致性能下降      // 新增一层树高  ->  原有树结构 会重新排列

        空间利用率降低大概50%

        当相邻的两个数据页 利用率很低的时候 会做数据页合并，合并的过程 是分裂过程的逆过程


------------------------------------------------------------------------------------------------------------------------
“N叉树”的N值在MySQL中是可以被人工调整的么
              count
    N = ——————————————————
            page size

    1、数据总数一定，页越大，一页存放的索引越多，N越大，树高越低

    2、页大小固定，索引(key值)占用空间越小，存储索引越多，N越大，树高越低


    ------------------------------------------
    1、通过改变key值来调整
        N叉树中非叶子节点存放的是索引信息，索引包含Key和Point指针。
        Point指针固定为6个字节，假如Key为10个字节，那么单个索引就是16个字节。
        如果B+树中页大小为16K，那么一个页就可以存储1024个索引，此时N就等于1024。
        我们通过改变Key的大小，就可以改变N的值
    2、改变页的大小
        页越大，一页存放的索引就越多，N就越大。

------------------------------------------------------------------------------------------------------------------------
索引树的理解：

    每一张表 其实就是几个B+树    // 1个主键树  +  n个普通索引树

        树结点的 key值 就是某一行的主键，value是该行的其他数据

        新建索引 就是新增一个B+树


    查询 走主键索引   ->  就是查询 主键索引B+树

    查询 走普通索引   ->  就是查询 普通索引B+树       ==>  回表 -> 走主键索引

    查询不走索引      ->  就是 遍历主B+树


------------------------------------------------------------------------------------------------------------------------
搜索树

    搜索树 已经很接近 跳表

        跳表 其实就是站在 平衡搜索树的肩膀上 改进而来的


    B+树 类比 跳表  的存、取：

        上层的结点         ->  为了查询 而建立的多级索引

        最底层的 叶子结点   ->  才是 数据(行)

------------------------------------------------------------------------------------------------------------------------
联合索引

    覆盖索引

    最左前缀原则

    索引下推优化











========================================================================================================================
5、锁
========================================================================================================================

1、全局锁     ->  Server层 实现

    锁整个数据库

    加全局读锁
        FTWRL   ->  Flush tables with read lock

    让整个库处于只读状态
        阻塞增删改、阻塞表结构变更

    场景：
        全库逻辑备份


    全库只读：

        1、set global readonly=true

            readonly 的值会被用来做其他逻辑，如：判断主库还是备库

            修改 global 变量的方式影响面更大，不建议你使用

        2、FTWRL

            异常风险：
                FTWRL 命令之后由于客户端发生异常断开，MySQL 会自动释放这个全局锁

                将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，
                这样会导致整个库长时间处于不可写状态，风险较高

------------------------------------------------------------------------------------------------------------------------
2、表级锁     ->  Server层 实现

    1、表锁                                         // 显示锁  ->  主动 加/释放锁

        加/释放 锁：
            手动加锁  ->  lock   tables ... read/write
            手动解锁  ->  unlock tables

        ---------------------------------------------------------
        read     ->  线程 获取到 read 的权限
        write    ->  线程 获取到 write + read（能写就能 读） 的权限

        ---------------------------------------------------------
        lock tables t1 read, t2 write

            当前线程 可以 read          表t1
            当前线程 可以 write + read  表t2

            其他线程  write          表t1  -> 阻塞
            其他线程  read + write   表t2  -> 阻塞


    --------------------------------------------------------------------------------------------------------------------
    2、MDL（meta data lock）  元数据锁                 //  隐式锁                  表级锁  ->   增删改查 时，不允许修改表结构

        加/释放 锁：
            增删改查   时     ->  自动加  MDL read锁     ==>  禁止 修改表结构
            修改表结构 时     ->  自动加  MDL write锁    ==>  禁止 增删改查

        -----------------------------------------------------------------
            A 申请 MDL read锁
            B 申请 MDL read锁
            C 申请 MDL write锁     ->  阻塞          ===>    加等待时间，不要阻塞后面的 MDL read锁 线程
            D 申请 MDL read锁      ->  阻塞
            ...

        -----------------------------------------------------------------
        长事务
            MDL 会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。

------------------------------------------------------------------------------------------------------------------------
3、行锁      ->  引擎层 实现                                          InnoDB 行锁   ->  隐式锁

    InnoDB 行锁
        隐式锁     ->      自动 加锁，锁住行记录

    细粒度锁
        减少锁冲突，提升业务并发度

    两阶段锁
        执行SQL时加锁，事务结束(commit/rollback) 才释放
    -----------------------------------------------------------
    加/释放 锁：
        加锁：
            update t set k=k+1 where id = 1;        // InnoDB 自动加行锁，锁住 id=1 的行记录

        释放锁：
            commit/rollback                         // 事务结束时，才(自动)释放锁
    -----------------------------------------------------------
    死锁
        资源循环依赖

    死锁检测（耗CPU资源）
        锁资源申请不到时，触发死锁检测                                         // 即：他要 加锁访问的行 上有锁，他才要检测
            检测 获取锁的线程，是否有 资源循环依赖 问题
            是 -> 则判定为死锁，随机释放一个线程持有的资源，破解僵局！

    解决死锁：
        1、超时自动释放
        2、开启 死锁检测（吃CPU）

    预防死锁：
        1、转移 上层/中间件 限流/排队
        2、业务上优化


========================================================================================================================
6、order by      // 排序
========================================================================================================================




========================================================================================================================
7、高可用、主备、读写分离
========================================================================================================================



========================================================================================================================
8、join
========================================================================================================================



========================================================================================================================
9、临时表
========================================================================================================================



========================================================================================================================
10、InnoDB、Memory
========================================================================================================================





========================================================================================================================
10、自增主键
========================================================================================================================




========================================================================================================================
11、insert 锁
========================================================================================================================




========================================================================================================================
12、复制一张表
========================================================================================================================


========================================================================================================================
13、分区表
========================================================================================================================




