========================================================================================================================
1、SQL执行过程
========================================================================================================================

    客户端     ->      Server端
                                   ↗   查缓存（MySQL8 已废弃）

    ->  连接器（管理连接，权限验证）  ->  分析器（词法分析，语法分析）  ->  优化器（执行计划生成，索引选择） ->  执行器（操作引擎，返回结果）

    ->  存储引擎（存储数据，提供读写接口）



    MySQL：

        1、Server层                                   // 不同的存储引擎共用一个 Server 层，也就是 从连接器到执行器 的部分

            连接器、查询缓存、分析器、优化器、执行器等

            涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等）

            所有 跨存储引擎的功能 都在这一层实现，比如 存储过程、触发器、视图 等


        2、存储引擎层                                  // 存、取     插件式

            负责 数据的存储和提取

            其架构模式是 插件式 的，支持 InnoDB、MyISAM、Memory 等多个存储引擎

            最常用的存储引擎是 InnoDB



========================================================================================================================
2、日志                        // CRUD 记录
========================================================================================================================

    1、redo log              // 引擎层 日志、InnoDB 引擎特有的日志、crash-safe、事务

        作用：
            crash-safe、事务


        目的：         // 提高写入性能   ->  通过  crash-safe、事务  保证数据完整性

            每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高

                // 写入磁盘的操作 成本过高：   ->  写入 log file  ->  就直接返回 insert/update/delete 成功    ->  后台再从 log file  --同步至-->  磁盘

                    // 所有我们先写入 一个日志file，做个缓冲        // 类似 log4j日志

                    // 读取 log  ->  解析 log  ->  写入磁盘

                    // 再从log file中，更新到磁盘（ 因为直接写入磁盘，需要经过 IO、查询、更新、维护索引...  --->  成本较高  ->  时间较慢  -->  系统效率慢 ）


        优化：

            先写日志，再写磁盘       // 也就是先写粉板，等不忙的时候再写账本

                InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了

                同时，InnoDB 引擎会在适当（空闲）的时候，将这个操作记录更新到磁盘里面


        日志 存储：  // 本质就是一个  循环队列

            本质就是一个  循环队列
            --------------------------------------
            日志存储空间有限，记满了    ->  停下来（阻塞），批量处理一批  ->  写入磁盘  ->  清除已处理日志，腾出空间


        理解：

            类比 掌柜记账

                黑板记账(日志，写入内存)    ->  打烊后（系统空闲）核算，记入账本（写入磁盘）

            -----------------------------
            黑板写满了   ->  停下来，先核算一批，写入账本  ->  擦除 -> 重新黑板记账



        crash-safe：                 // redo log 记录在 file，也是一种物理存储   并不是在内存中   ->   只要记录在了粉板上，就具备 crash-safe 的能力了

            只要写入了 log file，就已经持久化到 file 文件中了

            log file 类似 log4j 的日志文件，也是 持久化存储在 物理磁盘 上

            就算 数据库异常崩溃，log file 依然存在

            重启后，继续 读取、解析log，再持久化到磁盘



        实现：

            "循环队列"   ->  本质上是一个 循环file

            checkpoint  ->  游标



    2、binlog            // Server层 日志   ->  所有引擎 公有     、  归档

        归档日志    ->  数据恢复




------------------------------------------------------------------------------------------------------------------------
redo log、binlog 区别：         // 都是log file   ->  类似 log4j 业务日志   ->   均存储在 物理磁盘

    redo log    ->  引擎层   日志       InnoDB 独有        固定大小   循环写入(覆盖)       ->  crash-safe

    binlog      ->  Server层 日志      公有日志            无大小限制 追加写入             ->  归档


------------------------------------------------------------------------------------------------------------------------
物理日志 redo log

    保证 crash-safe 能力

    innodb_flush_log_at_trx_commit 参数设置成 1      ->      表示每次事务的 redo log 都直接持久化到磁盘

        // 这个参数建议设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失



------------------------------------------------------------------------------------------------------------------------
两阶段提交：      // InnoDB

    redo log（prepare）   ->  binlog  ->  redo log（commit）

    为了 让两份日志 之间的逻辑一致    // 两类日志 职责功能 各不相同   ->  破坏一个，就会破坏 现有 逻辑 和 功能

    -----------------------
    本质上，从设计目的：

        redo log    负责 事务

        binlog      负责 归档恢复

        各司其职，相互配合，才提供(保证)了 Mysql InnoDB 的现有功能（crash-safe、事务、归档恢复）

        如果 你非要破坏 其中一个log，自然也就破坏了 现有逻辑和功能（crash-safe、事务、归档恢复）

    ---------------------------
    两阶段提交

        是  跨系统 维持数据逻辑一致性  时常用的一个方案

        即使你不做数据库内核开发，日常开发中也有可能会用到

        如：分布式事务 的 两阶段提交

------------------------------------------------------------------------------------------------------------------------
crash-safe、两阶段提交、事务

    InnoDB 为了 提高写入效率     ->  设计了 redo log

    为了解决 redo log 和 磁盘 数据的一致性问题     ->  设计了 crash-safe

    具体：

        两阶段提交   +   事务(状态 标记)

------------------------------------------------------------------------------------------------------------------------
数据恢复：       // 依靠 ->  数据库备份  +  binlog（归档日志）

    1、找到 最近的一次全量备份（如：一天一备，也就是昨晚），恢复至临时库

    2、从 备份的时间点 开始，将binlog取出来，重放到误删表的时刻

        binlog（归档日志） -> 恢复数据：
            从 最近一次全量备份 的时间点 开始；
            到 删库跑路        的时间点 结束；

    应用：

        1、误删恢复

        2、扩容    ->  搭建备库（全量备份 + binlog）


------------------------------------------------------------------------------------------------------------------------
binlog为什么说是逻辑日志呢？它里面的内容 也是 存储成物理文件，怎么说是逻辑 而不是物理

    这样理解：

        逻辑日志 可以给别的数据库，别的引擎使用，以及大家都 讲得通（认可）这个“逻辑”

        物理日志 就只有“我”自己能用，别人没有共享我的“物理格式”


------------------------------------------------------------------------------------------------------------------------
redo log 的持久化

    实际上，为了提高 redo log 的写入效率：

        并没有 每次都直接将 redo log 写入file

        而是放到buffer中，积攒多条 再一次性刷盘

        --------------------------------------------
        innodb_flush_log_at_trx_commit      0/1

            设置成 1       ->     每次事务的 redo log  都直接 持久化 到磁盘

            建议设置成 1    ->    可以保证 MySQL 异常重启之后 redo log 不丢失     --> 保证了 数据不丢失


------------------------------------------------------------------------------------------------------------------------
binlog 的持久化

    sync_binlog     0/1

        参数设置成 1        ->    表示每次事务的 binlog  都直接 持久化 到磁盘

        也建议设置成 1      ->    可以保证 MySQL 异常重启之后 binlog 不丢失


------------------------------------------------------------------------------------------------------------------------
binlog 还不能去掉

    1、redo log 只有InnoDB有，别的引擎没有

    2、redo log是循环写的，不持久保存，binlog 的“归档”这个功能，redolog是不具备的


    3、binlog 是MySQL 原生支持的，很多三方扩展、或现有的数据同步方案  强依赖了 binlog    // 主从同步 即是通过 解析 binlog 实现的


------------------------------------------------------------------------------------------------------------------------
redo log 和 binlog  两套日志 共存

    归根结底是 历史原因

        binlog      MySQL 原生自带

        redo log    InnoDB 三方公司开发   后来被 MySQL 合并到官方版本   造成了 二者共存的局面

                    // 既然是三方公司开发，也不好直接改你的 binlog

                    // 且改动原有的设计，成本也非常大，而且你还不是官方

                    // 最优方案自然是在 MySQL 提供的扩展插件（自定义 引擎扩展）上 重新开发一套log   ->  redo log


------------------------------------------------------------------------------------------------------------------------
crash-safe 崩溃恢复：

    redo log 里面的数据有两种状态，分别是：prepare、commit

    宕机后重启

        如果 redo log 里面的数据是 commit 状态，则commit

        如果是 prepare 状态，则需要根据 binlog 来确定  数据 是回滚还是提交

            如果 binlog 中已经记录了 prepare 状态数据的逻辑修改，则commit，否则需要回滚

            // 如果 修改 已经归档到 binlog，则此数据 必须提交，因为 下游的从库 会用到binlog，这样才能保证主从一致



------------------------------------------------------------------------------------------------------------------------
crash-safe 可能情况分析：

    1-prepare阶段     2-写binlog       3-commit

    当在 2之前 崩溃

        重启恢复：没有commit，且 binlog 中不完整/不存在            ->  rollback

        备份恢复：没有 binlog

        一致

    当在 3之前 崩溃

        重启恢复：虽没有commit，但满足 prepare 和 binlog完整       ->  commit

        备份恢复：有 binlog

        一致


------------------------------------------------------------------------------------------------------------------------
redo log 和 binlog 是如何关联的

    xid     ->      通过 事务ID 关联



========================================================================================================================
3、事务隔离
========================================================================================================================

    事务：
        ACID（Atomicity、Consistency、Isolation、Durability，即 原子性、一致性、隔离性、持久性）


------------------------------------------------------------------------------------------------------------------------
隔离级别：       // 主导权在自身，这里所说的隔离指  -->  自己的变更（A会话 的更新）  未提交前 是否允许  被别人看到（B会话）

                // 隔离级别 -> 全局共享参数     ====>  实际开发中，所有线程(会话) 都为同一个隔离级别      A事务 与 B事务 彼此是否可见  -->  可类比 多线程 下的可见性问题


    读未提交（read un-committed）：                // 非阻塞、能看到

        一个事务还没提交时，它做的变更就能被别的事务看到


    读已提交（read committed）：                   // 非阻塞、看不到

        一个事务提交之后，它做的变更才会被其他事务看到


    可重复读（repeatable read）：                  // 非阻塞、看不到      实现：缓存第一次读取的值（别人改数据的事务 已经提交，我在我的事务中也 根本不去读）

        一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的

        当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的


    串行化（serializable）：                       // 阻塞

        顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”

        当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行

        ----------------------------
        串行化只有在加『读锁』或者「写锁」的时候 才会尝试加锁，而 不是事务一开始 就进行加锁


------------------------------------------------------------------------------------------------------------------------
隔离级别 - 效率  的平衡：

    隔离 得越严实     ->      效率 就会越低

    因此很多时候，我们都要在 二者之间 寻找一个平衡点

------------------------------------------------------------------------------------------------------------------------
默认隔离级别：

    官方MySQL     ->   可重复读（repeatable read）

    阿里云RDS     ->   读已提交（read committed）

    --------------------------------------------
    Oracle       ->   读已提交（read committed）

------------------------------------------------------------------------------------------------------------------------
隔离级别的理解

    读未提交：   别人改数据的事务 尚未提交，我在我的事务中 也能读到
    读已提交：   别人改数据的事务 已经提交，我在我的事务中 才能读到
    可重复读：   别人改数据的事务 已经提交，我在我的事务中 也不去读      // 类似 快照

    串行：      我的事务尚未提交，别人就别想改数据                    // 读写、写写 -> 互斥     读读并行

    这4种隔离级别，并行性能依次降低，安全性依次提高

------------------------------------------------------------------------------------------------------------------------
隔离级别的理解

    对于我读别人

        1、判断依据  ->  commit

        2、我可以改变 自身隔离级别          ->  来获取别人 未提交的数据    （牺牲 安全性）


    对于别人读我

        1、我能主导的就是   ->  要不要commit

        2、他可以改变 自身隔离级别          ->  来获取我  未提交的数据     （牺牲 安全性）


    --------------------------------
    而最终拿到的结果，都是视图给(维护)的

------------------------------------------------------------------------------------------------------------------------
关于隔离级别的理解：

    1、read uncommitted

        可以看到未提交的数据（脏读），举个例子：别人说的话你都相信了，但是可能他只是说说，并不实际做。

    2、read committed

        读取提交的数据。但是，可能多次读取的数据结果不一致（不可重复读，幻读）。用读写的观点就是：读取的行数据，可以写。

    3、repeatable read（MySQL 默认隔离级别）

        可以重复读取，但有幻读

        读写观点：

            读取的数据行不可写，但是可以往表中新增数据

            在MySQL中，其他事务新增的数据，看不到，不会产生幻读

            采用多版本并发控制（MVCC）机制解决幻读问题

    4、serializable

        可读，不可写

        像Java中的锁，写数据必须等待另一个事务结束

------------------------------------------------------------------------------------------------------------------------
事务的可见性      // 目标事务 所在会话的隔离级别

    A 能否看到 B   ->   主导权在B （即：B 想不想让 A 看到）

        A事务 能否看到 B事务的变更   ->  取决于 B事务所在会话的 事务隔离级别

------------------------------------------------------------------------------------------------------------------------
视图          // select == 视图中的结果值   ->  数据库里面会创建一个视图，访问的时候 以视图的逻辑结果 为准

    1、读未提交（read un-committed）

        无视图 一说，直接返回记录的最新值


    2、读已提交（read committed）

        每次执行sql语句之前 创建新视图
        -----------------------------------------------
            RC级别下，MVCC视图会在 每一个语句前 创建一个

                所以在RC级别下，一个事务 是可以看到另外一个事务 已经提交的内容

                因为它在每一次查询之前 都会重新给数据 创建一个新的MVCC视图


    3、可重复读（repeatable read）

        每次创建事务的时候 创建视图
        -----------------------------------------------
            RR级别下，MVCC视图 在开始事务的时候 就创建好了

            这个视图 会一直使用，直到该事务结束


    4、串行化（serializable）

        加锁  ->  阻塞  ->  禁止并行访问


------------------------------------------------------------------------------------------------------------------------
undo log        // 每个 insert/update/delete  -->  redo log  +  undo log  +  binlog

    可回溯（历史版本 undo log）：     // 类似 git

        实际上每条记录 在更新的时候 都会同时记录一条 回滚操作

        记录上的最新值，通过回滚操作，都可以得到前一个状态的值


    关联倒推（版本）：

        1 -> 2 -> 3 -> ... -> 100

    rollback：

        1 <- 2 <- 3 <- ... <- 100

    删除：

        在不需要的时候才删除

        也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除

        什么时候才不需要了呢？就是当系统里 没有比这个回滚日志更早的 read-view 的时候

        ------------------------------
        当与此相关的所有事务 都已commit


    所以不要用长事务

        长事务意味着 系统里面会存在 很老的事务视图

            由于这些事务 随时可能访问 数据库里面的任何数据

            所以这个事务提交之前，数据库里面 它可能用到的回滚记录 都必须保留，这就会导致 大量占用存储空间

        长事务还占用锁资源

------------------------------------------------------------------------------------------------------------------------
在可重复读的隔离级别下，如何理解

当系统里没有比这个回滚日志更早的 read-view 的时候，这个 回滚日志 就会被删除？

- 这也是尽量 不要使用长事务 的主要原因

    比如：

    1、在某个时刻（今天上午9:00）开启了 一个事务A（对于可重复读隔离级别，此时一个视图 read-view A 也创建了）

        这是一个 很长很长 的事务...

    2、事务A 在今天上午 9:20 的时候，查询了一个记录 R1的一个字段f1 的值为 1

    3、今天上午9:25的时候，一个事务B（随之而来的read-view B）也被开启了，它更新了 R1.f1 的值为 2（同时也创建了一个 由2到1 的回滚日志）

        这是一个短事务，事务随后就被 commit 了

    4、今天上午9:30的时候，一个事务C（随之而来的read-view C）也被开启了，它更新了 R1.f1 的值为 3（同时也创建了一个 由3到2 的回滚日志）

        这是一个短事务，事务随后就被 commit 了

    ...

    5、到了下午3:00了，长事务A 还没有 commit

        为了保证事务 在执行期间看到的数据 在前后必须是一致的，那些 老的事务视图、回滚日志 就必须一直存在，这就占用了大量的存储空间


    源于此，我们应该尽量不要使用长事务


------------------------------------------------------------------------------------------------------------------------
多版本并发控制（MVCC）：

    不同时刻启动的事务 会有不同的 read-view





    把 一致性读、当前读和行锁 串起来



========================================================================================================================
4、索引
========================================================================================================================
功能：
    快速查询

------------------------------------------------------------------------------------------------------------------------
数据结构模型：

    1、hash表

        无序  ->      不支持区间查

            等值查     ->  O(1)

            区间查    ->  遍历 O(n)



    2、有序数组

        有序：

            等值、区间   ->  二分查找O(logN)

        缺点：

            插删 数组全量移位


    3、二叉搜索树                     // 瘦高

        有序：
            支持区间查

        ---------------
        查：
            O(logN)

        插、删：

            O(logN)

        ---------------
        缺点：

            二叉  ->  分支少     ===>  树高 过高（树高 = IO 次数）   ->  IO 多


    4、N叉树       // B+树                矮胖

        1200^3 ≈ 17亿

            root 数据块 总是在内存中，且第二层 也大概率在内存中

            最多只需要 3次 IO   ->   就能查找到 17亿表中的数据

------------------------------------------------------------------------------------------------------------------------
索引模型

    索引在 引擎层实现   ->      不同引擎，实现各不相同，并没有统一规范

------------------------------------------------------------------------------------------------------------------------
InnoDB 的索引模型

    主键索引    ->  整行数据

    普通索引    ->  ID（回表）


    尽量使用主键ID查询：

        普通索引查询  ->  拿到ID   --回表-->   主键索引 获取整行数据


    尽量使用 整型自增主键：

        从性能和存储空间方面考量，自增主键往往是更合理的选择

            bigint -> 8个字节

            主键ID 占用空间越小  ->  非主键索引 占用的空间越小


------------------------------------------------------------------------------------------------------------------------
联合索引

    节省空间    ->  多棵树（多个B+索引树），合并一颗树                       // 索引合并

    回表优化    ->  idx__idCard_name：  根据 id_card -> name  不用回表     // 索引冗余

------------------------------------------------------------------------------------------------------------------------
索引的维护

    页分裂/页合并：

        一个数据页满了

        按照B+Tree算法，新增加一个数据页，叫做页分裂，会导致性能下降      // 新增一层树高  ->  原有树结构 会重新排列

        空间利用率降低大概50%

        当相邻的两个数据页 利用率很低的时候 会做数据页合并，合并的过程 是分裂过程的逆过程


------------------------------------------------------------------------------------------------------------------------
“N叉树”的N值在MySQL中是可以被人工调整的么
              count
    N = ——————————————————
            page size

    1、数据总数一定，页越大，一页存放的索引越多，N越大，树高越低

    2、页大小固定，索引(key值)占用空间越小，存储索引越多，N越大，树高越低


    ------------------------------------------
    1、通过改变key值来调整
        N叉树中非叶子节点存放的是索引信息，索引包含Key和Point指针。
        Point指针固定为6个字节，假如Key为10个字节，那么单个索引就是16个字节。
        如果B+树中页大小为16K，那么一个页就可以存储1024个索引，此时N就等于1024。
        我们通过改变Key的大小，就可以改变N的值
    2、改变页的大小
        页越大，一页存放的索引就越多，N就越大。

------------------------------------------------------------------------------------------------------------------------
索引树的理解：

    每一张表 其实就是几个B+树    // 1个主键树  +  n个普通索引树

        树结点的 key值 就是某一行的主键，value是该行的其他数据

        新建索引 就是新增一个B+树


    查询 走主键索引   ->  就是查询 主键索引B+树

    查询 走普通索引   ->  就是查询 普通索引B+树       ==>  回表 -> 走主键索引

    查询不走索引      ->  就是 遍历主B+树


------------------------------------------------------------------------------------------------------------------------
搜索树

    搜索树 已经很接近 跳表

        跳表 其实就是站在 平衡搜索树的肩膀上 改进而来的


    B+树 类比 跳表  的存、取：

        上层的结点         ->  为了查询 而建立的多级索引

        最底层的 叶子结点   ->  才是 数据(行)

------------------------------------------------------------------------------------------------------------------------
联合索引

    覆盖索引

    最左前缀原则

    索引下推优化











========================================================================================================================
5、锁
========================================================================================================================



========================================================================================================================
6、order by      // 排序
========================================================================================================================




========================================================================================================================
7、高可用、主备、读写分离
========================================================================================================================



========================================================================================================================
8、join
========================================================================================================================



========================================================================================================================
9、临时表
========================================================================================================================



========================================================================================================================
10、InnoDB、Memory
========================================================================================================================





========================================================================================================================
10、自增主键
========================================================================================================================




========================================================================================================================
11、insert 锁
========================================================================================================================




========================================================================================================================
12、复制一张表
========================================================================================================================


========================================================================================================================
13、分区表
========================================================================================================================




