------------------------------------------------------------
基本数据结构与算法           -   基本数据结构
------------------------------------------------------------

1、数据结构 与 算法

    1、广义：

        数据结构    指一组数据的存储结构

        算法        操作数据的一组方法


    2、狭义：

        某些著名的 数据结构和算法

        比如 队列、栈、堆、二分查找、动态规划


2、复杂度分析

    时间复杂度               // 执行时间

        全称是 渐进时间复杂度

        表示 算法的执行时间 与 数据规模 之间的 增长关系

    空间复杂度               // 占用空间

        全称是 渐进空间复杂度

        表示 算法的存储空间 与 数据规模 之间的 增长关系


    --------------------------------
    复杂度：
            也叫 渐进复杂度

        包括：
            时间复杂度 和 空间复杂度

        用来：
            分析 算法执行效率 与 数据规模 之间的 增长关系

        可以粗略地表示：

            越 高阶 复杂度的算法，执行效率越 低


        常见的复杂度并不多，从低阶到高阶有：

            O(1)、O(logⁿ)、O(n)、O(nlogⁿ)、O(n²)

            - 几乎所有的 数据结构和算法 的复杂度 都跑不出这几个


3、数组 和 链表

    1、可以说 最原始的数据结构 就2个：

        数组
            通过索引，前后串联           // 内存连续，一次性申请固定连续内存，拿到base_address，然后基于此做递增的 寻址计算  ->  索引

                                                // a[i]_address = base_address + i * data_type_size

                                                // ==> 拿到base_address时，每个索引位的 内存地址值 就已经确认了  -> 寻址公式 唯一的变量只剩 index

        链表
            通过指针，前后串联           // 内存不连续，寻址公式条件不存在  -->  无索引，前后通过 地址指针 连接


    2、其他数据结构，不过是基于 数组、链表 的二次封装，或 二者的组合：

        队列      // 数组、链表

        栈        // 数组、链表

        散列表     // 数组、链表


        二叉树、堆、图...         // 数组、链表



4、数据结构 用途：          // 存 + 取

    存
        插入、删除

    取
        查询



5、线性 与 非线性       // 一维 、 多维

    线性              // 一维

        数组、链表、队列、栈...


    非线性            // 二维、图...

        二叉树、堆、图


----------------------------------------------------------------------
6、查询 与 插删                           // 时间 、 空间

    1、底层基础：

        1、查：

            基于 数组索引  的 O(1) 查询：                         // 查：O(1)   、  插删：O(n)

                内存连续 -> 寻址公式，支持索引 -> 随机访问


        2、插、删：

            基于 链表 的 O(1) 插删：                             // 查：O(n)   、  插删：O(1)

                内存不连续  ->  无"位置"一说  ->  只需变更前后元素 指针 指向          // 双向链表 应用更广泛  ->  记录有 前后元素



    2、基于 数组和链表 的组合 ———— 实现 快速的 查+插+删：

        查 + 插、删：                  // 空间换时间


            1、散列表                                       // 时间：O(1)   、  空间：O(1)

                数据结构：

                    数组 + 链表（hash冲突）

                查：
                    hash  ->  index  ->  链表遍历

                维护：

                    hash冲突，链表维护

                区间查：

                    无序 -> 不支持 区间查找

            2、跳表                                        // 时间：O(logn)   、  空间：O(logn)

                数据结构：

                    链表 + 索引

                空间：
                    多级索引

                查：
                    二分查找

                维护：
                    索引维护，复杂度上升

                区间查：

                    有序 -> 支持 区间查找



            3、二叉树






            4、红黑树                                       // 时间：O(logn)   、  空间：O(logn)

                数据结构：








        跳表、红黑树      查、插、删    ->  时间 O(logn)     空间 O(n)

            1960s   红黑树
            1970s   B+树
            1990s   跳表          后发优势 ==>  实现简单         // 动态数据结构，实现不会简单到哪去，但是比起红黑树，还是要简单的多



------------------------------------------------------------------------------------------------------------------------
7、散列表



------------------------------------------------------------------------------------------------------------------------
8、跳表            // 动态 + 高效 + 相对简单   ->   O(logn)    -->   1990s   最新提出的（替代 红黑树、B+树） 高效 插、删、查  动态数据结构

    结构：
        链表 + 多级索引

    时间复杂度：

        原始链表    ->      O(n)

        跳表       ->      O(logn)

    查询：

        每一级索引 都最多只需要遍历 3 个

            O(m*logn)    ->    O(3logn)    ->     O(logn)

    空间换时间：

        存储多级索引，肯定要 消耗更多的存储空间：

            建立 多级索引    ->      查询 效率的提升


        内存占用：

            实际上，在软件开发中，我们 不必太在意 索引占用的额外空间。

            在讲数据结构和算法时，我们习惯性地把要处理的数据 看成整数，

            但是在实际的软件开发中，原始链表中存储的有可能是很大的对象，

            而索引结点只需要存储关键值和几个指针，并不需要存储对象，

            所以当对象比索引结点大很多时，那索引占用的额外空间就可以忽略了


        空间复杂度：

            O(n)

                n/2 + n/4 + n/8 + ... + 8 + 4 + 2    --->    n-2      ->      O(n)


                    2 个抽取 1个 建立索引    ->    n   个

                    3 个抽取 1个 建立索引    ->    n/2 个

    高效的动态 插入和删除：

        单链表     ->      先遍历[ 链表挨个遍历   ->  O(n)    ]  ，  再插、删         ->      O(n)

        双向链表   ->      O(1)

        跳表      ->      先遍历[  索引查找      ->   O(logn) ] ，  再插、删         ->      O(logn)


            跳表索引动态更新：           // 索引 动态维护

                如果 被删元素 为索引，则需同步删除                                              ->  额外做功

                如果 新插入 过多元素，则需同步动态更新索引，防止链表退化（退化趋近 -> 单链表）       ->  额外做功


                ---------------------
                作为一种动态数据结构，我们需要某种手段 来维护 索引与原始链表大小 之间的平衡，

                也就是说，如果链表中结点多了，索引结点就相应地增加一些，

                避免复杂度退化，以及查找、插入、删除操作性能下降。


    “平衡性”：

        跳表                    ->      随机函数

            随机函数：

                来决定将这个结点插入到哪几级索引中

                从概率上来讲，能够保证 跳表的索引大小和数据大小 平衡性，不至于性能过度退化


                // 跳表更加灵活，可以通过改变 索引构建策略，有效平衡 执行效率 和 内存消耗


        平衡二叉树               ->      左右旋

            左右旋：

                红黑树、AVL 树




    应用：

        Redis 的 有序集合（Sorted Set）：

            1、插、删、查       ->  O(logn)

            2、有序

            3、区间查找         ->  O(logn)

                定位 区间的起点    ->   O(logn)
                因为有序
                然后在原始链表中 顺序往后遍历 就可以了


    跳表 VS 红黑树：

        红黑树：

            1、插入、删除、查找    ->  O(logn)

            2、有序

            劣势：

                1、区间查找     no    ->  红黑树的效率 没有 跳表高

                2、实现超复杂

                3、出现的早，历史悠久，先发优势  ->  市场占有还是比较高     ->   很多编程语言中的 Map 类型都是通过红黑树来实现的





------------------------------------------------------------------------------------------------------------------------
9、树                             // 树、二叉树、二叉搜索树、平衡二叉搜索树、红黑树、B+树、递归树

    1、树的 基本定义：


        树 节点：

            根节点

                没有父节点的节点

            父节点

            子节点

            叶子节点

                没有子节点的节点

            兄弟节点


        树 属性：

            高度（Height）

                下 -> 上              0 开始

            深度（Depth）

                上 -> 下              0 开始

            层（Level）

                上 -> 下              1 开始




    2、二叉树               // 最常用 的树                   时间：O(n)


        1、基本定义：

            节点：

                每个节点  最多 两个“叉”

                    左子节点 和 右子节点

            分类：

                1、普通二叉树


                2、满二叉树                                // 满二叉树 又是 完全二叉树  的一种特殊情况

                    每个节点都有 左右两个子节点

                3、完全二叉树

                    最后一层的叶子节点 都靠左排列


        2、存储：

            1、链式 存储法                     // 常用  -> 大部分二叉树   都是通过 链式存储 来实现的

                基于 指针或引用  的  二叉链式存储法


                每个节点有三个字段：

                    data

                        存储数据

                    left、right                  // 空间换时间        ->  额外存储 左右子节点 指针

                        指向左右子节点的 指针


            2、数组 顺序存储法                    // 适用 -> 完全二叉树        ===>  仅浪费 0号位

                基于 数组 的顺序存储法

                    1、完全二叉树：

                        根节点      ->  数组下标 1 开始          // 仅“浪费” 1个 下标为0 的存储位置

                        左子节点        2i             // i 为父节点 索引位  -->  初始根节点 从 i=1 开始
                        右子节点        2i + 1


                        优点：

                            1、仅“浪费” 1个 下标为0 的存储位置：

                                如果某棵二叉树是一棵 完全二叉树

                                那用数组存储 无疑是最节省内存的一种方式


                            2、数组的存储方式 不需要像 链式存储法那样，要 存储额外的 左右子节点的指针

                                这是 完全二叉树 单独拎出来的原因

                                也是 完全二叉树要求 最后一层的子节点都靠左 的原因


                    2、非完全二叉树

                        会浪费比较多的 数组存储空间



        3、遍历（查找）：               // 前、中、后序  ->  节点 与 左右子节点  遍历打印的 先后顺序


            1、如何将 所有节点 都遍历打印出来

                1、前序遍历

                    节点  ->  左  ->  右

                2、中序遍历

                    左  ->  节点  ->  右

                3、后序遍历

                    左  ->  右  ->  节点


            2、递归：

                1、前序遍历的递推公式：

                    preOrder(r) = print r  ->  preOrder(r->left)  ->  preOrder(r->right)

                2、中序遍历的递推公式：

                    inOrder(r) = inOrder(r->left)  ->  print r  ->  inOrder(r->right)

                3、后序遍历的递推公式：

                    postOrder(r) = postOrder(r->left)  ->  postOrder(r->right)  ->  print r



                实际上，二叉树的 前、中、后序遍历 就是一个递归的过程

                    写递推公式的关键就是

                        如果要解决问题 A，就假设子问题 B、C 已经解决

                        然后再来看如何利用 B、C 来解决 A


            3、时间复杂度

                O(n)

                查看 前、中、后序遍历 的顺序图，可以看出来

                    每个节点最多会被访问两次

                    所以遍历操作的时间复杂度，跟节点的个数 n 成正比

                    也就是说 二叉树遍历 的时间复杂度是 O(n)




    3、二叉查找树         // 快速 查找、插入、删除           ======>  最常用的 二叉树     --->  理想情况下（平衡二叉查找树）  ->  时间： O(logn)

        优点：
            支持 动态数据集合的  快速 查找、插入、删除  操作


        其他操作：

            快速查找 最大节点、最小节点、前驱节点、后继节点

        支持重复数据：

            key冲突：

                1、链表 / 支持动态扩容的 数组

                2、把这个新插入的数据 当作 大于这个节点的值 来处理

        时间复杂度分析：

            跟树的 高度 成正比          -->     O(height)


            1、最糟糕

                退化成了链表                      ->      O(n)

                    极度 不平衡的 二叉查找树

            2、最理想

                完全二叉树（满二叉树）              ->     O(logn)

                    极度 平衡的 二叉查找树


            平衡二叉查找树：            //   稳定的  O(logn)

                高度接近 logn

                    插入、删除、查找  时间复杂度  都比较稳定    -->  O(logn)


                不管怎么删除、插入数据，在任何时候，

                都能保持 任意节点左右子树 都比较平衡的 二叉查找树



    4、平衡二叉查找树           // 理想情况下的  二叉查找树

        平衡二叉树：

            二叉树中 任意一个节点的  左右子树的高度相差  不能大于 1

        平衡二叉查找树：

            1、不仅满足  平衡二叉树   的定义

            2、还满足    二叉查找树  的特点



        发明 平衡二叉查找树 这类数据结构的 初衷是：

            解决普通二叉查找树在频繁的 插入、删除 等动态更新的情况下，出现 时间复杂度退化 的问题


        平衡二叉查找树 中 “平衡”的意思：

            其实就是让整棵树左右看起来比较“对称”、比较“平衡”，

            不要出现左子树很高、右子树很矮的情况

            这样就能让 整棵树的高度 相对来说低一些，相应的 插入、删除、查找 等操作的 效率高一些



            没必去死抠定义

                “平衡”

                    可以等价为 性能不退化

                “近似平衡”

                    等价为 性能不会退化得太严重


                很多 平衡二叉查找树 并没有严格符合上面的定义

                    红黑树

                        它从根节点到各个叶子节点的 最长路径，有可能会比 最短路径 大一倍


        合格的 平衡二叉查找树：

            只要 树的高度 不比 logn 大很多（比如 树的高度 仍然是 对数量级 的）



        常用：

            红黑树、Splay Tree（伸展树）、Treap（树堆）



    5、红黑树           // 平衡二叉查找树  的一种             ->  甚至默认  平衡二叉查找树 就是 红黑树


        1、近似平衡

            性能不会退化得太严重

            红黑树的高度  比较稳定地 趋近 logn

        2、优势：

            红黑树只是做到了 近似平衡，并不是严格的平衡

                所以在 维护平衡的成本上，要比 AVL 树要低

                所以，红黑树的 插入、删除、查找 各种操作 性能都比较稳定

            对于工程应用来说，要面对各种异常情况

                为了支撑这种工业级的应用，我们更倾向于这种 性能稳定的 平衡二叉查找树


        3、红黑树 结构：

            1、红黑树中的节点

                一类被标记为黑色，一类被标记为红色

            2、一棵红黑树：

                1、根节点是黑色的；

                2、每个叶子节点都是黑色的空节点（NIL），也就是说，叶子节点不存储数据；

                3、任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的；

                4、每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点；


        4、总结：


            1、稳定高效：

                红黑树是一种 平衡二叉查找树

                它是为了解决 普通二叉查找树在数据更新的过程中，复杂度退化 的问题而产生的

                红黑树的 高度近似 log2n，所以它是 近似平衡，插入、删除、查找 操作的时间复杂度都是 O(logn)


            2、工程应用：         // 动态 -> 插入、删除、查找

                因为红黑树是一种性能非常稳定的二叉查找树，

                所以，在工程中，但凡是用到 动态插入、删除、查找 数据的场景，都可以用到它


            3、实现复杂：         // 稳定、高效   ->    实现起来 实在太难   =====>   跳表 替代

                不过，它实现起来比较复杂，如果自己写代码实现，难度会有些高

                这个时候，我们其实更倾向用 跳表 来替代它



    6、递归树


        递归的思想：

            将大问题分解为小问题来求解，然后再将小问题分解为小小问题

            这样一层一层地分解，直到问题的数据规模被分解得足够小，不用继续递归分解为止


        应用：

            借助 递归树 来分析 递归算法的时间复杂度



    7、B+树


    8、堆

        结构：

            完全二叉树

        分类：

            大顶堆、小顶堆

                每个节点的值  都  大于等于（或小于等于）  其子树节点的值


        两个操作：

            插入 一个数据      ->      O(logn)

            删除 堆顶元素      ->      O(logn)


        堆排序：

            1、建堆

            2、排序









-----------------------
散列表 VS  平衡二叉搜索树：        // 快速 插、删、查

    散列表：

        O(1)

        扩缩容、散列冲突    ->      性能不稳定       =====>   实际应用中，性能也不一定会比  平衡二叉搜索树  好

        无序  ->  不支持 区间查找

    二叉查找树：

        有序  ->  区间查找




    查找不光是查找某一个值，还会查找一个特定的范围，这在散列表里面就不一定适用了。

    类似 B+树 之类的，只在叶子节点保存数据，并且将其用链表连起来。

    散列表在扩缩容的时候，性能不大稳定，

    同时由于散列冲突的存在，虽然散列表的时间复杂度是常数级别的，

    但实际应用中，由于其不稳定，性能也不一定会比平衡二叉搜索树好。


--------------------------

散列表 VS  二叉查找树（平衡二叉查找树  -->  红黑树）

    散列表的 插入、删除、查找 操作的时间复杂度 可以做到常量级的 O(1)，非常高效。

    二叉查找树在 比较平衡 的情况下，插入、删除、查找操作时间复杂度 才是 O(logn)


    相对散列表，好像并没有什么优势，那我们为什么还要用二叉查找树呢？

        1、散列表中的数据是无序存储的，如果要输出有序的数据，需要先进行排序。

            而对于二叉查找树来说，我们只需要中序遍历，就可以在 O(n) 的时间复杂度内，输出有序的数据序列

        2、散列表扩容耗时很多，而且当遇到散列冲突时，性能不稳定

            尽管二叉查找树的性能不稳定，但是在工程中，我们 最常用的 平衡二叉查找树 的性能非常稳定，时间复杂度稳定在 O(logn)

        3、笼统地来说，尽管 散列表 的查找等操作的时间复杂度是 常量级 的

            但因为 哈希冲突 的存在，这个常量不一定比 logn 小，所以实际的查找速度可能不一定比 O(logn) 快

            加上 哈希函数 的耗时，也不一定就比 平衡二叉查找树 的效率高

        4、散列表的构造 比 二叉查找树 要 复杂

            需要考虑的东西很多

                比如 散列函数的 设计、冲突解决办法、扩容、缩容 等

            平衡二叉查找树只需要考虑

                平衡性 这一个问题，而且这个问题的解决方案比较成熟、固定

            最后，为了避免过多的散列冲突，散列表装载因子不能太大

                特别是基于 开放寻址法 解决冲突的散列表，不然会浪费一定的存储空间



------------------------------------------------------------------------------
散列表、红黑树（平衡二叉查找树）、B+树（多叉树）、跳表         // 动态数据结构       ->      动态 插入、删除        ->      快速 插入、删除、查询


    1、查找、插入、删除：

        O(1)           ->      散列表                  // 基于 数组 的随机访问

        O(logn)        ->      红黑树、B+树、跳表


    2、有序

        有序      ->      红黑树、B+树、跳表

        无序      ->      散列表     // hash值  ->  散列  ->  无序


    3、区间查：

        跳表  >  B+树  >  红黑树

            // 散列表 -> 无序 -> 不支持 区间查


        O(logn)        ->      跳表       // O(logn) 定位到 区间起点 -> 有序 -> 从链表 起点开始往后 遍历即可   ===>  O(logn)

        O(logn)        ->      B+树       // 支持 区间 快速查找

        O(-)        ->      红黑树         // 不足以支持 按照区间 快速查找数据


    4、出现时间（演进过程）：

        红黑树（1960s）  <  B+树（1970s）  <  跳表（1990s）


    5、实现难度

        红黑树  >  B+树  >  跳表

            越晚出现的，自然结构更简单，实现更方便、灵活

            且兼具前人的优势的同时，往往还有其他特性（解决 区间查找）

            站在巨人的肩膀上，后发优势



    6、散列表的劣势

        扩缩容、hash冲突      ->      性能不稳定  ->  实际使用 并不一定 就比  平衡二叉查找树、跳表  快

        hash计算耗时


    ----------------------------
    1、功力 却有高低之分：

        散列表     ->    O(1)              ->      扩缩容、hash冲突、hash计算耗时       ->     不稳定

        红黑树     ->    O(logn)           ->      稳                                 ->     实现 超级复杂             1960s

        B+树       ->    O(logn)           ->      稳                                 ->     实现 复杂                1970s

        跳表       ->    O(logn)           ->      稳                                 ->     实现相对简单（较 红黑树）  1990s


    3、付出的代价不同：

        时间复杂度 越低     ->      付出的代价 必定越高       ->      稳定性 必然越差

            天下没有完美是事物

                欲戴皇冠，必承其重

                欲练此功，必先自宫

                解决一个问题的同时，会带来十个新问题


    4、跳表 替代 红黑树：

        跳表 出现晚于 红黑树，后发优势：

            性能近似，而实现简单


        跳表出现后，O(logn)场景下，多以 跳表 -> 红黑树：

            特别是 自己要实现一个 O(logn) 的 高效数据结构 时：

                Redis
                    Redis 中的 有序集合（Sorted Set）   ->      跳表













