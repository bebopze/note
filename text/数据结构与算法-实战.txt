1、剖析Redis常用数据类型对应的数据结构

    Redis 中，键的数据类型是字符串，但是值的数据类型有很多，常用的数据类型是：字符串、列表、字典、集合、有序集合


    1、字符串（string）

        值是一个字符串

        实现：

            散列表

                值为字符串的键值对，是通过hash实现的，将 键转换成index 存储在 hash表 中


    2、列表（list）

        支持存储 一组数据

        两种实现：

            1、压缩列表（ziplist）

                当列表中存储的 数据量比较小 时，可以采用 压缩列表 的方式实现

                    需要同时满足下面两个条件：
                        1、列表中保存的单个数据（可能是字符串类型的）小于 64 字节
                        2、列表中数据个数少于 512 个

            2、双向循环链表


        关于压缩列表
            1、它并不是基础数据结构，而是 Redis 自己设计的一种数据存储结构
            2、类似数组，通过一片 连续的内存空间 来存储数据
            3、跟数组不同的是 它允许 存储的数据大小不同


        压缩列表中的“压缩”如何理解？

            “压缩”：就是节省内存，之所以说节省内存，是 相较于数组 的存储思路而言的

                数组要求每个元素的大小相同，如果要存储不同长度的字符串，就需要用最大长度的字符串大小作为元素的大小
                但 压缩数组 允许 不同的存储空间

            1、压缩列表这种存储结构，另一方面可以支持不同类型数据的存储
            2、数据存储在一片连续的内存空间，通过键来获取值为列表类型的数据，读取的效率也非常高



        压缩列表 不支持 随机访问
            有点类似链表，但是比较省存储空间
            Redis一般都是通过key获取整个value的值，也就是 整个压缩列表 的数据，并不需要随机访问


        利用 CPU 缓存
            在数据量少时会采用ziplist数据结构，由于数据量少，可以利用CPU缓存（L2 缓存）


    3、字典（hash）

        用来存储 一组 数据对，每个 数据对 又包含 键值 两部分


        两种实现：

            1、压缩列表

                同样，只有当存储的数据量比较小的情况下，Redis 才使用压缩列表来实现字典类型

                    具体需要满足两个条件：
                        1、字典中保存的键和值的大小都要小于 64 字节
                        2、字典中键值对的个数要小于 512 个

            2、散列表

                当不能同时满足上面两个条件的时候，Redis 就使用散列表来实现字典类型
                    * Redis 使用 MurmurHash2 这种运行速度快、随机性好的哈希算法作为哈希函数
                    * 对于 哈希冲突，Redis 使用 链表法 来解决
                    * 除此之外，Redis 还支持散列表的 动态扩容、缩容

                        当数据动态增加，装载因子会不停地变大，为了避免散列表性能的下降：
                            当装载因子大于 1 的时候，Redis 会触发扩容，将散列表扩大为原来大小的 2 倍左右（具体值需要计算才能得到）
                            当数据动态减少之后，为了节省内存，当装载因子小于 0.1 的时候，Redis 就会触发缩容，缩小为字典中数据个数的大约 2 倍大小（这个值也是计算得到的）

                        扩容缩容要做大量的 数据搬移 和 哈希值的重新计算，比较耗时。
                        针对这个问题，Redis 使用 渐进式 扩容缩容策略：
                            将数据的搬移 分批 进行，避免了大量数据一次性搬移导致的服务停顿


    4、集合（set）

        用来存储 一组不重复的数据

        两种实现：

            1、有序数组

                Redis 若采用有序数组，要同时满足下面这样两个条件：
                    1、存储的数据都是 整数
                    2、存储的数据元素个数不超过 512 个

            2、散列表


    5、有序集合（sortedset）

        用来存储 一组数据，并且每个数据会 附带一个得分。通过得分的大小，将数据组织成跳表这样的数据结构，以支持快速地按照得分值、得分区间获取数据


        实现：

            1、压缩列表

                当数据量比较小的时候，Redis 可用压缩列表来实现有序集合

                使用的前提有两个：

                    1、所有数据的大小都要 小于 64 字节
                    2、元素个数要 小于 128 个

            2、跳表



    数据结构持久化

        尽管 Redis 经常会被用作内存数据库，但它也支持将内存中的数据存储到硬盘中
        当机器断电的时，存储在 Redis 中的数据不会丢失

        Redis 的数据格式由“键”和“值”两部分组成
        而“值”又支持很多数据类型，像字典、集合等类型，底层用到了散列表，散列表中有 指针 的概念，而 指针 指向的是 内存中的存储地址


            Redis 是如何将一个跟具体内存地址有关的数据结构存储到磁盘中的？

                1、Redis 遇到的这个问题被称为数据结构的持久化问题，或者对象的持久化问题
                2、将数据结构持久化到硬盘主要有两种解决思路：

                    1、第一种是清除原有的存储结构，只将数据存储到磁盘中
                        （1）当需要从磁盘还原数据到内存时，再重新将数据组织成原来的数据结构。Redis 采用的就是这种持久化思路。
                        （2）这种方式有一定的弊端：数据从硬盘还原到内存的过程，会耗用比较多的时间

                    2、第二种方式是保留原来的存储格式，将数据按照原有的格式存储在磁盘中

                        如 散列表
                            我们可以将散列表的大小、每个数据被散列到的槽的编号等信息，都保存在磁盘中
                            有了这些信息，我们从磁盘中将数据还原到内存中的时候，就可以 避免 重新计算哈希值



2、剖析搜索引擎背后的经典数据结构和算法

    整体系统介绍搜索引擎可以分为四个部分：搜集、分析、索引、查询。
        * 搜集：就是利用爬虫爬取网页
        * 分析：主要负责网页内容抽取、分词，构建临时索引，计算 PageRank 值这几部分工作
        * 索引：主要负责通过分析阶段得到的临时索引，构建倒排索引
        * 查询：主要负责响应用户的请求，根据倒排索引获取相关网页，计算网页排名，返回查询结果给用户



    搜集

        * 搜索引擎把整个互联网看作数据结构中的有向图，把每个页面看作一个顶点。如果某个页面中包含另外一个页面的链接，就在两个顶点之间连一条有向边。可以利用图的遍历搜索算法，来遍历整个互联网中的网页。
        * 搜索引擎采用的是广度优先搜索策略。
        * 权重比较高的链接，作为种子网页链接，放入到队列中
        * 爬虫按照广度优先的策略，不停地从队列中取出链接，取爬取对应的网页，解析出网页里包含的其他网页链接，再将解析出来的链接添加到队列中。

        1. 待爬取网页链接文件：links.bin
            * 在爬取页面的过程中，爬虫会不停地解析页面链接，将其放到队列中
            * 队列中的链接存储在磁盘中的文件（links.bin）。爬虫从 links.bin 文件中，取出链接去爬取对应的页面。等爬取到网页之后，将解析出来的链接，直接存储到 links.bin 文件中。
            * 文件来存储支持断点续爬

        2. 网页判重文件：bloom_filter.bin
            * 使用布隆过滤器，可以快速且非常节省内存地实现网页的判重，避免重复爬取相同的网页
            * 要定期地将布隆过滤器持久化存储到磁盘bloom_filter.bin 文件中，避免机器重启后，布隆过滤器被清空
            * 当机器重启之后，重新读取磁盘中的 bloom_filter.bin 文件，将其恢复到内存中

        3. 原始网页存储文件：doc_raw.bin
            * 爬取到网页之后，需要将其存储下来，以备后面离线分析、索引之用
            * 把多个网页存储在一个文件中，每个网页之间，通过一定的标识进行分隔，方便后续读取
            * 每个文件的大小不能超过一定的值（比如 1GB），因为文件系统对文件的大小也有限制。

        4. 网页链接及其编号的对应文件：doc_id.bin
            * 网页编号是给每个网页分配一个唯一的 ID，方便后续对网页进行分析、索引
            * 每爬取到一个网页之后，就从一个中心的计数器中拿一个号码，分配给这个网页
            * 在存储网页的同时，将网页链接跟编号之间的对应关系，存储在一个 doc_id.bin 文件中


    分析

        分析阶段两个步骤（1）抽取网页文本信息，（2）分词并创建临时索引
            1. 抽取网页文本信息
                * 网页是半结构化数据，要从半结构化的网页中，抽取出搜索引擎关系的文本信息

                这个抽取的过程分为两步
                    1、去掉 JavaScript 代码、CSS 格式以及下拉框中的内容
                        * 利用 AC 自动机这种多模式串匹配算法将<style>, <script>, <option>标签包裹的字符删除
                    2、去掉所有 HTML 标签，这过程跟第一步类似

            2. 分词并创建临时索引
                * 从网页中抽取出了文本信息，要对文本信息进行分词，并且创建临时索引
                * 中文分词比较复杂太多了，可以基于字典和规则的分词方法


    字典也叫词库，里面包含大量常用的词语。借助词库并采用最长匹配规则，来对文本进行分词。所谓最长匹配，也就是匹配尽可能长的词语。

        * 具体到实现层面，将词库中的单词，构建成 Trie 树结构，然后拿网页文本在 Trie 树中匹配
        * 网页的文本信息在分词完成后，得到一组单词列表。把单词与网页之间的对应关系，写入到一个临时索引文件中（tmp_Index.bin），这个临时索引文件用来构建倒排索引文件

        * 临时索引文件中存储的是单词编号，这样做是为了节省存储的空间。给单词编号的方式，跟给网页编号类似
        * 这个过程中使用散列表记录已经编过号的单词。对分词的先到散列表中查找，如果找到那就直接使用；如果没有找到，再去计数器中拿号码，并将这个新单词以及编号添加到散列表中

    当所有的网页处理（分词及写入临时索引）完成之后，再将单词跟编号之间的对应关系写入到磁盘文件中，并命名为 term_id.bin


    索引

        索引阶段主要负责将分析阶段产生的临时索引，构建成倒排索引
        倒排索引（ Inverted index）中记录了每个单词以及包含它的网页列表


    那如何通过临时索引文件，构建出倒排索引文件？
        考虑到临时索引文件很大，无法一次性加载到内存中，搜索引擎一般会选择使用多路归并排序的方法来实现
        先对临时索引文件，按照单词编号的大小进行排序
        因为临时索引很大，可以用归并排序的处理思想，将其分割成多个小文件，先对每个小文件独立排序，最后再合并在一起




3、剖析高性能队列Disruptor背后的数据结构和算法

    Disruptor

        是一种内存消息队列，功能上类似 Kafka， 不同的是 Disruptor 是线程之间用于消息传递的队列

    广泛应用：

        Apache Storm、Camel、Log4j2

    最快的内存消息队列：

        它的性能表现非常优秀，
        比 Java 中另一个非常常用的内存消息队列 ArrayBlockingQueue（ABS）的性能，要高一个数量级，
        可以算得上是最快的内存消息队列


    Disruptor 是如何做到如此高性能的？其底层依赖了哪些数据结构和算法？

        基于 循环队列 的 “生产者 - 消费者” 模型

            “生产者 - 消费者” 模型
                “生产者” 生产数据，并且将数据放到一个中心存储容器中
                “消费者” 从中心存储容器中，取出数据消费


        队列：
            实现 中心存储容器 的数据结构是队列
            队列支持数据的先进先出，使得数据被消费的顺序性可以得到保证


    队列有两种实现思路：

        1、基于 链表 实现的 链式 队列

        2、基于 数组 实现的 顺序 队列


        如果实现一个无界队列，适合选用链表来实现队列，因为链表支持快速地动态扩容

        相较于无界队列，有界队列的应用场景更加广泛
            机器内存是有限的，无界队列占用的内存数量是不可控的，有可能因为内存持续增长，而导致 OOM（Out of Memory）错误

    循环队列是一种特殊的顺序队列
        非循环的顺序队列在添加、删除数据时涉及数据的搬移操作，导致性能变差。
        而循环队列可以解决数据搬移问题，所以性能更加好。所以大部分用顺序队列中的循环队列。


    循环队列这种数据结构，就是 内存消息队列 的雏形


    基于加锁的并发“生产者 - 消费者模型”

        在多个生产者或者多个消费者并发操作队列的情况下，主要会有下面两个问题：
            1、多个生产者写入的数据可能会互相覆盖
            2、多个消费者可能会读取重复的数据


        最简单的处理方法就是给代码加锁，同一时间只允许一个线程执行 add() 函数，由并行改成了串行



    Disruptor 的基本思想是 换了一种队列 和 “生产者 - 消费者模型” 的实现思路

        * 生产者：
            往队列中添加数据之前，先批量地申请连续的 n 个（n≥1）可用空闲存储单元。
            这组存储单元是这个线程独享的，后续往队列中添加元素可以不用加锁了。
            申请存储单元的过程是需要加锁的

        * 消费者：
            处理的过程跟生产者是类似的。
            先申请一批连续可读的存储单元（申请的过程也是要加锁），
            当申请到这批存储单元之后，后续的读取操作就不加锁


    * Disruptor 实现思路的 弊端：

        如果生产者 A 申请到了一组连续的存储单元，
        假设是下标为 3 到 6 的存储单元，生产者 B 紧跟着申请到了下标是 7 到 9 的存储单元，
        在 3 到 6 没有完全写入数据之前，7 到 9 的数据是无法读取的


    * Disruptor 采用的数据结构：

        RingBuffer 和 AvailableBuffer



    总结引申

        1、多个生产者同时往队列中写入数据时，存在数据覆盖的问题。多个消费者同时消费数据，会存在消费重复数据的问题
        2、为了保证逻辑正确，尽可能地提高队列在并发情况下的性能，Disruptor 采用了“两阶段写入”的方法。
        3、在写入数据之前，先加锁申请批量的空闲存储单元，之后往队列中写入数据的操作就不需要加锁了，写入的性能因此就提高了
        4、Disruptor 对消费过程的改造，跟对生产过程的改造是类似的。
            它先加锁申请批量的可读取的存储单元，之后从队列中读取数据的操作也就不需要加锁了，读取的性能因此也就提高了




4、剖析微服务接口鉴权限流背后的数据结构和算法




5、用数据结构和算法实现一个短网址系统



