----------------------------------------------------------------------------------------------------
2、基础
----------------------------------------------------------------------------------------------------
10 个 数据结构：  数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树
10 个 算法   ：   递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法
------------------------------------------------------------------------------------------------------------------------


------------------------------------------------- 数据结构 --------------------------------------------------------------

1、数组                            // 线性表、下标、连续内存空间、相同类型数据、随机访问

    定义：
        数组（Array）是一种 线性表 数据结构。它用一组 连续的内存空间 ，来存储一组具有相同类型的数据

    最基础的数据结构：

        每一种编程语言中，基本都会有 数组 这种数据类型

    线性 与 非线性

        线性表
            数据排成 像一条线 一样的结构，每个线性表上的数据 最多只有 前和后 两个方向

            应用：
                数组、链表、队列、栈

        非线性表
            在非线性表中，数据之间并 不是 简单的前后关系

            应用：
                二叉树、堆、图


    连续的内存空间 和 相同类型的数据：

        优点：随机访问     ->  快速 查

                下标 ->  寻址公式   -> 直接定位      ->  O(1)

        缺点：增、删       ->  低效 插删

                为了保证 连续性    ->  需要做大量的 数据搬移 工作


    数组 和 链表 的区别：

        数组 支持 随机访问，根据下标随机访问 的时间复杂度为 O(1)

        链表 适合插入、删除，时间复杂度 O(1)


    随机访问：

        计算机读取数据：

            计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据.

            随机访问数组中的某个元素时，通过寻址公式，计算出该元素存储的内存地址：

                a[i]_address = base_address + i * data_type_size

                    ->   data_type_size ：数组元素类型的大小          int -> 4个字节


    低效的“插入”和“删除”：

        插入：
            尾插：O(1)     头插：O(n)     平均：O(n)

        删除：
            尾删：O(1)     头删：O(n)     平均：O(n)

            JVM 标记清除 垃圾回收算法：
                每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。
                当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作。

    容器：

        ArrayList                   // 对 数组操作 的封装

            1、封装数组操作：

                数组 插、删（指定index位 add/remove） -->  数据搬移

            2、动态扩容

                也是一种封装

                扩容耗时 -> 预先指定合理大小

    数组场景：
        1、基本类型
        2、预知数组大小
        3、多维数组

        4、底层开发  ->  追求极致性能

            业务开发 -> 容器  -> 便利


    数组下标从0开始：

        最主要：
            历史原因        ->      C 语言  -> “始作俑者”

        数组内存模型

            “下标” ->  “偏移（offset）”

            寻址公式：
                0开始     ->     a[k]_address = base_address + k * type_size
                1开始     ->     a[k]_address = base_address + (k-1) * type_size      ->  每次寻址  多一次 k-1 运算


    扩展：

        JVM标记清除算法：

            大多数主流虚拟机采用可达性分析算法来判断对象是否存活，
            在标记阶段，会遍历所有 GC ROOTS，将所有 GC ROOTS 可达的对象标记为存活。
            只有当标记工作完成后，清理工作才会开始。

            不足：
                1.效率问题
                    标记和清理效率都不高，但是当知道只有少量垃圾产生时会很高效

                2.空间问题
                    会产生不连续的内存空间碎片

        二维数组内存寻址：

            对于 m * n 的数组，a[i] [j] (i < m,j < n)的地址为：

                address = base_address + ( i * n + j) * type_size



2、链表                            // 非连续 的内存空间、指针、插删


    不连续 的内存空间

        数组：     申请100M  ->  剩余内存150M，但无连续的100M   ->  申请失败

        链表       指针     ->  一组零散的内存块               ->  串联


    3种链表结构：

        1、单链表

            data+next  ->   data+next  ->   ...  ->  data + NULL

            随机 插、删       O(1)
            随机 查          O(n)



        2、双向链表                          // 更高效  ->  应用更广   ->   空间 换 时间

            prev+data+next  ->   prev+data+next  ->   ...  ->  prev+data + NULL

            用空间换时间：

                删   ->   要知道其 前+后 节点


                    1、给定值           ==>  先查 -> 再删

                        先遍历查 O(n)   ->  删

                        单、双  无区别   ->  O(n)


                    2、给定地址值

                        双   ->   元素     ->      记录有 前后指针   ->  删                           ->   O(1)

                        单   ->   元素     ->      未记录 前指针     ->  从头遍历   ->   删            ->   O(n)

            应用：
                LinkedHashMap



        3、循环链表

            特殊的单链表          ->      环形 链表


        双向 + 循环 --> 双向循环 链表



    数组 VS 链表：

        数组
            简单易用，连续的内存空间 -> 可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高

            大小固定，一经声明就要占用整块连续内存空间   ->  “动态”扩容 -> 申请新的内存空间 -> 拷贝

        链表
            在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读

            链表本身没有大小的限制，天然地支持 动态扩容



    应用场景     LRU 缓存淘汰算法                                              // 常用策略 -> FIFO、LFU、LRU

            - 最近最少使用策略 LRU（Least Recently Used）




    -------------------

    “指针”/“引用”

        一个意思，都是 存储所指对象 的 内存地址

        将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针，
        或者反过来说，指针中存储了这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量


        p->next=q
            p结点 中的 next指针  存储了 q结点 的内存地址

        p->next=p->next->next
            p结点 的 next指针  存储了 p结点 的 下下一个节点 的内存地址



    head == null

        哨兵  ->  解决“边界问题”的，不直接参与业务逻辑


3、栈                         // 一端、后进先出、先进后出、进栈、出栈

    “栈”结构
        后进者先出，先进者后出             ===>    放盘子 -> 取盘子

    场景：
        当某个数据集合 只涉及在一端 插入和删除 数据，并且满足 后进先出、先进后出 的特性      ->  首选：“栈”

    阉割版 的 数组/链表

        栈是一种“操作受限”的线性表

            - 只支持两种基本操作：入队 和 出队


            功能上：数组/链表 完全可以实现 “栈”的操作

            可控性：数组/链表 暴露了太多操作接口     ->  不可控 -> 出错


    应用：
        函数调用栈

        表达式求值

        括号匹配

        浏览器前进和后退


    为什么 函数调用 要用 “栈” 来保存临时变量呢？用其他数据结构不行吗？

        其实，我们 不一定非要用 栈 来保存 临时变量，只不过如果这个函数调用 符合 后进先出 的特性，用 栈 这种数据结构 来实现，是 最顺理成章 的选择。

        从调用函数进入被调用函数，对于数据来说，变化的是什么呢？ 是 作用域。
        所以根本上，只要能保证每进入一个新的函数，都是一个新的作用域就可以。
        而要实现这个，用栈就非常方便。
        在进入被调用函数的时候，分配一段栈空间给这个函数的变量，在函数结束的时候，将栈顶复位，正好回到调用函数的作用域内。



4、队列                            // 先进先出、尾进头出、入队、出队

    “队列”结构：
        先进先出

    有限操作：

        入队 enqueue()    ->      放一个数据到队列尾部

        出队 dequeue()    ->      从队列头部取一个元素


    阉割版 的 数组/链表

        “操作受限”的 线性表 数据结构

        只支持两种基本操作：入队 和 出队


    顺序队列 和 链式队列

    循环队列
        消除 “数据搬移”

    应用：
        阻塞队列
            生产者 - 消费者

        并发队列
            基于数组的循环队列，利用 CAS 原子操作，可以实现非常 高效的 并发队列。

            这也是 循环队列 比 链式队列 应用更加广泛 的原因


    资源有限场景

        基于阻塞 -> 请求排队

            阻塞队列

        非阻塞 -> 直接拒绝

    -----------------
    队列也是一种“操作受限”的线性表，只支持两种基本操作：入队和出队。

    队列的应用非常广泛
        特别是一些具有某些额外特性的队列，比如 循环队列、阻塞队列、并发队列。
        它们在很多偏底层的系统、框架、中间件的开发中，起着关键性的作用。
        比如 高性能队列 Disruptor、Linux 环形缓存，都用到了循环并发队列；Java concurrent 并发包利用 ArrayBlockingQueue 来实现公平锁等。

    关于如何实现无锁并发队列

        Disruptor

            使用 cas + 数组 的方式实现


    队列的其他应用
        分布式消息队列，如 kafka 也是一种队列


5、跳表（Skip List）                         // 快速 插/删/查 -> O(logn) 、 动态 数据结构 、 红黑树

    跳表
        链表 加 多级索引 的结构

    Redis

    索引层   ->    跳

        空间 换 时间

        索引结点只需要存储关键值和几个指针，并不需要 存储对象   ->  额外空间可以忽略

        复杂度   ->   索引维护


    总结：
        跳表使用 空间换时间 的设计思路

            通过构建 多级索引 来提高查询的效率

            实现了基于链表的“二分查找”

        跳表是一种 动态数据结构

            支持快速地 插入、删除、查找 操作

            时间复杂度 都是 O(logn)

        跳表的空间复杂度是 O(n)

            不过，跳表的实现非常灵活

            可以通过改变索引构建策略，有效平衡执行效率和内存消耗

        虽然跳表的代码实现并不简单，但是作为一种动态数据结构，比起红黑树来说，实现要简单多了。
        所以很多时候，我们为了代码的简单、易读，比起红黑树，我们更倾向用跳表。



6、散列表（Hash Table）                           // 数组、随机访问

    散列表的由来

        散列表 来源于 数组

        它借助 散列函数 对 数组 这种数据结构进行 扩展

        利用的是 数组 支持按照下标 随机访问 元素的特性

    散列函数

        key   ->   hash(key)   ->  value

    装载因子

        装载因子越大，说明散列表中的元素越多，空闲位置越少，散列冲突的概率就越大

    散列冲突

        hash(key) 避免冲突
            几乎不可能           ->  数组的存储空间有限，也会加大散列冲突的概率

        解决方案：

            1、开放寻址法

                线性探测（Linear Probing）
                二次探测（Quadratic probing）
                双重散列（Double hashing）

                优：
                    散列表中的数据都存储在数组中，可以有效地利用 CPU 缓存加快查询速度

                缺：
                    删除数据的时候比较麻烦，需要特殊标记已经删除掉的数据。
                    而且，在开放寻址法中，所有的数据都存储在一个数组中，比起链表法来说，冲突的代价更高。

                场景：
                    据量比较小、装载因子小的时候，适合采用开放寻址    ->   ThreadLocalMap


            2、链表法

                HashMap

                优：
                    链表法对内存的利用率比开放寻址法要高
                    对大装载因子的容忍度更高

                缺：
                    链表法包含指针，序列化起来就没那么容易
                    链表中的结点是零散分布在内存中的，不是连续的，所以对 CPU 缓存是不友好的

                链表要存储指针
                    比较小的对象的存储，是比较消耗内存的，还有可能会让内存的消耗翻倍

                    如果我们存储的是大对象，也就是说要存储的对象的大小远远大于一个指针的大小（4 个字节或者 8 个字节），
                    那链表中指针的内存消耗在大对象面前就可以忽略了

                改进：
                    将链表法中的 链表 改造为其他高效的动态数据结构，比如 跳表、红黑树         // O(n)  ->  O(logn)

                场景：
                    基于链表的散列冲突处理方法 比较适合 存储大对象、大数据量 的散列表，
                    而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表

        应用：
            Word的单词拼写检查
                20W单词 -> 20M内存
                单词word  ->  hash(word)  ->  value   ===>    放到内存散列表中，查询check



7、二叉树

    遍历：     -->     O(n)

        1、前序遍历的递推公式：
            preOrder(r) = print r->preOrder(r->left)->preOrder(r->right)

        2、中序遍历的递推公式：
            inOrder(r) = inOrder(r->left)->print r->inOrder(r->right)

        3、后序遍历的递推公式：
            postOrder(r) = postOrder(r->left)->postOrder(r->right)->print r



    二叉查找树（Binary Search Tree）        ->      常用

        二叉查找树是最常用的一种二叉树，它支持快速 插入、删除、查找 操作
        各个操作的时间复杂度跟树的高度成正比，也就是 O(height)，理想情况下，时间复杂度是 O(logn)

        二叉查找树 可以支持快速地查找最大节点和最小节点，前驱节点和后继节点.
        中序遍历 二叉查找树，可以输出有序的数据序列，时间复杂度是O(n),非常高效。


    完全二叉树
        除了最后一层，其他层的节点个数都是满的，最后一层的节点都靠左排列

        完全二叉树高度小于等于logn
        平衡二叉查找树的高度接近logn，插入，删除，查找的时间复杂度比较稳定，为O(logn)


    散列表 vs 二叉查找树：

        1、散列表是无序存储的，要有序的话，需要先排序， 二叉查找树，只需要中序遍历，就可以在O(n)时间复杂度内，输出有序的数据序列。

        2、散列表扩容耗时多，遇到散列冲突时，性能不稳定，常用的平衡二叉树性能稳定，时间复杂度稳定在O(logn)

        3、一般来说，散列表查找，删除，插入操作的时间复杂度是常量级的。但因哈希冲突的存在，这个常量不一定比logn小，加上哈希函数的耗时，也就未必比平衡二叉查找树的效率高.

        4、散列表构造比二叉查找树要复杂，需要考虑的东西很多。比如散列函数的设计，冲突接近方法，扩容，缩容等.
            平衡二叉查找树只需要考虑平衡性这个问题。

        5、为了避免过多的散列冲突，散列表装在因子不能太大，特别是基于开放寻址法接近冲突的散列表.



    平衡二叉查找树

        红黑树

            红黑树是一种平衡二叉查找树。它是为了解决普通二叉查找树在数据更新的过程中，复杂度退化的问题而产生的。
            红黑树的高度近似 log2n，所以它是近似平衡，插入、删除、查找操作的时间复杂度都是 O(logn)。

            因为红黑树是一种性能非常稳定的二叉查找树，所以，在工程中，但凡是用到动态插入、删除、查找数据的场景，都可以用到它。
            不过，它实现起来比较复杂，如果自己写代码实现，难度会有些高，这个时候，我们其实更倾向用跳表来替代它。


    递归树


8、堆

    堆是一种特殊的树：
        1、堆是一个完全二叉树
            - 完全二叉树要求，除了最后一层，其他层的节点个数都是满的，最后一层的节点都靠左排列
        2、堆中每一个节点的值都必须大于等于（或小于等于）其子树中每个节点的值
            大顶堆、小顶堆



    堆 数据结构

        堆是一种 完全二叉树

        它最大的特性是：
            每个节点的值都 大于等于（或小于等于） 其子树节点的值
            因此，堆被分成了两类，大顶堆 和 小顶堆

        堆中比较重要的两个操作是：
            插入一个数据 和 删除堆顶元素，这两个操作都要用到 堆化

                插入一个数据的时候，我们把新插入的数据放到数组的最后，然后从下往上堆化；
                删除堆顶数据的时候，我们把数组中的最后一个元素放到堆顶，然后从上往下堆化。

                这两个操作时间复杂度都是 O(logn)

        堆的经典应用：

            堆排序
                堆排序包含两个过程：建堆 和 排序
                我们将下标从 2n​ 到 1 的节点，依次进行从上到下的堆化操作，然后就可以将数组中的数据组织成堆这种数据结构。
                接下来，我们迭代地将堆顶的元素放到堆的末尾，并将堆的大小减一，然后再堆化，重复这个过程，直到堆中只剩下一个元素，整个数组中的数据就都有序排列了。


    这种 堆数据结构 和 java内存模型中的 堆内存 有什么关系呢？

        - 完全没关系！！！


    应用场景：

        1、优先级队列

            实现：Java 的 PriorityQueue

            应用：
                1. 合并有序小文件

                2. 高性能定时器

        2、利用堆求 Top K

        3、利用堆 求中位数




9、图

    顶点（vertex）

        图中的 元素 我们就叫做 顶点（vertex）

    边（edge）

        图中的一个顶点可以与任意其他顶点建立连接关系，我们把这种建立的关系叫做边（edge）

    度（degree）

        拿微信举例子，每个用户有多少个好友，对应到图中，就叫做顶点的 度（degree），就是 跟顶点相连接的 边的条数

        入度（In-degree）
            顶点的入度，表示有多少条边 指向 这个顶点

        出度（Out-degree）
            顶点的出度，表示有多少条边是以这个顶点为起点 指向 其他顶点

    “有向图”、“无向图”

        微博允许单向关注，A关注B，就画一条从 A 指向 B 的边， A -> B
        边 有方向 的图 叫做“有向图”，边没有方向的图就叫做“无向图”

        微博，入度就表示有多少粉丝，出度就表示关注了多少人

    带权图（weighted graph）

        QQ 亲密度

        在带权图中，每条边 都有一个 权重（weight），我们可以通过这个 权重 来表示 QQ 好友间的亲密度



    广度优先搜索、深度优先搜索：

        是图上的两种最常用、最基本的搜索算法，
        比起其他高级的搜索算法，比如 A*、IDA* 等，要简单粗暴，没有什么优化，所以，也被叫作 暴力搜索算法。
        仅适用于 状态空间不大，也就是说图不大的搜索。

        广度优先搜索，通俗的理解就是，地毯式层层推进，从起始顶点开始，依次往外遍历。
        借助 队列 来实现，遍历得到的路径就是，起始顶点到终止顶点的最短路径。

        深度优先搜索用的是回溯思想，非常适合用递归实现。
        借助 栈 来实现

        在执行效率方面，深度优先和广度优先搜索的时间复杂度都是 O(E)，空间复杂度是 O(V)。



10、Trie 树






---------------------------------------------------- 算法 ---------------------------------------------------------------

1、递归

    陷入“递归”的 思维误区

        这或许就是 计算机思维
        我们很难想象10后面10个0到到底有多大，但是计算机恰好可以
        我们可以把苹果一切两半，但是无法想象切分50次的样子


    为什么使用递归？递归的优缺点？

        优点：代码的表达力很强，写起来简洁。
        缺点：空间复杂度高、有堆栈溢出风险、存在重复计算、过多的函数调用会耗时较多等问题。


    递归常见问题及解决方案
        警惕堆栈溢出：可以声明一个全局变量来控制递归的深度，从而避免堆栈溢出。
        警惕重复计算：通过某种数据结构来保存已经求解过的值，从而避免重复计算。

    递归 改写为 非递归代码

        笼统的讲，所有的递归代码 都可以 改写为 迭代循环 的非递归写法

        因为 递归 本身就是 借助栈 来实现的，只不过我们使用的栈是 系统或者虚拟机本身提供的，我们没有感知罢了。
        如果我们 自己在内存堆上实现栈，手动模拟入栈、出栈过程，这样 任何递归代码 都可以改写成 看上去不是递归代码 的样子。

        具体：
            抽象出递推公式、初始值和边界条件，然后用迭代循环实现

        本质：
            递归     ->   系统栈、虚拟栈
            迭代循环  ->  自己实现一个内存栈

            这种思路实际上是将 递归 改为了 “手动”递归，本质并没有变，
            而且也并没有解决前面讲到的某些问题，徒增了 实现的 复杂度。



2、排序

    O(n²)

        1、冒泡排序（Bubble Sort）                         // 比较、交换        -->     理论

            移位 -> 3 行代码

        2、插入排序（Insertion Sort）                      // 动态排序         -->     应用

            移位 -> 1 行代码         ==>     优于 冒泡


            有些编程语言中的排序函数的实现原理会用到插入排序算法

        3、选择排序（Selection Sort）                      //                 -->     理论




    O(nlogⁿ)

        4、归并排序（Merge Sort）                          // 分治、递归、递推公式、merge() 合并函数、  稳定 -> 空间复杂度 高

            致命“弱点”
                不是 原地排序 算法   ->    空间复杂度 比较 高    ->    O(n)         -> 占内存，用的少


        5、快速排序（Quick Sort）                          // 分治、分区、递推公式、partition() 分区函数

            最坏  ->  O(n²)

            平均  ->  O(nlogⁿ)


            快排核心思想：
                分治 和 分区

            快排的思想：
                如果要排序数组中下标从 p 到 r 之间的一组数据，我们选择 p 到 r 之间的任意一个数据作为 pivot（分区点）


        ---------------------------------
        分治思想

            分治，顾名思义，就是分而治之，将一个大问题分解成小的子问题来解决。小的子问题解决了，大问题也就解决了。

            分治算法一般都是用递归来实现的。

            分治是一种解决问题的处理思想，递归是一种编程技巧。


    O(n)

        6、桶排序（Bucket sort）                          // 范围不大、数据划分

            会用到“桶”
            核心思想是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。
            桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。

            适用场景：

                针对范围不大的数据，将数据划分成不同的桶来实现排序。

                    比较适合用在 外部排序 中

                        所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。





        7、计数排序（Counting sort）                        // 范围不大、数据划分

            桶排序的一种特殊情况

            适用场景：

                针对范围不大的数据，将数据划分成不同的桶来实现排序。

                计数排序只能用在数据范围不大的场景中，如果数据范围 k 比要排序的数据 n 大很多，就不适合用计数排序了。
                而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。


        8、基数排序（Radix sort）                          // 高低位、递进

            适用场景：

                基数排序要求数据可以划分成高低位，位之间有递进关系。
                比较两个数，我们只需要比较高位，高位相同的再比较低位。
                而且每一位的数据范围不能太大，因为基数排序算法需要借助桶排序或者计数排序来完成每一个位的排序工作。

                基数排序对要排序的数据是有要求的，
                需要可以分割出独立的“位”来比较，而且位之间有递进的关系，如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。
                除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 O(n) 了。



        -----------------------
        线性排序（Linear sort）

            桶、计数、基数排序 之所以能做到 线性的时间复杂度，
            主要原因是，这三个算法是 非基于比较 的排序算法，都不涉及 元素之间的 比较操作。




    -----------------------------------
    排序算法选择：
        小规模 数据进行排序，可以选择时间复杂度是 O(n²) 的算法
        大规模 数据进行排序，时间复杂度是 O(nlogⁿ) 的算法更加高效
        所以，为了兼顾任意规模数据的排序，一般都会首选时间复杂度是 O(nlogⁿ) 的排序算法 来实现 排序函数

    应用：
        Java    ->      堆       ->  O(nlogⁿ)

        C       ->      快排     ->  O(n²)




    总结：如何实现一个通用的高性能的排序函数？

    一、如何选择合适的排序算法？


        1.排序算法一览表

            时间复杂度                    稳定排序    原地排序
            冒泡排序 O(n^2)                 是          是
            插入排序 O(n^2)                 是          是
            选择排序 O(n^2)                 否          是
            快速排序 O(nlogⁿ)               否          是
            归并排序 O(nlogⁿ)               是          否
            桶排序 O(n)                     是          否
            计数排序 O(n+k)，k是数据范围      是          否
            基数排序 O(dn)，d是纬度           是          否


    2.为什选择快速排序？
        1）线性排序时间复杂度很低但使用场景特殊，如果要写一个通用排序函数，不能选择线性排序。
        2）为了兼顾任意规模数据的排序，一般会首选时间复杂度为 O(nlogⁿ) 的排序算法来实现排序函数。
        3）同为 O(nlogⁿ)的 快排和归并 排序相比，归并排序不是原地排序算法，所以最优的选择是快排。


    二、如何优化快速排序？

        导致快排时间复杂度降为O(n)的原因是分区点选择不合理，最理想的分区点是：被分区点分开的两个分区中，数据的数量差不多。

        如何优化分区点的选择？有2种常用方法，如下：

            1.三数取中法
                ① 从区间的首、中、尾分别取一个数，然后比较大小，取中间值作为分区点。
                ② 如果要排序的数组比较大，那“三数取中”可能就不够用了，可能要“5数取中”或者“10数取中”。

            2.随机法：每次从要排序的区间中，随机选择一个元素作为分区点。


        警惕快排的递归发生堆栈溢出，有2中解决方法，如下：
            ① 限制递归深度，一旦递归超过了设置的阈值就停止递归。
            ② 在堆上模拟实现一个函数调用栈，手动模拟递归压栈、出栈过程，这样就没有系统栈大小的限制。


    三、通用排序函数实现技巧

        1.数据量不大时，可以采取用时间换空间的思路
        2.数据量大时，优化快排分区点的选择
        3.防止堆栈溢出，可以选择在堆上手动模拟调用栈解决
        4.在排序区间中，当元素个数小于某个常数时，可以考虑使用O(n²)级别的插入排序
        5.用哨兵简化代码，每次排序都减少一次判断，尽可能把性能优化到极致


    四、思考

        1. Java中的排序函数都是用什么排序算法实现的？有有哪些技巧？       // Arrays.sort

            1. 对于基本类型的数组
                Java 采用的是 双枢轴快速排序（DualPivotQuicksort -> since 1.7）
                在此之前，Java 采用的是 普通的快速排序，双枢轴快速排序 是对 普通快速排序 的优化

            2. 对于对象类型
                Java 采用的算法是 TimSort（ -> since 1.7）
                在此之前，Java 采用的是 归并排序
                TimSort 算法实际上是对 归并排序 的 一系列优化

            3. 在这些排序算法中，如果数组长度比较小，它们还会采用 效率更高的 插入排序（< 47）

        2. 查看了Java的 Arrays.sort

            -> DualPivotQuicksort.sory();

                1. 若数组元素个数总数小于47，使用插入排序
                2. 若数据元素个数总数在47~286之间，使用快速排序。应该是使用的优化版本的三值取中的优化版本
                3. 若大于286的个数，使用归并排序

                    // 底层实现的代码校验比较多


3、二分查找

    一、什么是二分查找

        二分查找针对的是一个 有序的数据集合，
        每次通过跟 区间中间 的元素对比，将待查找的区间 缩小为之前的一半，直到找到要查找的元素，或者区间缩小为0

    二、时间复杂度分析

        1. 时间复杂度

            假设数据大小是n，每次查找后数据都会缩小为原来的一半，最坏的情况下，直到查找区间被缩小为空，才停止。
            所以，每次查找的数据大小是：n，n/2，n/4，…，n/(2^k)，…，这是一个等比数列。
            当n/(2^k)=1时，k的值就是总共缩小的次数，也是查找的总次数。
            而每次缩小操作只涉及两个数据的大小比较，所以，经过k次区间缩小操作，时间复杂度就是O(k)。
            通过n/(2^k)=1，可求得k=log2n，所以时间复杂度是O(logn)。

        2. 认识 O(logn)

            ① 这是一种极其高效的时间复杂度，有时甚至比O(1)的算法还要高效。为什么？
            ② 因为logn是一个非常“恐怖“的数量级，即便n非常大，对应的logn也很小。比如n等于2的32次方，也就是42亿，而logn才32
            ③ 由此可见，O(logn)有时就是比O(1000)，O(10000)快很多


    三、如何实现二分查找

        1. 循环实现

            注意事项：
            ① 循环退出条件是：start<=end，而不是start<end。
            ② mid的取值，使用mid=start + (end - start) / 2，而不用mid=(start + end)/2，因为如果start和end比较大的话，求和可能会发生int类型的值超出最大范围。
                为了把性能优化到极致，可以将除以2转换成 位运算，即start + ((end - start) >> 1)，因为相比除法运算来说，计算机处理位运算要快得多。
            ③ start和end的更新：start = mid - 1，end = mid + 1，若直接写成start = mid，end=mid，就可能会发生死循环。

        2. 递归实现

    四、使用条件（应用场景的局限性）

        1. 二分查找依赖的是顺序表结构，即数组。   // 链表 -> 无index，无法随机访问 -> 遍历查询 O(n)
        2. 二分查找针对的是有序数据，因此只能用在插入、删除操作不频繁，一次排序多次查找的场景中。
        3. 数据量太小不适合二分查找，与直接遍历相比效率提升不明显。
            但有一个例外，就是数据之间的比较操作非常费时，比如数组中存储的都是长度超过300的字符串，那这是还是尽量减少比较操作使用二分查找吧。
        4. 数据量太大也不是适合用二分查找，因为数组需要连续的空间，若数据量太大，往往找不到存储如此大规模数据的连续内存空间。

    五、思考

        1. 如何在1000万个整数中快速查找某个整数？
            ① 1000万个整数占用存储空间为40MB，占用空间不大，所以可以全部加载到内存中进行处理；
            ② 用一个1000万个元素的数组存储，然后使用快排进行升序排序，时间复杂度为O(nlogn)
            ③ 在有序数组中使用二分查找算法进行查找，时间复杂度为O(logn)

        2. 如果数据使用链表存储，二分查找的时间复杂就会变得很高，那查找的时间复杂度究竟是多少呢？
            如果你自己推导一下，你就会深刻地认识到，为何我们会选择用数组而不是链表来实现二分查找了。

            假设链表长度为n，二分查找每次都要找到中间点(计算中忽略奇偶数差异)：
                第一次，查找中间点，需要移动指针n/2次；
                第二次，需要移动指针n/4次；
                第三次，需要移动指针n/8次；
                ......
                以此类推，一直到1次为值

            总共指针移动次数(查找次数) = n/2 + n/4 + n/8 + ...+ 1，这显然是个等比数列，根据等比数列求和公式：sum = n - 1

            最后算法时间复杂度是：O(n-1)，忽略常数，记为O(n)，时间复杂度和顺序查找时间复杂度相同

            但是稍微思考下，在二分查找的时候，由于要进行多余的运算，严格来说，会比顺序查找时间慢


        3. 如何编程实现“求一个数的平方根”？要求精确到小数点后6位？



    实现：
        十个二分九个错
            尽管第一个二分查找算法于 1946 年出现，然而第一个完全正确的二分查找算法实现直到 1962 年才出现。

        变体：
            1、查找第一个值等于给定值的元素
            2、查找最后一个值等于给定值的元素
            3、查找第一个大于等于给定值的元素
            4、查找最后一个小于等于给定值的元素

        细节：
            终止条件、区间上下界更新方法、返回值选择

        凡是用 二分查找 能解决的，绝大部分我们更倾向于用 散列表 或者 二叉查找树

        场景：
            求“值等于给定值”的二分查找确实不怎么会被用到，二分查找更适合用在“近似”查找问题。
            如上面几种变体问题，用其他数据结构，比如散列表、二叉树，就比较难实现了。



4、搜索


5、哈希算法

    无法做到零冲突

        鸽巢原理（也叫抽屉原理）：
            如果有 10 个鸽巢，有 11 只鸽子，那肯定有 1 个鸽巢中的鸽子数量多于 1 个   --->  肯定有 2 只鸽子在 1 个鸽巢内

        哈希算法产生的哈希值的长度是固定且有限的，而我们要哈希的数据是无穷的。

        MD5  ->  最多能表示 2^128 个数据


    应用：
        安全加密
            MD5（MD5 Message-Digest Algorithm，MD5 消息摘要算法）
            SHA（Secure Hash Algorithm，安全散列算法）
            DES（Data Encryption Standard，数据加密标准）
            AES（Advanced Encryption Standard，高级加密标准）

            没有绝对安全的加密
            越复杂、越难破解的加密算法，需要的计算时间也越长

        唯一标识
            图片比对

        数据校验
            BT文件下载，是否被恶意修改过

        散列函数
            看重的是散列的平均性和哈希算法的执行效率

        负载均衡
            利用哈希算法替代映射表，可以实现一个会话粘滞的负载均衡策略

        数据分片
            hash值 取模
            通过哈希算法对处理的海量数据进行分片，多机分布式处理，可以突破单机资源的限制

        分布式存储
            一致性哈希算法  -> 解决 rehash
            利用一致性哈希算法，可以解决缓存等分布式系统的扩容、缩容导致数据大量搬移的难题

            http://www.zsythink.net/archives/1182


6、贪心算法

    应用：
        1、分糖果
        2、钱币找零
        3、区间覆盖


7、分治算法

    思想核心：
        分而治之

        将原问题划分成 n 个规模较小，并且结构与原问题相似的子问题，递归地解决这些子问题，然后再合并其结果，就得到原问题的解

    实现：
        递归、归并

    应用：
        倒排索引、PageRank 计算、网页分析等搜索引擎相关的技术


8、回溯算法

    用途：
        用来解决广义的搜索问题
        从一组可能的解中，选择出一个满足要求的解

    枚举：
        回溯算法本质上就是枚举，优点在于其类似于摸着石头过河的查找策略，且可以通过剪枝少走冤枉路。
        它可能适合应用于缺乏规律，或我们还不了解其规律的搜索场景中。

    实现：

        非常适合用 递归 来实现，在实现的过程中，剪枝 操作是提高回溯效率的一种技巧

        利用剪枝，我们并不需要穷举搜索所有的情况，从而提高搜索效率


    应用：
        深度优先搜索、正则表达式匹配、编译原理中的语法分析

        很多经典的数学问题都可以用回溯算法解决，比如：数独、八皇后、0-1 背包、图的着色、旅行商问题、全排列


        电影《蝴蝶效应》，讲的就是主人公为了达到自己的目标，一直通过回溯的方法，回到童年，在关键的岔路口，重新做选择


    复杂度：
        指数级


9、动态规划

    解决问题的思路：
        我们把问题分解为多个阶段，每个阶段对应一个决策。
        我们记录每一个阶段可达的状态集合（去掉重复的），然后通过当前阶段的状态集合，来推导下一个阶段的状态集合，动态地往前推进

    场景：
        求解最优问题，比如求：最大值、最小值

    优点：
        著地降低时间复杂度，提高代码的执行效率

    思维方式：
        求解问题的过程 不太符合人类 常规的思维方式


    复杂度：
        空间换时间


    比较：

        贪心：     一条路走到黑，就一次机会，只能哪边看着顺眼走哪边
        回溯：     一条路走到黑，无数次重来的机会，还怕我走不出来 (Snapshot View)
        动态规划： 拥有上帝视角，手握无数平行宇宙的历史存档， 同时发展出无数个未来 (Versioned Archive View)


10、字符串匹配算法

    Java 中的 indexOf()


    单模式串匹配 算法，也就是一个串跟一个串进行匹配

        BF 算法（Brute Force 暴力匹配算法，也叫 朴素匹配算法）
            是最简单、粗暴的字符串匹配算法
            它的实现思路是，拿模式串与主串中是所有子串匹配，看是否有能匹配的子串。
            所以，时间复杂度也比较高，是 O(n*m)，n、m 表示主串和模式串的长度。
            不过，在实际的软件开发中，因为这种算法实现简单，对于处理小规模的字符串匹配很好用。

        RK 算法
            是借助 哈希算法 对 BF 算法进行改造
            即对每个子串分别求哈希值，然后拿子串的哈希值与模式串的哈希值比较，减少了比较的时间。
            所以，理想情况下，RK 算法的时间复杂度是 O(n)，跟 BF 算法相比，效率提高了很多。
            不过这样的效率取决于哈希算法的设计方法，如果存在冲突的情况下，时间复杂度可能会退化。
            极端情况下，哈希算法大量冲突，时间复杂度就退化为 O(n*m)。


    多模式串匹配 算法，一个串中同时查找多个串

        Trie 树

            解决字符串快速匹配问题的数据结构



            实现：
                Trie树的开源库：Apache Commons，里面有关于Trie的实现


            空间换时间

            场景：
                查找前缀匹配的字符串


        AC 自动机































----------------------------------------------------
高级排序


1、拓扑排序

    基于 有向无环图 的一个算法

    环的检测：
        第二次 被访问的时候，就说明存在 环

2、最短路径

3、位图

4、概率统计

5、向量空间

6、B+树

    数据库索引是如何实现的呢？底层使用的是什么数据结构和算法呢？

    执行效率 和 存储空间：
        在执行效率方面，我们希望通过索引，查询数据的效率尽可能地高
        在存储空间方面，我们希望索引不要消耗太多的内存空间


    演进：
        通过 二叉查找树 演化 过来的，而非跳表

        B+树 发明于 1972 年，跳表发明于 1989 年
        我们可以大胆猜想下，跳表的作者有可能就是受了 B+树 的启发，才发明出跳表

    时间换空间：
        把索引存储在硬盘中，而非内存中

        内存 访问速度是 纳秒级
        磁盘 访问速度是 毫秒级

        时间、空间的平衡，既保证了执行效率，又节省了内存


    --------
    B+Tree 理解要点：
        1. 理解二叉查找树
        2. 理解二叉查找树会出现不平衡的问题（红黑树理解了，对于平衡性这个关键点就理解了）
        3. 磁盘IO访问太耗时
        4. 当然，链表知识跑不了 ———— 别小瞧这个简单的数据结构，它是链式结构之母
        5. 最后，要知道典型的应用场景：数据库的索引结构的设计

    ----------
    1、B+ 树中，将叶子节点串起来的链表，是单链表还是双向链表？为什么？

        双向链表    ->  方便asc和desc


        对于 B+ Tree 叶子节点，是用双向链表 还是用单链表，得从具体的场景思考：

            大部分同学在开发中遇到的数据库查询，都遇到过升序或降序问题

                即类似这样的sql:

                    select name,age, ... from where uid > startValue and uid < endValue order by uid asc(或者desc)

                此时，数据底层实现有两种做法：
                    1、保证查出来的数据就是用户想要的顺序
                    2、不保证查出来的数据的有序性，查出来之后再排序

                以上两种方案，不加思考，肯定选第一种
                因为第二种做法浪费了时间（如果选用内存排序，还是考虑数据的量级）

            那如何能保证查询出来的数据就是有序的呢？

                单链表肯定做不到，只能从头往后遍历，再想想，只能选择双向链表了

                此时，可能有的同学又问了：双向链表，多出来了一倍的指针，不是会多占用空间嘛？
                    答案是肯定的
                    可是，我们再细想下，数据库索引本身都已经在磁盘中了，对于磁盘来说，这点空间已经微不足道了，用这点空间换来时间肯定划算呀

                    顺便提一下：
                        在实际工程应用中，双向链表应用的场景非常广泛，毕竟能大量减少链表的遍历时间


    2、我们对平衡二叉查找树进行改造，将叶子节点串在链表中，就支持了按照区间来查找数据。
        我们在散列表（下）讲到，散列表也经常跟链表一块使用，如果我们把散列表中的结点，也用链表串起来，能否支持按照区间查找数据呢？

        可以支持区间查询
        java中linkedHashMap就是链表链表+HashMap的组合，用于实现缓存的lru算法比较方便，
        不过要支持区间查询需要在插入时维持链表的有序性，复杂度O(n).效率比跳表和b+tree差

        JDK中的LinkedHashMap为了能做到保持节点的顺序（插入顺序或者访问顺序），就是用双向链表将节点串起来的。



7、搜索

    为什么需要索引？

        在实际的软件开发中，业务纷繁复杂，功能千变万化，但是，万变不离其宗
        如果抛开这些业务和功能的外壳，其实它们的 本质 都可以抽象为 “对数据的存储和计算”

        对应到数据结构和算法中

            “存储”    -->     需要的就是   数据结构

            “计算”    -->     需要的就是   算法



    索引
        1. 功能性需求
            1、数据是格式化数据还是非格式化数据
                对关键词构建索引
            2、数据是静态数据还是动态数据
                动态地更新索引
            3、索引存储在内存还是硬盘
                内存消耗和查询效率
            4、单值查找还是区间查找
            5、单关键词查找还是多关键词组合查找
                求并集、求交集

        2. 非功能性需求

            1、不管是存储在内存中还是磁盘中，索引对存储空间的消耗不能过大
            2、在考虑索引查询效率的同时，我们还要考虑索引的维护成本


        常用的数据结构

            1、几种支持 动态数据集合 的数据结构：        //（动态增删改、查）

                1、散列表：                                      // O(1) ———— 内存索引 ———— K-V数据库（Redis、MemCache）

                    增删改 查 操作的性能非常好，时间复杂度是 O(1)

                    一些K-V数据库，如：Redis、MemCache

                    这类索引，一般都构建在 内存 中


                    缺点：不能支持 按照区间 快速查找数据


                2、红黑树                                       // O(logn) ———— 内存索引 ———— 文件系统（Ext）

                    红黑树 作为一种常用的 平衡二叉查找树

                    数据 插入、删除、查找 的时间复杂度是 O(logn)

                    也非常适合用来构建 内存 索引

                    Ext 文件系统中，对磁盘块的索引，用的就是红黑树


                    缺点：不足以支持 按照区间 快速查找数据


                3、B+树                                       // O(logn) ———— 磁盘索引 ———— 关系数据库（MySQL、Oracle）

                    B+ 树主要是用在 外部存储 上，为了减少磁盘IO次数

                        B+ 树是一个多叉树，所以，对相同个数的数据构建索引，B+ 树的高度要低于红黑树。
                        当借助索引查询数据的时候，读取 B+ 树索引，需要的磁盘 IO 次数会更少。

                    优点：支持 区间 快速查找


                4、跳表                                       // O(logn) ———— 内存索引 ———— K-V数据库（Redis）

                    跳表比较适合内存存储

                        也支持快速 添加、删除、查找
                        我们通过灵活调整索引结点个数和数据个数之间的比例，可以很好地平衡索引对内存的消耗及其查询效率。

                        Redis 中的有序集合，就是用跳表来构建的。


                    优点：支持 区间 快速查找



            2、辅助索引：

                位图、布隆过滤器

                    布隆过滤器有一定的判错率。
                    但是，我们可以规避它的短处，发挥它的长处。
                    尽管对于判定存在的数据，有可能并不存在，但是对于判定不存在的数据，那肯定就不存在。
                    而且，布隆过滤器还有一个更大的特点，那就是内存占用非常少。
                    我们可以针对数据，构建一个布隆过滤器，并且存储在内存中。
                    当要查询数据的时候，我们可以先通过布隆过滤器，判定是否存在。
                    如果通过布隆过滤器 判定数据不存在，那我们就 没有必要 读取磁盘中的索引 了
                    对于 数据不存在 的情况，数据查询就 更加快速 了


            3、静态数据：     //（读多写少）

                有序数组

                    把数据的 关键词（查询用的）抽取出来，组织成 有序数组，然后利用 二分查找 算法来快速查找数据

    ------------------------
    我对索引的理解

    索引真是个好东西
        索引的英文名字叫：index，记住这个英文单词，会让我们更容易记忆和联想它到底是什么。
        在实际的编程中，index这个单词，真是到处可见。 例如：数组的下标就是index

    如果用一句话描述“索引”的作用，那会是什么？
        我想是这样：索引是用来辅助查找，用计算机专业术语叫：Addressing(寻址）

    现实世界中，我们的查找会存在两种场景：
        1. 从局部信息，查询与其相关的整体信息
        2. 从整体信息中查询局部信息

    怎么理解呢？
        搜索引擎需要查询一个网页中是否存在某个关键词，以及通过某个关键词查询包含它的所有网页。

    索引的应用
        正是因为计算机大部分工作都是在Addressing，所以，在计算机中，索引到处存在。
        小到 操作系统 虚拟内存 到 真实内存 的映射，就是索引嘛，
        大到 分布式系统、网络，都是这个原理。

    以上，我对索引的理解有点“广义”。我觉得数据结构和算法如此重要，它体现计算机精髓的地方便在于此。



8、并行算法


    算法的目的就是为了提高代码执行的效率。当算法无法再继续优化的情况下，需要借助 并行计算 的处理思想对算法进行改造

    1、并行排序

        假设要给大小为 8GB 的数据进行排序，最常用的是三种排序算法，归并排序、快速排序、堆排序，时间复杂度为 O(nlogn) 。
        从理论上讲，已经很难再从算法层面优化了。而利用并行的处理思想可以将执行效率提高很多倍。

        第一种是对归并排序并行化处理
            * 将这8GB 的数据划分成 16 个小的数据集合，每个集合包含 500MB 的数据。
            * 用 16 个线程，并行地对这 16 个 500MB 的数据集合进行排序。
            * 16 个小集合分别排序完成之后，再将这 16 个有序集合合并。

        第二种是对快速排序并行化处理
            * 将数据扫描一遍，找到数据所处的范围区间，在按从小到大划分成 16 个小区间。
            * 将 8GB 的数据划分到对应的16 个小区间中，启动 16 个线程，并行地进行排序。
            * 等到 16 个线程都执行结束后，得到的数据就是有序数据了。

        对比这两种处理思路
            * 共同点：它们利用的都是分治的思想，对数据进行分片，然后并行处理。
            * 不同点：
                （1）第一种处理思路是，先随意地对数据分片，排序之后再合并。
                （2）第二种处理思路是，先对数据按照大小划分区间后再排序，排完序就不需要再处理了。
            * 这个跟归并和快排的区别如出一辙。


    2、并行查找

        散列表是一种非常适合快速查找的数据结构

            弊端：
                * 如果给动态数据构建索引，数据不断加入会使散列表的装载因子越来越大
                * 为了保证散列表性能不下降，就需要对散列表进行动态扩容
                * 对巨大的散列表进行动态扩容，不仅比较耗时，还比较消耗内存

            优化：
                * 实际上可以将数据随机分割成 k 份（比如 16 份），每份中的数据只有原来的 1/k
                * 然后针对这 k 个小数据集合分别构建散列表。这样，散列表的维护成本就变低了
                * 当某个小散列表的装载因子过大的时，可以单独对这个散列表进行扩容，而其他散列表不需要进行扩容。
                * 当要查找数据时，通过 16 个线程并行地在这16 个散列表中查找数据。这样的查找性能，比起一个大散列表的做法，也并不会下降，反倒有可能提高。
                * 当往散列表中添加数据时，可以将新数据放入装载因子最小的散列表中，这样也有助于减少散列冲突。


        假设有 2GB 的数据，放到 16 个散列表中，每个散列表中的数据大约是 150MB
        当某个散列表需要扩容的时候，我们只需要额外增加 150*0.5=75MB 的内存（假设还是扩容到原来的 1.5 倍）
        不管从扩容的执行效率还是内存的利用率上，这种多个小散列表的处理方法，都要比大散列表高效

        并行字符串匹配
            在文本中查找某个关键词可以通过字符串匹配算法来实现，字符串匹配算法有 KMP、BM、RK、BF 等

        如果处理的是超级大的文本，可以把大的文本，分割成 k 个小文本
            假设 k 是 16，就启动 16 个线程，并行地在这 16 个小文本中查找关键词，这样整个查找的性能就提高了 16 倍


    3、并行搜索

        搜索算法有：广度优先搜索、深度优先搜索、Dijkstra 最短路径算法、A* 启发式搜索算法

        对于广度优先搜索算法，也可以将其改造成并行算法
            * 广度优先搜索是一种逐层搜索的搜索策略
            * 基于当前这一层顶点，我们可以启动多个线程，并行地搜索下一层的顶点
            * 在代码实现方面，原来广度优先搜索的代码实现，是通过一个队列来记录已经遍历到但还没有扩展的顶点
            * 经过改造之后的并行广度优先搜索算法，需要利用两个队列来完成扩展顶点的工作



    并行计算是一个工程上的实现思路，尽管跟算法关系不大，但是，在实际的软件开发中，它确实可以非常巧妙地提高程序的运行效率，是一种非常好用的性能优化手段。

    当要处理的数据规模达到一定程度之后，我们无法通过继续优化算法，来提高执行效率 的时候，
    我们就需要在实现的思路上做文章，利用更多的硬件资源，来加快执行的效率。
    所以，在很多超大规模数据处理中，并行处理的思想，应用非常广泛，比如 MapReduce 实际上就是一种并行计算框架。




----------------------------------------------------------------------------

支持 快速查找、插入、删除 的动态数据结：

    1、散列表

        查询性能很好，时间复杂度是 O(1)

        不支持 按照区间 快速查找数据


    2、平衡二叉查找树

        查询的性能也很高，时间复杂度是 O(logn)

        不支持 区间 快速查找

    3、跳表

        跳表是在 链表 之上加上 多层索引 构成的

        支持 快速地 查找、插入、删除，时间复杂度都是 O(logn)

        支持 按照区间 快速地查找数据


----------------------------------------------------------------------------

学了这么久的数据结构和算法，今天突然顿悟

    基础的数据结构就是 数组 和 链表，
    而后面更加复杂的 树、队列、图等等，都可以通过 数组 和 链表 等方式存储

    出现树、队列、图 等数据结构的原因，就是为了解决 部分问题处理过程中 时间复杂度过高 的问题，所以 数据结构 就是为了 算法 而生的！

    尤其是学习了时间复杂度过后，在工作和学习过程中，就应该分析自己的代码复杂度，以进行优化或者 选择更好的 数据结构和算法！
    这样才能写出更好的代码，更好的解决问题.


    -- 站在高维度思考，可以很容易解决低维度的问题，可是，升维很难。但只要升维成功，就能降维打击，无往而不胜，这个代价是值得的。

    -- 回头想想内存就明白了，所有数据的存取只有两种方式：线性和非线性。底层都是 数组和链表。所以不可能有其他数据结构的，高级的数据结构都是这二者的算法组合。

    -- 算法解题过程中两种思想：第一以空间换时间，第二升维。高级数据结构的出现我想就是通过升维来解决复杂度问题的。

    -- 数据结构分 数据逻辑结构 和 数据存储结构。而数据存储结构只有两种：顺序存储 与 链式存储。也就是说落到内存或磁盘上，只有这两种结构。

    -- 学到现在有一种特别明显的感受，就是描述一种 需求模型 可以有很多种组合数据结构，而这些 复杂数据结构 都是 基础数据结构 组合 起来的，
       而这些数据结构去的选择又是基于需求模型对 时间和空间 这两个维度来的，所以解决问题的关键是我们 对需求的理解 以及 我们对数据结构的熟练运用。



个人感觉其实就 两种数据结构：

    数组 和 链表

        数组占据随机访问的优势，却有需要连续内存的缺点

        链表具有可不连续存储的优势，但访问查找是线性的

        散列表和链表、跳表的混合使用，是为了结合数组和链表的优势，规避它们的不足

        我们可以得出数据结构和算法的重要性排行榜：连续空间 > 时间 > 碎片空间



与其追新，不如求本



被 天天吹🐂🍺的大厂 神话的 "区块链"

    区块链是一块块区块组成的，每个区块分为两部分：区块头和区块体。

    区块头保存着 自己区块体 和 上一个区块头 的哈希值。

    因为这种 链式关系 和 哈希值的唯一性，只要区块链上任意一个区块被修改过，后面所有区块保存的哈希值就不对了。

    区块链使用的是 SHA256 哈希算法，计算哈希值非常耗时，如果要篡改一个区块，就必须重新计算该区块后面所有的区块的哈希值，短时间内几乎不可能做到。




散列表：
    插入、删除、查找 都是O(1), 是最常用的，但其缺点是不能顺序遍历以及扩容缩容的性能损耗。
    适用于那些不需要顺序遍历，数据更新不那么频繁的。

跳表：
    插入、删除、查找 都是O(logn), 并且能顺序遍历。缺点是空间复杂度O(n)。
    适用于不那么在意内存空间的，其顺序遍历和区间查找非常方便。

红黑树：
    插入、删除、查找 都是O(logn), 中序遍历即是顺序遍历，稳定。
    缺点是难以实现，查找不方便。
    其实跳表更佳，但红黑树已经用于很多地方了。






---------------------------------------------

谈一谈自己对 数据结构 和 索引 的理解：

    - 数据的存储，在底层只有两种形式：连续空间存储 和 零散空间存储，这两种形式对应了两种最基本的数据结构：数组 和 链表

    - 使用这两种数据结构存储数据的空间利用率是最高的，
        但是如果想要实现更加快速的查找，我们就需要使用额外的操作，这两种操作是：用额外计算获取数据地址 和 用额外空间保持一种方便查找的结构

        - 用额外的计算获取数据地址，这种思路只能用于数组，因为数组的下标可以计算内存地址。

            具体应用如下：
                1. 使用数组下标进行数据的 随机访问，这也是数组的杀手锏
                2. 通过对数据的计算确定数据应该存放的位置，这就是 散列表，这种计算方法就是 哈希函数

        - 用额外的空间保持方便查找的结构，这种思路用于“使用零散空间存储数据的情况”

            你仔细思考，跳表、红黑树、B+树 是不是都是这种思路的产儿？
                1. 跳表通过设置额外的节点索引，实现了加快数据查询的功能
                2. 红黑树、B+树 通过树这种结构用不同孩子保存了不同数据间的关系

    - 不同数据结构的 组合 可以实现更多功能

    - 如果想实现范围索引，最好的办法是使用 有序链表
        我们通过某种方法，找到数据范围中的起始结点，然后通过有序链表依次输出范围内的结点，直到数据超出范围

        这里有几个现成的例子：
            1. 跳表：通过额外的结点找到有序链表的起始结点，然后依次输出
            2. B+树：通过查找叶子节点定位有序链表的起始节点，然后依次输出



---------------------------------------------

现在才明白，其实最底层的数据结构是<addr,value>，按照存储介质 是否连续、是否显示制定key，又可以分为数组、链表和hash，
其中数组可以认为是一种<index,arr[index]>，链表是<p,*p>，
然后在这基础之上衍生出了 一维的线性表、栈、队列、散列表 ， 二维的树(平衡二叉树、红黑树、跳表) ， 三维的图 ，
还有就是各种数据结构灵活组合的数据结构，这里的跳表可以算是组合类型的，但是它的使用范围很多，所以划到了二维中
这些是存储

然后是算法：排序、分治、贪心、回溯、动态规划

第一次真正感觉到了数据结构和算法的关联，好神奇的感觉。至少现在觉得那些难记的算法、数据结构没那么困难了，多思考、实践总会能够像写代码般应用到实际中。



------------------------------------------------------------
小数据量的情况下，散列表在存储和匹配上并不一定比二分查找高




------------------------------------------------------------
实现：

    散列表     HashMap

    红黑树     TreeMap


    数组       ArrayList

    双向链表    LinkedList

    跳表       ConcurrentSkipListMap、ConcurrentSkipListSet（Java的 Set实现 均基于 Map）           since 1989 （新的数据结构用的比较多 更新换代  Redis...）
               基于链表，且必须为有序链表

    平衡二叉树               since 1960s         （老的数据结构 用的比较多）



    一维的数据结构 要加速(查)的话  一般是升维  一维 --> 二维      多一个维度 = 多一级信息（保存了额外的信息，不用挨个遍历   同时多保存了信息 = 内存消耗  --->  空间换时间   维护成本亦增加）
    有序、前后节点...(附加信息)



---------------
n ㏒ ª ₂²ⁿ ᴺ ɴ
𝓃𝘯log₂ⁿ
log


𝘯²
𝘯(log₂ⁿ)
n
log₂ⁿ
1