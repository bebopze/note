========================================================================================================================
面试
========================================================================================================================

基本是这样吧!
1、自我介绍
2、项目介绍
3、拉锯式问答，这里不同公司不同方式，阿里是越拉越深直到问疼你，让你充分认识到自己的无知。如果第一个人做不到，会换另一个力气大的继续拉。公司越大拉的次数相对越多，小公司没这么多拉锯和擅长拉锯的。
4、算法＋OS＋网络＋设计模式＋JVM＋常用组件原理＋架构设计＋问题排查思，路都是常客
5、如果OK，后面会有领导来拉一下不深较广的软技能，价值观、企业文化、抗压能力、家庭、职业规划等待
6、HR最后谈钱，如果妥啦！可以轻松一点，或者继续，如果不妥也不要怀疑自己不行，复盘、下一家
7、入职，过适用期，你会发现都是新来的同事，那代表组织不稳定，如果都是老人，那代表组织将要发生变化
8、没有完美的人，更没有完美的公司，找到合适自己的，记得每天成长，过活自己的人生


------------------------------------------------------------------------------------------------------------------------
面试一个月的成长，能赶上我平时半年多。
把现在主流招聘信息的东西都看一遍：Spring 全家桶；Redis；消息队列；分布式等。
背面试题：可能有点投机取巧，但是收益却很高。本人对数据结构还算熟练，Hash Map。Array List的一些原理性问题，几乎可以秒答，甚至能描述部分JDK实现。但是对于Jvm内存管理相关就很弱项了。关于类似String是存在哪个内存区域这种个人兴趣不高，还容易忘的，大多还是通过背题。
面试总结：每次优质的面试一定要总结。记清楚对方问了些什么，对方是什么公司，侧重点是什么。


------------------------------------------------------------------------------------------------------------------------
看后不禁想起了一个面试经典问题：平时遇到问题你是怎么解决的？
我第一次面对这种问题，大脑一片空白，因为没有能拿得出手的问题，只好泛泛而谈，差不多就是“百度，查文档”之类的，想起来真是尴尬。
下来之后反思了一下，觉得如果实在没有能拿得出手的案例，也要假设一个有挑战性的问题去回答。
回答得好可以体现学习能力，回答不好至少也能留下个好学的印象。

    其实就像文中说的，我们可以在平时多积累问题，多积累解决问题的案例，这样就不会大脑空白了~ ：）

------------------------------------------------------------------------------------------------------------------------
有上亿人都用到的项目固然好，没有其实可以自己造一个

    比如：一亿条数据的一个文件，怎么高效的落库。


------------------------------------------------------------------------------------------------------------------------
1、在面试的时候确实应该把话题转移到自己熟悉的技术上，但是前提是自己一定要对自已所谓的熟悉的技术不仅要熟练，更要超出平均水平
2.、项目当中其实没有很多高并发的实战的，自己设想一个和自己项目有关联的就行，前提是不能生搬硬套

------------------------------------------------------------------------------------------------------------------------




========================================================================================================================
1、实际应用中的高并发场景讲讲？

    1、税率Redis缓存

    2、MQ异步消费（削峰）            套1个相关场景

    3、分布式锁


2、怎么预防超卖？                                                                   - https://learnku.com/articles/49280

    ===>  共享变量 的读写安全问题

        1、为了应对高并发

            1、MQ异步消费（削峰）

            2、限流（单位时间内 只允许放行n个请求）


        2、为了数据安全

            1、SQL  ==>  num >= #{购买数量}

                update goods set num = num - 1 WHERE id = 1001 and num > 0;                                      // 递减

                update Product set count = count - #{购买数量} where id = #{id} and count >= #{购买数量};           // 减n


            2、乐观锁（版本号）

                先获取 版本号，再更新

                同一库存数  ->  对应同一个版本号

                ==>  100个线程   ->   只有1个能更新成功


                ------------------------------------------
                num >= #{购买数量}  +  version = #{version}


            3、分布式锁（互斥）




3、MySQL线程池、Redis线程池 怎么设置的？

    1、默认 2n + 1

    2、根据 DB最大连接数 / 容器个数

    3、压测


4、CPU抖动、OOM、数据库抖动 怎么排查问题的？

    1、可视化工具连接、dump离线分析

    2、云平台查看 慢SQL、CPU、读写压力...

        DB大批量写   ->   换SSD盘、参数调优（IOPS、批量提交）


5、JVM垃圾回收器用的哪种？

    这问题问的水平太差，搞的我有点懵逼

    ---
    我应该一顿输出
        堆栈  二八法则   分代回收   可达性分析
        标记-清除  标记-复制  标记-整理    内存碎片
        TLAB  卡表   串行/并行/并发  stop-the-world



    ---
    JDK1.7 默认垃圾收集器 Parallel Scavenge（新生代）+ Parallel Old（老年代）           // 并行

    JDK1.8 默认垃圾收集器 Parallel Scavenge（新生代）+ Parallel Old（老年代）           // 并行

    JDK1.9 默认垃圾收集器 G1                                                        // 并发







========================================================================================================================
项目

1、双写

    1、历史数据同步

        写job，全量同步一次历史数据

    2、增量数据同步

        1、写入旧库，发送mq消息（行数据ID）

        2、新应用接收消息，拿到行数据ID，通过RPC到老DB获取数据

            构造成新DB模型，写入新DB

    3、数据校验工具

        写数据校验程序，随机挑选一批数据，做规则校验   ->   保障数据规则校验 100%通过

    3、开始灰度测试

        切入小部分流量进入到 新DB，有异常问题（业务异常、程序异常），流量切回老DB

        线上跑一段时间后，无问题，慢慢放大 灰度流量比例

        直至流量100%切换










------------------------------------------------------------------------------------------------------------------------


------------------------------------------------------------------------------------------------------------------------



------------------------------------------------------------------------------------------------------------------------


