========================================================================================================================
事务
========================================================================================================================

------------------------------------------------------------------------------------------------------------------------
在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这句话能具体说明吗?

    就是语句开始执行前 创建一个read-view


------------------------------------------------------------------------------------------------------------------------
隔离级别的理解

    读未提交：   别人改数据的事务 尚未提交，我在我的事务中 也能读到
    读已提交：   别人改数据的事务 已经提交，我在我的事务中 才能读到
    可重复读：   别人改数据的事务 已经提交，我在我的事务中 也不去读      // 类似 快照

    串行：      我的事务尚未提交，别人就别想改数据                    // 读写、写写 -> 互斥     读读并行

    这4种隔离级别，并行性能依次降低，安全性依次提高

------------------------------------------------------------------------------------------------------------------------
隔离级别的理解

    对于我读别人

        1、判断依据  ->  commit

        2、我可以改变 自身隔离级别          ->  来获取别人 未提交的数据    （牺牲 安全性）


    对于别人读我

        1、我能主导的就是   ->  要不要commit

        2、他可以改变 自身隔离级别          ->  来获取我  未提交的数据     （牺牲 安全性）


    --------------------------------
    而最终拿到的结果，都是视图给(维护)的

------------------------------------------------------------------------------------------------------------------------
关于隔离级别的理解：

    1、read uncommitted

        可以看到未提交的数据（脏读），举个例子：别人说的话你都相信了，但是可能他只是说说，并不实际做。

    2、read committed

        读取提交的数据。但是，可能多次读取的数据结果不一致（不可重复读，幻读）。用读写的观点就是：读取的行数据，可以写。

    3、repeatable read（MySQL 默认隔离级别）

        可以重复读取，但有幻读

        读写观点：

            读取的数据行不可写，但是可以往表中新增数据

            在MySQL中，其他事务新增的数据，看不到，不会产生幻读

            采用多版本并发控制（MVCC）机制解决幻读问题

    4、serializable

        可读，不可写

        像Java中的锁，写数据必须等待另一个事务结束



========================================================================================================================
事务隔离      // 视图 +  MVCC（多版本并发控制）               // 视图快照  ->  视图数组（活跃事务ID）  ==>  加锁  ->  保证原子性
========================================================================================================================

------------------------------------------------------------------------------------------------------------------------
事务数组        // 活跃trx_id 列表

    事务ID，虽然在生成的时候保证了 有序递增，但每个事务的 生命周期 是不确定的。
    所以，可能出现，虽然落在高、低水位之间，但却是已经提交了的事务。
    这时，就需要根据，活跃数组中具体的值(row trx_id)，来判断 行记录当前版本 是否是在当前事务之前，就已经提交的事务。

------------------------------------------------------------------------------------------------------------------------
Innodb 要保证这个规则：事务启动以前所有还没提交的事务，它都不可见。

    但是只存一个 已经提交事务的最大值(低水位) 是不够的。
        因为存在一个问题，那些比 最大值(低水位) 小的事务，之后也可能更新

    所以事务启动的时候还要保存“现在正在执行的所有事物ID列表”，如果一个row trx_id 在这列表中，也要不可见。

------------------------------------------------------------------------------------------------------------------------
当开启事务时，需要 保存活跃事务的数组（A），然后获取高水位（B）。
我的疑问就是，在这两个动作之间（A和B之间）会不会产生新的事务？如果产生了新的事务，那么这个新的事务相对于当前事务就是可见的，不管有没有提交。

    是加了锁的，保证了A-B的原子操作：

        代码实现上，获取视图数组 和 高水位，
        是在 事务系统的 锁保护下 做的，可以认为是原子操作，期间不能创建新事务。




========================================================================================================================
读已提交、可重复读、当前读
========================================================================================================================



------------------------------------------------------------------------------------------------------------------------
事务隔离的本质实现: 两阶段锁协议 + MVCC（多版本并发控制）

------------------------------------------------------------------------------------------------------------------------
事务的可重复读的能力是怎么实现的？

    可重复读 的核心就是 一致性读（consistent read）

    而事务 更新数据 的时候，只能用 当前读，如果 当前记录的行锁 被其他事务占用 的话，就需要进入 锁等待




========================================================================================================================
磁盘、IO、随机读写、顺序读写
========================================================================================================================

------------------------------------------------------------------------------------------------------------------------
磁盘读取时间基本概念

    寻道时间    表示磁头在不同磁道之间移动的时间。
    旋转延迟    表示在磁道找到时，中轴带动盘面旋转到合适的扇区开头处。
    传输时间    表示盘面继续转动，实际读取数据的时间。

    7200转/min
        旋转一周需要8.33ms，寻道约10ms
        所以整个磁盘读取时间在一个磁道上是10ms级的

------------------------------------------------------------------------------------------------------------------------
计算机存储设备 一般分为两种：
    1、内存储器(main memory)
    2、外存储器(external memory)


    不同容量的存储器，访问速度差异悬殊：

        磁盘(ms级别) << 内存(ns级别)， 10W 倍

        若内存访问需要 1s，则一次外存访问需要 1天
        为了避免1次外存访问，宁愿访问内存100次...所以将最常用的数据存储在最快的存储器中
------------------------------------------------------------------------------------------------------------------------
预读

    从磁盘中读 1B，与读写 1KB 的时间成本几乎一样


局部预读性原理

    考虑到磁盘IO是非常高昂的操作，计算机操作系统做了一些优化：
        当一次IO时，不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内

    因为 局部预读性原理 告诉我们：
        当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。

    每一次IO读取的数据我们称之为一页(page)
        具体一页有多大数据跟操作系统有关，一般为4k或8k。
        也就是我们读取一页内的数据时候，实际上才发生了一次IO

    这个理论对于索引的数据结构设计非常有帮助


------------------------------------------------------------------------------------------------------------------------
    索引查询的数据主要受限于硬盘的I/O速度，查询I/O次数越少，速度越快，所以B树的结构才应需求而生；
    B树的 每个节点的元素 可以视为一次I/O读取，树的高度表示最多的I/O次数，
    在相同数量的总元素个数下，每个节点的元素个数越多，高度越低，查询所需的I/O次数越少；

    假设，一次硬盘一次I/O数据为8K，索引用int(4字节)类型数据建立，
    理论上一个节点最多可以为2000个元素，2000*2000*2000=8000000000，80亿条的数据只需3次I/O（理论值）
    可想而知，B树作为索引的查询效率有多高；

------------------------------------------------------------------------------------------------------------------------
随机读写 与 顺序读写

    顺序写 磁头几乎不用换道，或者换道的时间很短
    随机写 会导致磁头不停地换道，造成效率的极大降低

    -------------------
    顺序读写    读取一个大文件

    随机读写    读取多个小文件


------------------------------------------------------------------------------------------------------------------------
顺序读写 比 随机读写 快

    传输时间

        顺序读写：主要时间花费在了传输时间，而这个时间两种读写可以认为是一样的。

        随机读写：需要多次寻道和旋转延迟，而这个时间可能是传输时间的许多倍。

    预读          // 类比 有序数组(连续空间) 对CPU缓存友好

        顺序读写：磁盘会预读，预读即在读取的起始地址连续读取多个页面
                （现在不需要的页面也读取了，这样以后用时就不用再读取，当一个页面用到时，大多数情况下，它周围的页面也会被用到）

        随机读写：因为数据没有在一起，将预读浪费掉了

    文件系统的overhead
        读写一个文件之前，得一层层目录找到这个文件，以及做一堆属性、权限之类的检查。

    查找磁盘可用空间的耗时
        小文件，这些时间消耗的占比就非常大了

------------------------------------------------------------------------------------------------------------------------
随机关注IOPS，顺序关注吞吐量

    随机读写的话，每次IO操作的 寻址时间和旋转延时 都不能忽略不计，而这两个时间的存在也就 限制了IOPS的大小；

    而顺序读写，可以忽略不计 寻址时间和旋转延时，主要花费在 数据传输的时间上。


------------------------------------------------------------------------------------------------------------------------
局部预读性原理         // 相同的还有 有序数组(空间连续) 的读取

    当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。
    每一次IO读取的数据我们称之为一页(page)

    具体一页有多大数据跟操作系统有关，一般为4k或8k，也就是我们读取一页内的数据时候，实际上才发生了一次IO

    这个理论对于索引的数据结构设计非常有帮助。


------------------------------------------------------------------------------------------------------------------------
访问磁盘和内存索引涉及磁盘(sata，ssd，nvm)读写性能，以及内存读写性能，可否给一些数值方便直观认识?

    我估计你要的是这个：

    This group of numbers is from a presentation Jeff Dean gave at a Engineering All-Hands Meeting at Google.

    L1 cache reference                                      0.5 ns
    Branch mispredict                                         5 ns
    L2 cache reference                                        7 ns
    Mutex lock/unlock                                       100 ns
    Main memory reference                                   100 ns          // 内存   ->  100 ns
    Compress 1K bytes with Zippy                         10,000 ns
    Send 2K bytes over 1 Gbps network                    20,000 ns
    Read 1 MB sequentially from memory                  250,000 ns
    Round trip within same datacenter                   500,000 ns
    Disk seek                                        10,000,000 ns          // 磁盘   ->  10,000,000 ns      ==> 10万倍
    Read 1 MB sequentially from network              10,000,000 ns
    Read 1 MB sequentially from disk                 30,000,000 ns
    Send packet CA->Netherlands->CA                 150,000,000 ns
------------------------------------------------------------------------------------------------------------------------




========================================================================================================================
索引、B+树、树高、IO次数
========================================================================================================================
                                                   // B树、B+树详解  - https://www.cnblogs.com/lianzhilei/p/11250589.html
------------------------------------------------------------------------------------------------------------------------
B树 - 树高 - IO次数

    索引查询的数据 主要受限于硬盘的I/O速度，查询I/O 次数越少，速度越快，所以B树的结构才应运而生；

    B树的每个节点的元素 可以视为一次I/O读取，树的高度 表示最多的I/O次数；

    在元素总数量相同的情况下，每个节点的 元素个数越多（子节点个数越多），高度越低，查询所需的I/O次数越少；

        假设，一次硬盘I/O数据为8K，索引用 int(4字节)类型 数据建立，理论上一个节点 最多可以为2000个元素，

        2000^3 = 80亿，80亿条的数据只需3次I/O（理论值），可想而知，B树做为索引的查询效率有多高；

    另外也可以看出同样的总元素个数，查询效率和树的高度密切相关

------------------------------------------------------------------------------------------------------------------------
B树(B-Tree) 与 B+树(B-Plus Tree)           // B-Tree：Balance Tree  平衡树

    B树  内部节点中的元素 存储了指针和数据。
    B+树 内部节点中的元素 只存储了指向子节点的指针，只作为索引，所以相对于B树 内部节点占用的空间更小。

    B树
        子结点 存储了 data

    B+树     // 结构近似 跳表      ->      多级索引 + 链表(data)

        子结点      -> 多级索引    ——> 未存储 data ，仅作为 叶子结点 的索引

        叶子结点    ->  链表       ——> 有序链表，存储有数据


------------------------------------------------------------------------------------------------------------------------
innoDB 自增主键

    自增方式的主键，保障了插入时数据的有序性，减少了页的分裂


    插入  ->  追加          // 仅针对 主键ID 的索引    ===>  而 普通索引，没有递增约束，所以还是会发生 中间插入 -> 导致页分裂

        避免了B+树结点元素的 中间插入，导致的页分裂

        采用自增，相当于新insert的数据都比前一个要大
        不涉及到挪动其他记录，也不会触发叶子节点的分裂

------------------------------------------------------------------------------------------------------------------------
页分裂、页合并

    页          ->      B+树的 结点

    data        ->      结点中的 元素




------------------------------------------------------------------------------------------------------------------------

B+树

    父结点 分支出 M个子结点（1个结点 -> 包含N个元素）

------------------------------------------------------------------------------------------------------------------------
为什么说 B+树 比 B树 更适合数据库索引？

    1、B+树的磁盘  读写代价更低

        B+树的内部结点 并没有指向 关键字具体信息的指针。

        因此其内部结点 相对B树更小，

        如果把 所有同一内部结点的关键字 存放在同一盘块中，那么盘块所能容纳的 关键字数量也越多。

        一次性读入内存 中的需要查找的关键字 也就越多，相对来说 IO读写次数 也就降低了。


    2、B+树查询效率  更加稳定

        由于 非叶子结点 并不是最终指向文件内容的结点，而只是 叶子结点中关键字 的索引。

        所以 任何关键字的查找 必须走一条 从root结点到叶子结点 的路。

        所有关键字查询的 路径长度相同，导致每一个数据的查询 效率相当。


    3、B+树便于  范围查询（最重要的原因，范围查找是数据库的常态）       // B树的范围查找用的是 中序遍历，而B+树用的是 链表遍历

        B树 在提高了IO性能的同时 并没有解决元素遍历效率低下的问题，

        正是为了解决这个问题，B+树应用而生。

        B+树 只需要去遍历叶子节点 就可以实现整棵树的遍历。

        而且在数据库中 基于范围的查询 是非常频繁的，而 B树 不支持 这样的操作 或者说效率太低。


------------------------------------------------------------------------------------------------------------------------
二叉树的搜索效率最高，实际上 MySQL索引 却并不使用二叉树

    索引 的存储：

        索引是以 树形 存储在磁盘中     ->   持久化了 完整的 搜索树 结构

            更新数据时，同步更新 索引B+树，并持久化到磁盘

            读取时，搜索树已提前创建，通过IO，直接走 树搜索 即可

    数据 存储的过程：

        1、写一份保存到磁盘

        2、写一份保存在索引      ->   以 B+树的结构 保存在磁盘


------------------------------------------------------------------------------------------------------------------------
索引的由来，为何选取 多叉(B+树)，而不用效率最高的 二叉？

    表数据 结构化存储在 磁盘，我们不仅要存，还要取

    成千上万的数据，要快速查找，类比现实经验，图书馆海量图书的图书索引
    数据库也提出了 数据库索引

    且，索引必须是实时维护、同步更新
    提前生成的，不可能每次查的时候，再去生成...

    索引既要满足  ->  高效查询
    同时还要满足 实时维护、同步更新   ->  高效写

    索引存储 数据结构 的选取    ===>   二叉搜索树  ->  读写 O(logN)
    但是二叉的子节点过少 -> 导致树高过高 -> IO次数过多 -> 查询效率 最终还是低下
    索引，实际数据库索引 一般都选择 多叉树 -> 降低树高 -> 减少IO次数 -> 提高查询效率

    MySQL  ->  B+树


------------------------------------------------------------------------------------------------------------------------
B+树

    多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。
    二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。
    其原因是，索引不止存在内存中，还要写到磁盘上。



------------------------------------------------------------------------------------------------------------------------
B+树      // 一个结点  =  一个页

    构造索引 所用到的数据结构

    在实际设计中：
        我们把 一个结点 设为一个页

    为什么这么干呢：
        因为磁盘预读是以页为单位的
        所以这样的话 一页就代表访问一次磁盘，也就是代表 一次I/O操作



------------------------------------------------------------------------------------------------------------------------
B树： 我们假设如果是4阶的，那么每个结点最多3个关键字，最少两个（根节点最少1个）
    也就是说，我们最多也就要访问3次磁盘就可以完成访存，而传统的访存需要每一个关键字都进行访存，可以看出B树的优势
    注意B树的非叶结点不单单只有key值，还有key对应数据在磁盘的具体地址

B+树： 相对与B树而言，B+树的非叶结点值只存有key值，不含有卫星数据
    比较而言就会有更大的空间，就可以存更多的key值，就会显得更加“矮胖”，矮了操作数就相对会更少一些
    同时由于B+树增加了一个最小关键字的根结点，所以顺序访问更加便捷



------------------------------------------------------------------------------------------------------------------------
索引
    1. 主键索引的叶子结点存储了整一行的内容（聚簇索引），使用主键可以快速获取到整行的数据。

    2. 非主键索引的叶子结点存储的是主键的值，所以主键字段占用空间不宜过大。
        同时，其查找数据的过程称为“回表”，需要先查找自己得到主键值，再在主键索引上边查找数据内容。

    3. 索引的实现由存储引擎来决定，InnoDB使用B+树（N叉树，比如1200叉树），把整颗树的高度维持在很小的范围内
        同时在内存里缓存前面若干层的节点，可以极大地降低访问磁盘的次数，提高读的效率。

    4. B+树的插入可能会引起数据页的分裂，删除可能会引起数据页的合并，二者都是比较重的IO消耗
        所以比较好的方式是顺序插入数据，这也是我们一般使用自增主键的原因之一。

    5. 在Key-Value的场景下，只有一个索引且是唯一索引，则适合直接使用业务字段作为主键索引。


------------------------------------------------------------------------------------------------------------------------
索引只能定位到 page（结点），page内部怎么去定位 行数据（元素-data）

    内部有个 有序数组（存储 元素），二分法

------------------------------------------------------------------------------------------------------------------------
主键、普通索引的重建：

    二级索引重建 应该 先建索引 再做删除，如果有查询用到这个索引，此时索引已被删除，会导致业务抖动

    主键重建 不能采用drop这种方式去按操作，因为所有数据 都是以主键组织的，
    删了主键后，InnoDB会自己找一个主键组织数据，再次添加主键又会重新组织数据，
    重建表的次已达二次，我们可以直接 Optimiz 这个表


------------------------------------------------------------------------------------------------------------------------
没有主键的表，有一个普通索引，怎么回表？
    没有主键的表，InnoDB会默认创建一个Rowid做主键

------------------------------------------------------------------------------------------------------------------------
“N叉树”的 N值 在MySQL中是可以被人工调整的么？

    面试中题面越简单的问题越暗藏凶险，可见一斑...
    可以按照调整key的大小的思路来说；
    如果你能指出来5.6以后，可以通过page大小来间接控制应该能加分吧
    面试回答不能太精减，计算方法、前缀索引什么的一起上😄

------------------------------------------------------------------------------------------------------------------------
索引维护

    B+树为了维护索引的有序性，所以需要做索引维护

        页分裂
            页分裂使空间利用率降低了50%
            一个数据页满了，按照B+Tree算法，新增加一个数据页，叫做页分裂，会导致性能下降。空间利用率降低大概50%

        页合并
            当相邻的两个数据页利用率很低的时候会做数据页合并，合并的过程是分裂过程的逆过程

------------------------------------------------------------------------------------------------------------------------
自增主键的使用场景

    1、主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小
    2、业务字段做主键场景：
        1、只有一个索引
        2、该索引必须是唯一索引 这是典型的kv场景
            由于没有其他索引，估不用考虑其它索引叶子节点大小的问题，故将该值设为主键索引

------------------------------------------------------------------------------------------------------------------------
之前看过一遍文章，一直有疑惑：
一个innoDB引擎的表，数据量非常大，根据二级索引搜索 会比主键搜索快
文章阐述的原因是：主键索引和数据行 在一起，非常大 搜索慢
我的疑惑是：通过普通索引找到主键ID后，同样要跑一边主键索引，还望老师解惑...

    联合索引 -> 避免回表，数据量也小(不含行数据，只关联了主键)


------------------------------------------------------------------------------------------------------------------------
请教下，文中说 非主键索引 会存储主键的值，而文中举例的 非主键索引值 刚好没有重复
问下，如果记录表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,1)、(300,1)、(500,1) 和 (600,1)
那么 非主键索引 k=1的节点，应该记录100，200，300，500，600的值，是这样理解么？

    -   不是，非主键索引上 有5个值，分别是：

            （1，100），（1，200）... （1，600）


------------------------------------------------------------------------------------------------------------------------
如果插入的数据 是在主键树叶子结点 的中间，后面的所有页 如果都是满的状态，
是不是会造成 后面的每一页 都会去进行 页分裂操作，直到最后一个页 申请新页 移过去最后一个值

    不会不会，只会分裂 它要写入的那个页面
    每个页面之间 是用指针串的，改指针就好了，不需要 后面的全部挪动

------------------------------------------------------------------------------------------------------------------------
还有之前看到过说是 插入数据 如果是在 某个数据满了页的首尾，
为了减少数据移动和页分裂，会先去 前后两个页 看看是否满了，如果没满 会先将数据放到前后两个页上，不知道是不是有这种情况？

    对，为了增加空间利用率


------------------------------------------------------------------------------------------------------------------------
非聚集索引上 为啥 叶子节点的value 不是地址，这样可以 直接定位到整条数据，而不用 再次对整棵树 进行查询

    这个叫作“堆组织表”，MyISAM就是这样的，各有利弊
    你想一下如果修改了数据的位置的情况，InnoDB这种模式是不是就方便些

------------------------------------------------------------------------------------------------------------------------
如果我新建一张表，不加任何约束，也就是没有主键。
    当插入一定量的数据库后，我再给一个字段加上主键，那么这个主键会包含一行所有的数据吗？

    - 加主键 就会重建整张表

        没有指定主键约束，InnoDB也会有一个默认主键rowId

        加主键，就相当于删除掉原有的主键索引，然后再添加新的主键


------------------------------------------------------------------------------------------------------------------------
如果业务里只有很少的等值连接查询,是否可以把AHI关掉？

    AHI不是hash索引的意思，这个结构是帮innodb 快速找到叶子结点，所以对于range 查询也有优化作用的

------------------------------------------------------------------------------------------------------------------------
通过explain extend看到 in 会被转换为 or
    但是mysql里in是会先将()列表里面排序，然后在进行二分查找的方式去匹配是否满足，时间复杂度为O(logn)
    请问这里是in里面得值一个个取出来，然后再去索引的叶子节点上利用二分查找法去匹配该值？
    or的时间复杂度为O(n)，我理解的是根据or上的值去索引扫描到叶子节点得到该值，然后返回根节点继续扫描得到第二个值。
    如果按照我的理解那么or的效率应该比in高啊,请问老师是哪里出错了？

    -   不是，这样其实就已经是拿到结果了，不论是 a in () 还是 “a=X or a=Y”
        你说的这个过程就没有用上a的索引了
        只是在拿到值以后做的判断

------------------------------------------------------------------------------------------------------------------------
什么情况下创建索引才有意义？
    有这个索引带来的查询收益，大于维护索引的代价，就该建😄
    对于可能变成大表的表，实际上如果不建索引会导致全表扫描，这个索引就是必须的

------------------------------------------------------------------------------------------------------------------------
如何查看索引占用多少空间？
    可以估算出来的，根据表的行数和索引的定义。

------------------------------------------------------------------------------------------------------------------------
查看索引数的结构，比如多少个层，多少节点？
    同上，估算
    如果要精确的，就要解数据文件，这个工具可以看看 https://github.com/jeremycole/innodb_diagrams

------------------------------------------------------------------------------------------------------------------------
如何查看索引的利用率。比如我创建了一个索引，是否可以有记录这个索引被调用了多少次？
    performance_schema.table_io_waits_summary_by_index_usage能看到一些信息



------------------------------------------------------------------------------------------------------------------------
联合索引的技巧，总结：

    1、覆盖索引：如果查询条件使用的是普通索引（或是联合索引的最左原则字段），查询结果是联合索引的字段或是主键，不用回表操作，直接返回结果，减少IO磁盘读写读取正行数据

    2、最左前缀：联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符

        联合索引，
        根据创建联合索引的顺序，以最左原则进行where检索，比如（age，name）以age=1 或 age= 1 and name=‘张三’可以使用索引，
        单以name=‘张三’ 不会使用索引，考虑到存储空间的问题，还请根据业务需求，将查找频繁的数据进行靠左创建索引。

    4、索引下推：like 'hello%’and age >10 检索，MySQL5.6版本之前，会对匹配的数据进行回表查询。5.6版本后，会先过滤掉age<10的数据，再进行回表查询，减少回表率，提升检索速度


------------------------------------------------------------------------------------------------------------------------


========================================================================================================================
全局锁、表锁、行锁
========================================================================================================================


根据加锁范围，MySQL里面的锁可以分为：

    全局锁、表级锁、行级锁

------------------------------------------------------------------------------------------------------------------------
Server层：            // 所有引擎都支持
    全局锁、表级锁

引擎层：              // 引擎自身实现
    行级锁


------------------------------------------------------------------------------------------------------------------------
全局锁

对 整个数据库实例 加锁

使用场景：
    全库逻辑备份

MySQL提供加全局读锁的方法：
    Flush tables with read lock(FTWRL)

    这个命令可以使整个库处于只读状态。
    使用该命令之后，数据更新语句、数据定义语句和更新类事务的提交语句等操作 都会被阻塞。


风险：
    1.如果在主库备份，在备份期间不能更新，业务停摆
    2.如果在从库备份，备份期间不能执行主库同步的binlog，导致主从延迟

官方自带的逻辑备份工具mysqldump
    当mysqldump使用参数--single-transaction的时候，会启动一个事务，确保拿到一致性视图。
    而由于MVCC的支持，这个过程中数据是可以正常更新的。

一致性读是好，但是前提是引擎要支持这个隔离级别。
如果要全库只读，为什么不使用set global readonly=true的方式？
    1.在有些系统中，readonly的值会被用来做其他逻辑，比如判断主备库。所以修改global变量的方式影响太大。
    2.在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。
        而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高。



------------------------------------------------------------------------------------------------------------------------
表级锁
------------------------------------------------------------------------------------------------------------------------
MySQL里面表级锁有两种：
    表锁
    元数据锁（MDL -> meta data lock）

表锁的语法是:
    lock tables ... read/write

------------------------------------------------------------------------------------------------------------------------
lock tables / unlock tables

    可以用 unlock tables 主动释放锁，也可以在客户端断开的时候 自动释放。

    lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

    对于InnoDB这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。

------------------------------------------------------------------------------------------------------------------------
MDL：
    不需要显式使用，在访问一个表的时候会被 自动加上

MDL的作用：
    保证读写的正确性


在对一个表做 增删改查 操作的时候，加MDL读锁；
当要对表做 结构变更 操作的时候，加MDL写锁。

读锁之间不互斥。读写锁之间，写锁之间是互斥的，用来保证变更表结构操作的安全性。

MDL 会直到事务提交才会释放，在做表结构变更的时候，一定要小心不要导致锁住线上查询和更新。

------------------------------------------------------------------------------------------------------------------------
DML
    增删改数据

DDL
    修改表结构（修改、加字段...）

------------------------------------------------------------------------------------------------------------------------
例子里，为什么 session C 之后的所有“读”请求都会被阻塞？毕竟session C还没加上锁。难道这里隐含涉及到了意向锁？

    嗯，这个不是读写锁，是锁队列，一进去就开始影响后面的


------------------------------------------------------------------------------------------------------------------------
Online DDL的过程是这样的：
    1. 拿MDL写锁
    2. 降级成MDL读锁
    3. 真正做DDL
    4. 升级成MDL写锁
    5. 释放MDL锁

    1、2、4、5如果没有锁冲突，执行时间非常短。第3步占用了DDL绝大部分时间，这期间这个表可以正常读写数据，是因此称为“online ”


如果第四步升级为MDL写锁的时候，这个表的MDL锁有其他事务占着，那么这个事务会阻塞，等到可以拿到MDL写锁是吧？

    对，而且如果不幸一直拿不到，最后锁超时了，就只好回滚这个DD了操作。



------------------------------------------------------------------------------------------------------------------------
1、表锁

read     ->  线程 获取到 read 的权限

write    ->  线程 获取到 write + read（能写就能 读） 的权限


------------------------------------

lock tables t1 read, t2 write

    当前线程 可以 read          表t1
    当前线程 可以 write + read  表t2

    其他线程  write          表t1  -> 阻塞
    其他线程  read + write   表t2  -> 阻塞


------------------------------------------------------------------------------------------------------------------------
2、MDL（meta data lock）  元数据锁               // 表级锁  ->   增删改查 时，不允许修改表结构

    增删改查 时       ->  自动加  MDL read锁     ==>  禁止 修改表结构

    修改表结构 时     ->  自动加  MDL write锁    ==>  禁止 增删改查



    A 申请 MDL read锁
    B 申请 MDL read锁
    C 申请 MDL write锁     ->  阻塞          ===>    加等待时间，不要阻塞后面的 MDL read锁 线程
    D 申请 MDL read锁      ->  阻塞
    ...


长事务
    MDL 会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。

------------------------------------------------------------------------------------------------------------------------
行锁
------------------------------------------------------------------------------------------------------------------------
引擎层实现

    innoDB  ->  实现了行锁

    MyISAM  ->  未实现行锁

------------------------------------------------------------------------------------------------------------------------
细粒度锁
    减少锁冲突，提升业务并发度
------------------------------------------------------------------------------------------------------------------------
两阶段锁
    行锁 在需要的时候(执行SQL的时候)才加上，事务结束(commit/rollback) 才会释放

    ---------------------------------------
    加锁  ->  执行SQL时
    解锁  ->  事务commit/rollback 才会释放

------------------------------------------------------------------------------------------------------------------------
优化：
    把 最可能造成锁冲突、最可能影响并发度 的锁 尽量往后放

------------------------------------------------------------------------------------------------------------------------
死锁和死锁检测

    资源循环依赖  ->  死锁
------------------------------------------------------------------------------------------------------------------------
解除死锁：                       // 属于 DB层 的并发处理

    1、设置超时时间，等待超时，自动释放资源

    2、开启死锁检测，随机释放一个线程持有的资源，破局           // 死锁检测要耗费大量的 CPU 资源


------------------------------------------------------------------------------------------------------------------------
控制并发度：

    1、业务上优化


    2、转移：
        DB层 ->  应用层

        DB层 ->  DB中间件层

    -------------------------------------------
    控制并发度    ->     在 应用层 防止死锁的产生
    -------------------------------------------
    1、拦截：
        将流量 拦截在 应用层/中间层/上层

    2、延时分流：
        基本思路就是，对于相同行的更新，在进入引擎之前排队。
        这样在 InnoDB 内部就不会有大量的死锁检测工作了


------------------------------------------------------------------------------------------------------------------------
减少死锁的主要方向
    控制 访问相同资源 的并发事务量

    控制并发量 不但可以减少死锁的概率,也可以减少死锁检测带来的性能消耗.

------------------------------------------------------------------------------------------------------------------------
关于死锁检测innodb_deadlock_detect，是每条事务执行前都会进行检测吗？
如果是这样，即使简单的更新单个表的语句，当每秒的并发量达到上千的话，岂不是也会消耗大量资源用于死锁检测吗？


是个好问题
如果他要加锁访问的 行上有锁（发生了-锁冲突），他才要检测。

这里面我担心你有两个误解，说明下：
1. 一致性读不会加锁，就不需要做死锁检测；

2. 并不是每次死锁检测都都要扫所有事务。比如某个时刻，事务等待状态是这样的：

   B在等A，
   D在等C，
   现在来了一个E，发现E需要等D，那么E就判断跟D、C是否会形成死锁，这个检测不用管B和A


------------------------------------------------------------------------------------------------------------------------
掌握程度:
1.两阶段锁的概念是什么? 对事务使用有什么帮助?
2.死锁的概念是什么? 举例说明出现死锁的情况.
3.死锁的处理策略有哪两种?
4.等待超时处理死锁的机制什么?有什么局限?
5.死锁检测处理死锁的机制是什么? 有什么局限?
6.有哪些思路可以解决热点更新导致的并发问题?

------------------------------------------------------------------------------------------------------------------------
避免死锁
    在开发时一般都是 按照顺序加锁 来避免死锁。比如都是按照先拿t1,再拿t2.


------------------------------------------------------------------------------------------------------------------------
如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到：
    第一种，直接执行 delete from T limit 10000;
    第二种，在一个连接中循环执行 20 次 delete from T limit 500;
    第三种，在 20 个连接中同时执行 delete from T limit 500。
你会选择哪一种方法呢？为什么呢？

个人理解，选择第二种
    1.直接delete 10000可能使得执行事务时间过长
    2.效率慢点每次循环都是新的短事务，并且不会锁同一条记录        // 大事务分割成小事务
    3.效率虽高，但容易锁住同一条记录，发生死锁的可能性比较高

    // 方案3万万不可， 你锁我我锁你，检测来检测去。

------------------------------------------------------------------------------------------------------------------------
对思考题的思考：

我直观上感觉第一种和第二、三种在结果上不是等价的，因为 非原子性 操作，可能导致删除的内容是不一致的。

    你说的对😄，分成小事务 一定要确定 业务接受

------------------------------------------------------------------------------------------------------------------------
如果不考虑这个问题，还有个疑问请教老师：
事务、连接 和 session 的关系是什么？多个事务是否会造成额外的系统开销？


这是个好问题，一个连接就是一个session, 一个连接里可以先后创建多个事务（必须前一个结束才能启动下一个）
事务是无处不在的，大事务会造成额外的处理开销。

------------------------------------------------------------------------------------------------------------------------
第二种方法难道不会引起数据一致性问题吗？
如果在innodb中开启了自动事务并且没有显式用begin, commit来做的话，
在上一次循环结束和下一次循环开始之间如果有其他事务插入了新数据，而且正好位置也在前面500条，那不就不一致了么...


是的，好问题，加个order by id 😆 （假设id是这个表的自增主键）

------------------------------------------------------------------------------------------------------------------------
针对公司建表的要求，每个表要有个 createtime 字段，并且该字段要有索引

就是为了方便 方法2的操作, 目前线上的delete 全是 第二个操作,
创建 createtime 字段也方便将来 通过时间字段 导出数据。

------------------------------------------------------------------------------------------------------------------------
面试官问了行锁的原理，
我:行锁的实现原理？
面试官:对
我:不知道。。。
回来又看了几遍事务隔离的这几篇文章，发现确实不知道，老师能简单讲讲么？


主要是不知道面试官想知道多深的原理。。

我觉得08篇的内容可以讲讲的，每次更新产生一个新的数据版本，数据版本上加了锁。
如果来了另外一个更新，就会在这个新版本上被锁住。

然后看看面试官怎么追问。。。

------------------------------------------------------------------------------------------------------------------------
其实关于电影院总额的并发问题，之前我们的系统中遇到了，也需要限制退款是否会成负数;

当时的解决方案是 异步队列处理，线程池线程数为4，5个节点也就20个并发请求
更新余额时增加条件updateTime<now()，如果更新数目等于0就回滚事务，再把请求入队重试(限制了重入队次数，防止死循环)
客户端提交后即刻返回，然后等服务端通知

感觉刚好对应了老师讲的 死锁检测限制并发 的思路

------------------------------------------------------------------------------------------------------------------------
老师，我有一个问题：
例题中的订票系统，影院的余额表可不可以用 流水 的方式来记录，每天闲时汇总一次，这样就没有update只有insert和select sum了


嗯，如果是没有边界条件，比如一直加钱，这种可以的。
但是如果有“退款”的逻辑，就不行了。 只记日志，可能会给 扣成负数。

------------------------------------------------------------------------------------------------------------------------
本课举的例子，预售一年电影票导致CPU占用率100%，这怎么可能是死锁导致的呢？这种场景会出现互等锁的情景吗？

不会出现死锁，就是普通的单向锁等待
但是我们知道不会死锁，InnoDB可不知道，所以它得做死锁检测才能得到“没有死锁”这个结论，
我们说吃CPU的就是死锁检测这个逻辑

------------------------------------------------------------------------------------------------------------------------
我理解同一个行记录 在每个事务里面 只出现一次update，是不回出现死锁的吧？
还有一个问题，一个事务里面修改同一条记录两次，不是也会死锁了？


多个事务更新同一行，只是锁等待，如果还有更新别的行，可能造成循环依赖，导致死锁。

一个事务自己跟自己不会死锁
------------------------------------------------------------------------------------------------------------------------
老师，第6期留的问题，第7期答案里，有一点很困惑！！！

“如果在 Q4 语句执行之前到达，现象：没有影响，备份拿到的是 DDL 后的表结构。”
其他的都能理解，就是这点很困惑：Q2已经建立了快照，为什么还能备份快照后，对表结构修改后的表呢？不应该备份快照时的表结构吗？不然备份不就乱了吗？

- Q2是启动了一致性视图，但一致性视图不包含表结构哦

------------------------------------------------------------------------------------------------------------------------
秒杀场景对减库存操作也是针对同一行的update操作，这种高并发场景下是有超卖现象存在的，请问是为什么呢？

- 一定是不止用了MySQL

-------
- 程序逻辑判断的时候，到提交到数据库这段时间差里面，有判断前后的操作，打了一个时间差，然后就有负值的出现。
------------------------------------------------------------------------------------------------------------------------




========================================================================================================================
一致性读、当前读、行锁
========================================================================================================================

1、innodb支持RC和RR隔离级别，实现是用的 一致性视图(consistent read view)

2、事务在启动时会拍一个快照，这个快照是基于整个库的
    基于整个库的意思就是说，一个事务内，整个库的修改对于该事务都是不可见的(对于快照读的情况)
    如果在事务内 select 表t，另外的事务执行了DDL t表，根据发生时间，要么锁住、要么报错(参考第六章)

3、事务是如何实现的MVCC呢？
    1、每个事务都有一个事务ID,叫做 transaction id(严格递增)
    2、事务在启动时，找到 活跃事务ID 的 最小事务ID，记为 低水位
    3、事务在更新一条语句时，比如id=1改为了id=2，会把id=1和该行之前的row trx_id写到undo_log里，
        并且在数据页上把id的值改为2，并且把修改这条语句的 transaction_id 记在该行行头
    4、再定一个规矩，一个事务要查看一条数据时，必须先用该事务的 up_limit_id(低水位) 与 该行的transaction_id 做比对，
        如果 低水位 > row trx_id，那么可见.
        如果 低水位 < row trx_id，则只能去undo_log里去取。
            去undo log查找数据的时候，也需要做比对。必须 低水位 > row trx_id，才返回数据(可见)

4、什么是当前读？
    由于当前读都是先读后写，只能读当前的值，所以为当前读.

5、为什么RR能实现可重复读而rc不能，分两种情况

    1、快照读的情况下
        RR不能更新事务内的up_limit_id
        而RC每次会把 up_limit_id 更新为快照读之前 最新已提交事务的 transaction_id，则rc不能可重复读

    2、当前读的情况下
        RR是利用 record lock + gap lock 来实现的
        而RC没有gap，所以RC不能可重复读



------------------------------------------------------------------------------------------------------------------------
老师，
这两天反复读这篇文章，想到一个业务上的问题：减库存的场景
当前库存：num=200
假如多线程并发：
AB同时开启事务，A先请求到行锁，

A：
start transaction;
select num from t where num>0;先查询当前库存值（num>0）
update t set num=num-200; 库存减量

B：
start transaction;
select num from t where num>0;先查询当前库存值（num>0）
update t set num=num-200; 库存减量

----结果---
A：查询到num=200,做了库存减量成了0
B：事务启动后，查询到也是200，等 A 释放了行锁，B进行update，直接变成 -200
但是 B 查询时，时有库存的，因此才减库存，结果变成负的。
老师，对于这种场景，怎么避免减成负值？
给 select 加读锁或者写锁吗 ？这种select 加锁，对业务影响大吗？


这是个好问题，也是并发业务常见的问题。

一开始Select 加锁虽然可以，但是会比较严重地影响并发数。

比较简单的做法是update语句的where 部分加一个条件： where num >= 200 .
然后在程序里判断这个update 语句的 affected_rows：
如果等于1，那就是符合预期；
如果等于0，那表示库存不够减了，业务要处理一下去，比如提示“库存不足”


------------------------------------------------------------------------------------------------------------------------
事物就像一根线，排前排后看创建。
提交顺序要看清，否则结果搞不清。

------------------------------------------------------------------------------------------------------------------------

请教一个问题，业务上有这样的需求，A、B两个用户，如果互相喜欢，则成为好友。设计上是有两张表，一个是like表，一个是friend表，like表有user_id、liker_id两个字段，我设置为复合唯一索引即uk_user_id_liker_id。语句执行顺序是这样的：
以A喜欢B为例：
1、先查询对方有没有喜欢自己（B有没有喜欢A）
select * from like where user_id = B and liker_id = A
2、如果有，则成为好友
insert into friend
3、没有，则只是喜欢关系
insert into like

如果A、B同时喜欢对方，会出现不会成为好友的问题。因为上面第1步，双方都没喜欢对方。第1步即使使用了排他锁也不行，因为记录不存在，行锁无法生效。请问这种情况，在mysql锁层面有没有办法处理

------------------------------

关于这个问题，之前遇到过一个面试题有点类似，我想到的方案是，like表的结构可以类似

```
CREATE TABLE `like` (
`less_userid` BIGINT(20) NOT NULL DEFAULT '0',
`greater_userid` BIGINT(20) NOT NULL DEFAULT '0',
`like_flag` BIGINT(20) NOT NULL DEFAULT '0',
PRIMARY KEY(`less_userid`,`greater_userid`)
) ENGINE=InnoDB;
```

当然也可以用`less_userid`和`greater_userid`字段建唯一索引，而不是主键。

`less_userid`表示更小的userid， `greater_userid`表示更大的userid，`like_flag`表示谁like谁，

例如：
1 表示 `less_userid` like `greater_userid`，
2 表示 `greater_userid` like `less_userid`，
3 表示 互相like。

每个like都是直接插入，
如果发现唯一键冲突，update `like_flag`，取或运算，
如果`like_flag`等于3，说明互相like了。


------------------------------------------------------------------------------------------------------------------------
原来在同一行数据，最新版本的 row trx_id 是可能会 小于 旧版本的 row trx_id的，这里才搞明白(惭愧脸)。。

    主要看         事务提交时间，
    而不是简单看    事务启动时间。

------------------------------------------------------------------------------------------------------------------------
老师好,第45篇有说到.只读事物不分配trx_id,那么事务A为什么 事务Id为100啊?


是这样的，只读事务不分配id，是5.6以后的优化；
其实也不是不分配id，只是不分配自增的id，随机分配的那个也是事务id的。

这里简化为同一个机制（等同于都是按照老版本来说），比较便于理解哈

很细致👍





========================================================================================================================
change buffer 和 redo log
========================================================================================================================

redo log 用于优化 写磁盘，change buf 用于优化 读磁盘。

------------------------------------------------------------------------------------------------------------------------
redo log 主要节省的是 随机写 磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是 随机读 磁盘的 IO 消耗。

------------------------------------------------------------------------------------------------------------------------
redo log 与 change buffer(含磁盘持久化) 这2个机制，

    不同之处在于 ———— 优化了 整个变更流程 的 不同阶段

    ---------------------------------------------------------------
    先不考虑redo log、change buffer机制，

    简化抽象一个变更（insert、update、delete）流程：
        1、从磁盘读取 待变更的行 所在的数据页，读取至内存页中；
        2、对内存页中的行，执行变更操作；
        3、将变更后的数据页，写入至磁盘中；

        ------------------------------
        步骤1，涉及 随机 读磁盘IO；
        步骤3，涉及 随机 写磁盘IO；

    ---------------------------------------------------------------
    change buffer 机制， 优化了步骤1    —>  避免了随机读磁盘IO

    redo log      机制， 优化了步骤3    —>  避免了随机写磁盘IO，将随机写磁盘，优化为了顺序写磁盘(写redo log，确保crash-safe)


    ---------------------------------------------------------------
    在我们mysql innodb中， change buffer 机制不是一直会被应用到，
    仅当 待操作的数据页 当前不在内存中，需要先读磁盘加载数据页时，change buffer才有用武之地。
    redo log机制，为了保证crash-safe，一直都会用到。

    ---------------------------------------------------------------
    有无用到change buffer机制，对于redo log这步的区别在于：
        用到了 change buffer 机制时，在redo log中记录的本次变更，是记录 new change buffer item 相关的信息，
        而不是直接的记录物理页的变更。




------------------------------------------------------------------------------------------------------------------------
change buffer 是写内存，断电，会不会丢失呢？？？
    change buffer 一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致 change buffer 丢失呢？
    change buffer 丢失可不是小事儿，再从磁盘读入数据可就没有了 merge 过程，就等于是数据丢失了。会不会出现这种情况呢？



    change buffer 在 redo log 和 ibdata1 上也有一份

    ---------------------------------------------------------
    1、change buffer有一部分在内存、有一部分在ibdata。
        做merge操作，应该就会把change buffer里相应的数据持久化到ibdata。

    2、redo log里记录了数据页的修改以及change buffer新写入的信息，
        如果掉电，持久化的change buffer数据已经merge，不用恢复。


    主要分析没有持久化的数据，情况又分为以下几种:
        1、change buffer写入，redo log虽然做了fsync但未commit，binlog未fsync到磁盘，这部分数据丢失
        2、change buffer写入，redo log写入但没有commit，binlog以及fsync到磁盘，先从binlog恢复redo log，再从redo log恢复change buffer
        3、change buffer写入，redo log和binlog都已经fsync，那么直接从redo log里恢复。

------------------------------------------------------------------------------------------------------------------------
关于redo log 的顺序写

    这里的顺序写
        指的是 redo log 记录，顺序 写 redo log！！！

        写log文件，当然都是顺序写的！！！
        log文件，没有 B+Tree 这种数据结构的维护！！！

    不要理解为
        写磁盘（写表数据）

    本质上：
        是将 磁盘(表结构) 的 随机写，变为 redo log 的 顺序写！！！


        后台异步刷盘时，redo log -> 磁盘              // "脏页刷盘"

            写磁盘时，还是该怎样就怎样， 想维护 B+Tree 这种数据结构在磁盘中，该随机IO还得随机IO

            只是 同步更新 -> 后台异步更新，减少阻塞，提高性能.

    --------------------------------------------------------------
    像 写日志   这种 磁盘 顺序写，每秒几万次没问题!

    而 写表结构 这种 磁盘 随机写，不停的寻找切换 磁道，实时效率就太低了！






========================================================================================================================
缓冲池(buffer pool)                // 读                                     - https://juejin.im/post/6844903874172551181
========================================================================================================================
缓存(cache) - 缓冲池(buffer pool)机制

    应用系统分层架构，为了加速数据访问，会把最常访问的数据，放在缓存(cache)里，避免每次都去访问数据库。
    操作系统，会有缓冲池(buffer pool)机制，避免每次访问磁盘，以加速数据的访问。
    MySQL作为一个存储系统，同样具有缓冲池(buffer pool)机制，以避免每次查询数据都进行磁盘IO。

------------------------------------------------------------------------------------------------------------------------
InnoDB的缓冲池缓存什么？有什么用？

    缓存 表数据 与 索引数据

    把磁盘上的数据加载到缓冲池，避免每次访问都进行磁盘IO，起到加速访问的作用。

------------------------------------------------------------------------------------------------------------------------
速度快，那为啥不把所有数据都放到缓冲池里？
    凡事都具备两面性，抛开数据易失性不说，访问快速的反面是存储容量小：
        1、缓存访问快，但容量小，数据库存储了200G数据，缓存容量可能只有64G；
        2、内存访问快，但容量小，买一台笔记本磁盘有2T，内存可能只有16G；

    因此，只能把“最热”的数据放到“最近”的地方，以“最大限度”的降低磁盘访问。

------------------------------------------------------------------------------------------------------------------------
如何管理与淘汰缓冲池，使得性能最大化呢？


什么是预读？
    磁盘读写，并不是按需读取，而是按页读取.
    一次至少读一页数据（一般是4K），如果未来要读取的数据就在页中，就能够省去后续的磁盘IO，提高效率。


预读为什么有效？
    数据访问，通常都遵循“集中读写”的原则，使用一些数据，大概率会使用附近的数据，这就是所谓的“局部性原理”.
    它表明提前加载是有效的，确实能够减少磁盘IO。

按页(4K)读取，和InnoDB的缓冲池设计有啥关系？
    1、磁盘访问按页读取能够提高性能，所以缓冲池一般也是按页缓存数据；
    2、预读机制启示了我们，能把一些“可能要访问”的页提前加入缓冲池，避免未来的磁盘IO操作；

InnoDB是以什么算法，来管理这些缓冲页呢？
    最容易想到的，就是LRU(Least recently used)

    -------------------------------------------
    画外音：memcache，OS都会用LRU来进行页置换管理，但MySQL的玩法并不一样。



传统的LRU是如何进行缓冲页管理？
    最常见的玩法是，把入缓冲池的页放到LRU的头部，作为最近访问的元素，从而最晚被淘汰。

    这里又分两种情况：
        1、页已经在缓冲池里，那就只做“移至”LRU头部的动作，而没有页被淘汰；
        2、页不在缓冲池里，除了做“放入”LRU头部的动作，还要做“淘汰”LRU尾部页的动作；

    ---------------------------------
    为了减少数据移动，LRU一般用链表实现。


传统的LRU缓冲池算法十分直观，OS，memcache 等很多软件都在用，MySQL为啥这么矫情，不能直接用呢？

    这里有两个问题：
        1、预读失效；
        2、缓冲池污染；

------------------------------------------------------------------------------------------------------------------------
预读失效
    由于预读(Read-Ahead)，提前把页放入了缓冲池，但最终MySQL并没有从页中读取数据，称为预读失效。



优化 预读失效

    思路：
        1、让预读失败的页，停留在缓冲池LRU里的时间尽可能短；
        2、让真正被读取的页，才挪到缓冲池LRU的头部；

    以保证，真正被读取的热数据，留在缓冲池里的时间尽可能长。

    -----------------------------
    具体方法：

        1、将LRU分为两个部分：
            新生代(new sublist)
            老生代(old sublist)

        2、新、老生代 首尾相连                                      // 即：新生代的尾(tail) 连接着 老生代的头(head)

        3、新页（例如被预读的页）加入缓冲池时，只加入到 老生代头部：
            如果数据真正被读取（预读成功），才会加入到 新生代的头部
            如果数据没有被读取，则会比新生代里的“热数据页” 更早被淘汰出缓冲池

------------------------------------------------------------------------------------------------------------------------
MySQL 缓冲池污染

    当某一个SQL语句，要批量扫描大量数据时，可能导致把缓冲池的所有页都替换出去，导致大量热数据被换出，MySQL性能急剧下降，这种情况叫 缓冲池污染。

    例如，有一个数据量较大的用户表，当执行：
        select * from user where name like "%bebop%";

    虽然结果集可能只有少量数据，但这类like不能命中索引，必须全表扫描，就需要访问大量的页：
        1、把页加到缓冲池（插入老生代头部）；
        2、从页里读出相关的row（插入新生代头部）；
        3、row里的name字段和字符串bebop进行比较，如果符合条件，加入到结果集中；
        4、…直到扫描完所有页中的所有row…

    如此一来，所有的数据页都会被加载到新生代的头部，但只会访问一次，真正的热数据被大量换出。


扫码大量数据导致的缓冲池污染

    MySQL缓冲池加入了一个“老生代停留时间窗口”的机制：
        1、假设 T = 老生代停留时间窗口；
        2、插入老生代头部的页，即使立刻被访问，并不会立刻放入新生代头部；
        3、只有满足 “被访问” 并且 “在老生代停留时间”大于T ，才会被放入新生代头部；

========================================================================================================================
缓冲池(buffer pool)                   // 读 优化

    1、缓冲池(buffer pool)是一种常见的 降低磁盘访问 的机制；
    2、缓冲池通常以页(page)为单位缓存数据；
    3、缓冲池的常见管理算法是LRU，memcache，OS，InnoDB都使用了这种算法；
    4、InnoDB对普通LRU进行了优化：
        将缓冲池分为 老生代 和 新生代，入缓冲池的页，优先进入老生代，页被访问，才进入新生代，以解决预读失效的问题
        页被访问，且在老生代停留时间超过配置阈值(默认1s)的，才进入新生代，以解决批量数据访问，大量热数据淘汰的问题

    --------------------------------------------------------------------------------------------------------------------
    1、MySQL数据存储，包含 内存 与 磁盘 两个部分；
    2、内存缓冲池(buffer pool)以页为单位，缓存 最热的数据页(data page) 与 索引页(index page)；
    3、InnoDB以 变种LRU算法 管理缓冲池，并能够解决 “预读失效” 与 “缓冲池污染” 的问题；



========================================================================================================================
写缓冲(change buffer)                  // 写 优化                            - https://juejin.im/post/6844903875271475213
========================================================================================================================


对于读请求，缓冲池(buffer pool)能够减少磁盘IO，提升性能。问题来了，那写请求呢？


写缓冲(change buffer)
    降低写操作的磁盘IO，提升数据库写性能的一种机制                            // 减少一次随机读

    在MySQL5.5之前，叫插入缓冲(insert buffer)，只针对insert做了优化；
    现在对delete和update也有效，叫做写缓冲(change buffer)

什么时候缓冲池中的页，会刷到磁盘上呢？

    定期刷磁盘，而不是每次刷磁盘，能够降低磁盘IO，提升MySQL的性能。
    批量写，是常见的优化手段。


是否会出现一致性问题呢？

    并不会：
        1、读取，会命中缓冲池的页；
        2、缓冲池LRU数据淘汰，会将“脏页”刷回磁盘；
        3、数据库异常奔溃，能够从redo log中恢复数据；

------------------------------------------------------------------------------------------------------------------------
1、假如要修改页号为4的索引页，而这个页正好 在 缓冲池内：
    1、直接修改缓冲池中的页，一次内存操作；
    2、写入redo log，一次磁盘顺序写操作；                         // 像写日志 这种顺序写，每秒几万次没问题

2、假如要修改页号为40的索引页，而这个页正好 不在 缓冲池内：

    1、无 change buffer 时，必须一次 读IO：
        1、先把需要为40的索引页，从磁盘加载到缓冲池，一次磁盘随机读操作;      // 读IO一次
        2、修改缓冲池中的页，一次内存操作；
        3、写入redo log，一次磁盘顺序写操作；

    2、引入 change buffer：
        1、在写缓冲中记录这个操作，一次内存操作；                           // 可以看到，40这一页，并没有加载到缓冲池中。
        2、写入redo log，一次磁盘顺序写操作；

-----------------------------------
其性能与，这个索引页在缓冲池中，相近。

-----------------------------------
是否会出现一致性问题呢？

    也不会：
        1、数据库异常奔溃，能够从redo log中恢复数据；
        2、写缓冲不只是一个内存结构，它也会被定期刷盘到写缓冲系统表空间；
        3、数据读取时，有另外的流程，将数据合并到缓冲池；

------------------------------------------------------------------------------------------------------------------------
哪些场景会触发刷写缓冲中的数据：
    1、数据页被访问
    2、有一个后台线程，认为数据库空闲时；
    3、数据库缓冲池不够用时；
    4、数据库正常关闭时；
    5、redo log写满时；                  // 几乎不会出现redo log写满，此时整个数据库处于无法写入的不可用状态（阻塞，刷redo log）

------------------------------------------------------------------------------------------------------------------------
业务场景：                                                       // 适合开启 InnoDB的 写缓冲机制
    写多读少    ->      账单流水业务


不适合：
    1、数据库都是唯一索引；
    2、或者，写入一个数据后，会立刻读取它；

    ---------------------------------------------------------------
    这两类场景，在写操作进行时（进行后），本来就要进行进行页读取，
    本来相应页面就要入缓冲池，此时写缓存反倒成了负担，增加了复杂度。


适合：
    1、数据库大部分是非唯一索引；
    2、业务是写多读少，或者不是写后立刻读取；

    ----------------------------------------------------------------
    可以使用写缓冲，将原本每次写入都需要进行磁盘IO的SQL，优化定期批量写磁盘。



========================================================================================================================
MyISAM 的索引                                                               - https://juejin.im/post/6844903875284041741

MyISAM的 索引 与 行记录 是分开存储的，叫做 非聚集索引（UnClustered Index）

    其 主键索引与普通索引 没有本质差异：                  // MyISAM的 主键索引、普通索引  ->  无差别 ===> 都是 叶子结点  ->  行记录
                                                                                            -> 不存在 普通索引的 回表
        1、主键索引 的叶子结点，存储 主键，  与对应行记录的 指针
        2、普通索引 的叶子结点，存储 索引列，与对应行记录的 指针

        3、有连续聚集的区域单独存储行记录

----------------------------------
画外音：MyISAM的表 可以没有主键！！！

----------------------------------
主键索引与普通索引是两棵独立的索引B+树，通过索引列查找时：
    1、先定位到B+树的叶子结点
    2、再通过指针定位到行记录

----------------------------------
MyISAM B+树索引构造：
    1、行记录单独存储
    2、id   为PK， 有一棵id的索引树，  叶子指向行记录
    3、name 为KEY，有一棵name的索引树，叶子也指向行记录

------------------------------------------------------------------------------------------------------
MyISAM 行数据 关联到每一个  索引B+Tree              ->  行记录变更    ->   所有 B+Tree         需要同步更新
InnoDB 行数据 只关联到     主键B+Tree               ->  行记录变更    ->   只有主键B+Tree一处   需要同步更新

----------------------------------
MyISAM      ->  所有索引    不用回表
InnoDB      ->  普通索引    需要回表

========================================================================================================================
InnoDB 的索引


InnoDB的主键索引与行记录是存储在一起的，故叫做聚集索引（Clustered Index）：
    1、没有单独区域存储行记录
    2、主键索引的叶子节点，存储主键，与对应行记录（而不是指针）

    --------------------------------------
    画外音：因此，InnoDB的PK查询是非常快的。


因为这个特性，InnoDB的表必须要有聚集索引：
    1、如果表定义了PK，则PK就是聚集索引；
    2、如果表没有定义PK，则第一个非空unique列是聚集索引；
    3、否则，InnoDB会创建一个隐藏的row-id作为聚集索引；

    -----------------------------------------------------------
    聚集索引，也只能够有一个，因为数据行在物理磁盘上只能有一份聚集存储。
    InnoDB的普通索引可以有多个，它与聚集索引是不同的：
        普通索引的叶子节点，存储主键（也不是指针）

对于InnoDB表，这里的启示是：
    1、不建议使用较长的列做主键，例如char(64)，因为所有的普通索引都会存储主键，会导致普通索引过于庞大；
    2、建议使用趋势递增的key做主键，由于数据行与索引一体，这样不至于插入记录时，有大量索引分裂，行记录移动；

其B+树索引构造如上图：
    1、id为PK，   行记录和id索引树存储在一起
    2、name为KEY，有一棵name的索引树，叶子存储id

-----------------------------------------------------------
MyISAM和InnoDB都使用B+树来实现索引：
    1、MyISAM的索引与数据分开存储
    2、MyISAM的索引叶子存储指针，主键索引与普通索引无太大区别
    3、InnoDB的聚集索引和数据行统一存储
    4、InnoDB的聚集索引存储数据行本身，普通索引存储主键
    5、InnoDB一定有且只有一个聚集索引
    6、InnoDB建议使用趋势递增整数作为PK，而不宜使用较长的列作为PK



------------------------------------------------------------------------------------------------------------------------
insert的时候，写主键是肯定不能用 change buffer了，但是同时也会要写其它索引，而其它索引中的“非唯一索引”是可以用的这个机制的；

第二段，你搜出来的这个不太完整。
是这样的，change buffer的前身是insert buffer,只能对insert 操作优化；
后来升级了，增加了update/delete的支持，名字也改叫change buffer.


------------------------------------------------------------------------------------------------------------------------
merge   ->      把change buffer应用到旧的数据页，得到新的数据页的过程。

------------------------------------------------------------------------------------------------------------------------
1. 看完后感觉牵扯到之前的内容，又糊涂了。change buffer相当于推迟了更新操作，那对并发控制相关的是否有影响，比如加锁？
   我一直以为加锁需要把具体的数据页读到内存中来，才能加锁，然而并不是？

    锁是一个单独的数据结构，如果数据页上有锁，change buffer 在判断“是否能用”的时候，就会认为 否!

2. 在change buffer中有此行记录的情况下，再次更改，是增加一条还是原地修改？

    增加

3. purge行为之后应该不会再产生redo log了吧？

    是这样的，这个问题你分成两步来考虑。
        1、第一步，merge其实是从磁盘读数据页到内存，然后应用，这一步都是更新的内存，同时写redolog
        2、第二步，现在内存变成脏页了，跟磁盘数据不一样。之后就走刷脏页的流程。刷脏页也不用写。

4.从应用开发的角度看，还是由数据库保证唯一好。

    是否使用唯一索引，这个要看 业务有没有保证、性能是否有问题.


========================================================================================================================
老师你好，我说下我的理解

    1、change buffer 跟普通数据页一样 也是存在磁盘里，区别在于 change buffer 是在共享表空间ibdata1里

    2、redo log有两种：
        1、一种记录普通数据页的改动
        2、一种记录changebuffer的改动

    3、只要内存里 脏页（innodb buffer pool）里的数据发生了变化，就一定会记录 2中的一种redo log

        （对数据的修改 记录在change buffer里的时候，内存里是 没有这个物理页的，不存在脏页!）

    4、真正对磁盘数据页的修改，是通过 将内存里脏页的数据 刷回磁盘来完成的，而不是根据redo log


非常好，尤其括号里那句和最后一句！！！
========================================================================================================================

redo日志有分几十种类型的

redo log做的事情，简单讲就是 记录页的变化（WAL将页变化的乱序写转换成了顺序写）。

页是分多种的，比如 B+树索引页（主键 / 二级索引）、undo页（数据的多版本MVCC）、以及现在的change buffer页等等，
这些页被redo-log记录后，就可以不着急刷盘了。

change buffer记录索引页的变化；
但是change buffer本身也是要持久化的，而它持久化的工作和其他页一样，交给了redo日志来帮忙完成；
redo日志记录的是change buffer页的变化。

change buffer 持久化文件是 ibdata1
索引页         持久化文件是 t.ibd


========================================================================================================================
1.change buffer和redo log刷新到磁盘文中存储的位置不同：ibdata 和 t.ibd
2.redo log记录 内存中数据页的变更，同时也要记录change buffer的变更，
    因为change buffer的操作是不会将磁盘中的数据读取到内存中进行修改的，也就是说内存中不存在该数据的脏页，
    那为了保证更新操作的存在，则需要通过redo log来记录，防止更新操作的丢失，比如宕机后保证更新操作记录仍然在
3.当mysql未宕机时，redo log写满后需要移动check point点时，通过判断内存中数据和磁盘是否一致，即是否是脏页来刷新到磁盘中；
    当mysql宕机后，没有内存即没有脏页,通过redo log来恢复脏页

------------------------------------------------------------------------------------------------------------------------
redo log 重放，使内存变脏


------------------------------------------------------------------------------------------------------------------------
会导致change buffer丢失，会导致本次未完成的操作数据丢失，但不会导致已完成操作的数据丢失。

    change buffer中分两部分：一部分是本次写入未写完的，一部分是已经写入完成的

            1、针对未写完的，此部分操作，还未写入redo log，因此事务还未提交，所以没影响。
            2、针对已经写完成的，可以通过redo log来进行恢复。

    所以，不会对数据库造成影响。


作者回复: 优秀
------------------------------------------------------------------------------------------------------------------------
change buffer和数据页一样，也是物理页的一个组成部分，数据结构也是一颗B+树，这棵B+树 放在共享表空间中，默认ibdata1中。

change buffer 写入系统表空间 机制，应该和 普通表的脏页刷新到磁盘 是相同的机制————checkpoint机制；

之所以change buffer要写入系统表空间，是为了保证数据的一致性
    change buffer做修改时需要写redo log，在做恢复时需要根据redo log来恢复change buffer，
    若是不进行change buffer写入系统表空间，也就是不进行持久化，
    那么在change buffer写入内存后掉电（也就是篇尾提出的问题），则无法进行数据恢复。

    这样也会导致 索引中的数据 和 表的相应列中的数据 不一致。

change buffer 写入到了系统表空间，merge 的时候会先查询change buffer里对应的记录，然后进行merge，
因为change buffer B+树的key是表空间ID，所以查询根据表空间ID 查询change buffer会很快。


------------------------------------------------------------------------------------------------------------------------
change buffer 持久化

    change buffer 也会持久化到 表中     ->  系统表空间 ibdata         ->  对应的内部 系统表名为SYS_IBUF_TABLE


    因此在异常关机的时候，不会丢失!!!

------------------------------------------------------------------------------------------------------------------------
不会导致change buffer丢失。

因为在更改change buffer 时，也会写redo log，也需要持久化。

change buffer 更新完成并且相应事务提交的情况下，
    首先要保证redo log落盘（二阶段提交），若此时掉电重启，则可以根据 redo 进行恢复;
若change buffer 更新完成但是相应事务未提交的情况下，
    则redo 有可能落盘了（redo 的组提交），也有可能未落盘，
    若落盘了，读取redo发现没有commit标志（还会进行lsn，binlog的对比），则回滚；
    若redo未落盘则也就不会出现前滚和回滚的情况，数据依旧一致。

------------------------------------------------------------------------------------------------------------------------
有点疑惑: 主键id也是唯一索引吧? 那我们的新增操作如何利用 change buffer呢?


    所以主键索引用不上，都是对于那些 二级索引 的才有效。

    一个insert语句要操作所有索引的嘛，收益在二级索引。


------------------------------------------------------------------------------------------------------------------------
老师讲的真清楚！但是我突然想到一个问题，
文中讲 change buffer 中存的内容是“在某个数据页更新什么”，
但是在update/insert时，确定这条记录更新/插入 在哪个数据页，不也是有一个查找的过程么？（肯定有一个一层层查找的过程，会路过很多数据页啊）
为了确定在哪个数据页操作，而遍历过的数据页也会读进内存作缓存吗？

好问题
是的，查找过程避不开，但是二级索引树的非叶子节点没多少，主要在磁盘上的还是叶子节点。


查找过程避不开

索引树的 一层(根)、二层，基本都在内存中，
索引树的非叶子节点也没多少


------------------------------------------------------------------------------------------------------------------------
1. 真正把数据更新到磁盘，是由change buffer做还是redo log做？
    数据更新到磁盘是这两个都不少，是内存直接写到磁盘的。

2. 插入新的一行的话，一定会有唯一primary key的啊，这样是不是插入就不能用change buffer?
    插入数据的时候，主键索引用不上，但是普通索引可以


------------------------------------------------------------------------------------------------------------------------
什么是 数据表空间 和 系统表空间

    比如有一个表a
        那么a.ibd 就是数据表空间；
        “表a的表结构”这个信息，存在ibdata1的系统表空间里；

------------------------------------------------------------------------------------------------------------------------
数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。
后面又说change是占用pool内存的，那到底占不占用buffer pool的内存


好问题

1. change buffer本身是占用内存的；
2. 但是chage buffer本身只是记录了“更新过程”，远远比数据页（一个16k）小。相比于把数据页读入内存，这个方式还是省了内存的。


------------------------------------------------------------------------------------------------------------------------
老师好，关于change buffer为什么需要持久化的问题，还是有点疑问想请教一下，我的理解如下：

1.既然change buffer的修改在事务提交时，在redo log中都有记录的，那么已经是crash safe的吧？
    是的

2.change buffer的持久化是不是考虑到随着事务的运行，内存中已经存放不下change buffer了，所以才考虑要持久化到系统表空间中去的？

    change buffer的写盘策略跟数据一样，内存放不下会触发落盘，还有checkpoint推进的时候也是可能会触发

------------------------------------------------------------------------------------------------------------------------
redo log      感觉是对  写数据     的优化
change buffer 是对     写普通索引  的优化


一切都是以 写入内存(脏页)，就快速返回

后台慢慢跑，或者主动强制刷


------------------------------------------------------------------------------------------------------------------------
change buffer  ->  本质上是一个 B+树       ->  存放在 共享表空间

使用change buffer后，可能导致 innodb_buffer_pool 的占用内存变大（因为要在内存里面维护这样一个树结构）

merge的合并时机会：
    1、master线程每1秒或者10秒刷新，随即选取changbuffer的叶子节点进行merge操作
    2、插入change buffer后，立即执行了读取操作
    3、change buffer的空间不满足要求时（当检测到插入的数据大于制定叶的容量限度时）

------------------------------------------------------------------------------------------------------------------------

聚簇索引
    索引即数据，数据即索引


二级索引(辅助索引)
------------------------------------------------------------------------------------------------------------------------
重学还是发现了问题：
对于唯一索引来说，需要将 数据页 读入内存，判断到没有冲突，插入这个值，语句执行结束
那么这里是只读【索引页】呢，还是会连带【数据页】一起读入内存？


作者回复: 赞重读发现的问题😆

如果是判断唯一索引的，就只读【索引页】就可以的，
但是因为 primary key 也有唯一约束，所以这个”索引“也需要判断冲突。

而 主键索引 上其实就是 数据了

---------------------------------------------
我理解：

    【索引页】   --->        普通索引页      ->      普通索引 叶子结点

    【数据页】   --->       【主键索引页】    ->      主键索引 叶子结点

---------------------------------------------
是不是可以这么理解  【数据页】  =  【主键索引页】
---------------------------------------------


------------------------------------------------------------------------------------------------------------------------

对于 change buffer 想要实现的更新，redo log 并不知道 它要怎么更新！！！

change buffer 是一棵B+树                                                        // change buffer  ==  B+树

    redo log       里面记录的是    ->  对 change buffer 这棵B+树 的更新

    change buffer  上记录的是      ->  数据页的更新动作


------------------------------------------------------------------------------------------------------------------------
小结

1、普通索引和唯一索引在读性能上，相差无几，由于普通索引还需要多做一些检索和判断操作，性能稍差，但可忽略，因为大概率这些操作是在内存中的数据页上进行操作的

2、普通索引和唯一索引在写性能上，也相差无几，由于唯一索引需要做唯一性校验，性能稍差，不过由于不能利用change buffer来优化性能，相比而言普通索引的写性能更加，普通索引可以借助change buffer来优化性能，写性能更好

    有个问题，普通索引写入时虽然不需要判断唯一性，但是如果重复的索引值较多，是需要处理怎么放置这些重复的值的吧？这个具体怎么处理呢？

3、如果程序逻辑可以保证字段值的正确性，建议使用普通索引，尤其是写多的场景更是如此，否则对于需要使用唯一索引来保证唯一性的只能用唯一索引了

4、change buffer本质上就是一块内存区域并且在buffer pool中开辟出来的，可动态调控大小，
    修改数据时如果数据在内存中，则直接修改，
    如果不在，在保证数据一致性的前提下，可以先将对数据的修改缓存在change buffer中，这样就能减少读盘的次数，以提高修改数据的效率！

    由于这样的特性，change buffer只能对普通索引适用，唯一索引/主键索引都不适用，因为她们需要唯一性的判断，需要将数据及时拿到内存中。


5、change buffer针对的操作包括：
    insert、delete、update

6、change buffer针对 写多及写后延迟读 的优化更佳

7、change buffer
    也会落盘持久化、也使用了WAL记日志

8、change buffer 中记录的是
    数据操作的历史记录

9、将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。
    除了访问这个数据页会触发 merge 外；
    系统有后台线程会定期 merge；
    在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作；
    如果change buffer快满了也会触发merge操作。


感谢，数据库性能优化真是深入灵魂的，我想应该有一个过程，不是一下子就想到这么玩可以的。

------------------------------------------------------------------------------------------------------------------------
如果某次写入使用了 change buffer 机制，之后主机异常重启，是否会丢失 change buffer 和数据。


不会丢失，留言区的很多同学都回答对了。

虽然是只更新内存，但是在事务提交的时候，我们把 change buffer 的操作也记录到 redo log 里了，
所以崩溃恢复的时候，change buffer 也能找回来。

在评论区有同学问到，merge 的过程是否会 把数据直接写回磁盘，这是个好问题。

这里，我再为你分析一下。

merge 的执行流程是这样的：
    1、从磁盘读入数据页到内存（老版本的数据页）；
    2、从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个），依次应用，得到新版数据页；
    3、写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。

到这里 merge 过程就结束了。
这时候，数据页 和 索引页（change buffer 对应的磁盘位置）都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。

------------------------------------------------------------------------------------------------------------------------
概念混用、混乱

    文章中提到的 内存、数据页

    特别是 【数据页】      比较混乱

    他说的【数据页】  多代指了  【index】+【data】


------------------------------------------------------------------------------------------------------------------------


========================================================================================================================
选错 索引
========================================================================================================================
根据经验大表增加索引的时候比较慢，这个是理解的，但是删除索引的时候能做到秒删，这个什么原理呢？

    删除的时候是 标记删除，所以很快。
    建索引 是要 扫描数据 和 真正生成索引树，是会慢些.


------------------------------------------------------------------------------------------------------------------------
我之前一直以为这个操作也是在存储层进行的。
那 执行器 ——调用——> 存储(引擎)层的接口 只能获取到 最原始的数据!!!

后续的加工，比如 order、join 、group by 操作也都是在 执行器 里进行的吗？对应的 buffer 和 内存临时表 也都是 server层 的东西？


是的，你提到的这些，都在 server层!!!

很早之前，连过滤数据 都在server层，后来有了 Index_Condition_Pushdown，下推了一点到 引擎层

------------------------------------------------------------------------------------------------------------------------
引擎层     ->  返回 原始数据

    条件过滤：Index_Condition_Pushdown(ICP) 在引擎层实现了

数据加工    ->  Server层

    order、join 、group by ...

------------------------------------------------------------------------------------------------------------------------
Index_Condition_Pushdown(ICP)                       // Mysql 5.6     ->    用索引 去表里取数据 的一种优化

    有了ICP，MySQL 在读取XX表前，继续检查满足company和address条件的记录，这个行为在引擎层完成。
    直接把过滤好的返回给Server层，就减少了Server层的操作。
    总之是把 之前在Server层 的 下推到引擎层 去处理。


------------------------------------------------------------------------------------------------------------------------
不要过度迷恋 优化
不要过度迷恋 技术
从业务量预估 优化和收益

原谅我偷懒的想法，一个学校每年预估2万新生，50年才100万记录，能节省多少空间，直接全字段索引。
省去了开发转换及局限性风险，碰到超大量迫不得已再用后两种办法


从业务量预估优化和收益，这个意识很好👍


------------------------------------------------------------------------------------------------------------------------
字符串字段 创建索引 的场景

方式有：
    1、直接创建完整索引，这样可能比较占用空间；
    2、创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；
    3、倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；
    4、创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。

在实际应用中，你要根据业务字段的特点选择使用哪种方式。
------------------------------------------------------------------------------------------------------------------------
我觉得建立索引和插入数据在实际生产过程中可能是相互迭代的。
先建立索引-->后插入数据-->再优化索引-->再插入数据，
所以文中说的几种方法都要知道下，具体不同情况不同看。

像人员表邮箱这个字段，会先建立全字符串索引，要是业务发展到人员表暴增，导致磁盘比较多，才会想到优化某种长度的字符串索引.


差不多是这样的
一般在你说的这个迭代之前，会再多一个“业务量预估”😆

========================================================================================================================
WAL
========================================================================================================================
    掌柜记忆                  记账粉板                           账本
    内存(buffer pool)        日志文件（redo log）                磁盘-数据文件

------------------------------------------------------------------------------------------------------------------------
脏页
    内存数据页 跟 磁盘数据页     内容 不一致

干净页
    内存数据页 跟 磁盘数据页     内容 一致


------------------------------------------------------------------------------------------------------------------------
SSD以及云主机的广泛运用，
像 Innodb 这种使用 WAL技术，似乎并不能发挥最大性能（我的理解：基于SSD的WAL 更多的只是起到 队列一样 削峰填谷的作用）。

对于一些数据量不是特别大，但读写频繁的应用（比如点赞、积分），有没有更好的引擎推荐。


    即使是SSD，顺序写也比随机写快些的。 不过确实没有机械盘那么明显。



------------------------------------------------------------------------------------------------------------------------
我的认识里，有一点不是很清楚。
memory这个存储引擎，最大的特性应该是把数据存到内存。
但是innodb也可以把数据存到内存，不但可以存到内存(innodb buffer size)，还可以进行持久化。
这样一对比，我感觉memory的优势更没有了。不知道我讲的对不对

    是，如我们文中说的，不建议使用普通内存表了哈


========================================================================================================================
MySQL 抖动
========================================================================================================================
1、MySQL抖一下是什么意思？
    抖我认为就是不稳定的意思，一个SQL语句平时速度都挺快的，偶尔会慢一下且没啥规律，就是抖啦！

2、MySQL为啥会抖一下？
    因为运行的不正常了，或者不稳定了，需要花费更多的资源处理别的事情，会使SQL语句的执行效率明显变慢。
    针对innoDB导致MySQL抖的原因，主要是InnoDB 会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。
    所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用 IO 资源并可能影响到了你的更新语句，
    都可能是造成你从业务端感知MySQL“抖”了一下的原因。

3、MySQL抖一下有啥问题？
    很明显系统不稳定，性能突然下降对业务端是很不友好的。

4、怎么让MySQL不抖？
    设置合理参数配配置，尤其是设置 好innodb_io_capacity 的值，并且平时要多关注脏页比例，不要让它经常接近 75%

5、啥是脏页？
    当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。
    按照这个定义感觉脏页是不可避免的，写的时候总会先写内存再写磁盘和有没有用WAL没啥关系？

6：啥是干净页？
    内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。

7：脏页是咋产生的？
    因为使用了WAL技术，这个技术会把数据库的随机写转化为顺序写，但副作用就是会产生脏页。

8：啥是随机写？为啥那么耗性能？
    随机写我的理解是，这次写磁盘的那个扇区和上一次没啥关系，需要重新定位位置，机械运动是很慢的即使不是机械运动重新定位写磁盘的位置也是很耗时的。

9：啥是顺序写？
    顺序写我的理解是，这次写磁盘那个扇区就在上一次的下一个位置，不需要重新定位写磁盘的位置速度当然会快一些。

10：WAL怎么把随机写转化为顺序写的？
    写redo log是顺序写的，先写redo log等合适的时候再写磁盘，间接的将随机写变成了顺序写，性能确实会提高不少。

------------------------------------------------------------------------------------------------------------------------
当内存不够用了，要将脏页写到磁盘，会有一个数据页淘汰机制（最久不使用），假设淘汰的是脏页，则此时脏页所对应的 redo log 的位置是随机的，
当有多个不同的脏页需要刷，则对应的 redo log 可能在不同的位置，
这样就需要把redo log的多个不同位置刷掉，这样对于redo log的处理不是就会很麻烦吗？（合并间隙，移动位置？）

另外，redo log的优势在于将磁盘随机写转换成了顺序写，如果需要将redo log的不同部分刷掉（刷脏页），不是就在redo log里随机读写了么？



好问题。

其实由于淘汰的时候，刷脏页过程不用动redo log文件的。

这个有个额外的保证，是redo log在“重放”的时候，如果一个数据页已经是刷过的，会识别出来并跳过。

------------------------------------------------------------------------------------
这个额外保证是如何做到的？能不能稍微解释下
通过刷脏页时数据页更新的timestamp 来对比redo log的timestamp？


LSN，每次写redo log都带的一个数字， 数据页上也有，对比大小的，因为太细节没有写到文章中。

------------------------------------------------------------------------------------
checkpoint 往前推 redo log 覆盖时，由redo log自身机制保证 对应脏页 是否已经被刷过

------------------------------------------------------------------------------------------------------------------------
innodb是如何知道一个页是不是脏页的，是有标记位还是通过redo log的ckeckpoint来确定的？


    每个数据页头部有LSN，8字节，每次修改都会变大。
    对比这个LSN跟checkpoint 的LSN，比checkpoint小的一定是干净页!!!
------------------------------------------------------------------------------------------------------------------------
我观察了下公司的数据库确实发现了抖动现象，有几个问题
1、Innodb_buffer_pool_pages_total这个值很大，百万级别的，而且数值不像是人为设置上去的，是怎么来的呢？
2、Innodb_buffer_pool_pages_dirty达到4万多的时候就开始flush了，脏页比例是75，这肯定是远达不到的，
    ssd磁盘，innodb_io_capacity是200，肯定可以提高。
    文章中说flush的触发条件有2个，一个是内存不够了，一个是redo log 满了，那么我这个场景是哪种情况呢


作者回复:
1、这个是innodb 数据页总是，过百万是正常的，16K一个，Bufree pool size 16G 就是100万了
2、你这个例子就是io_capacity设太小了...
------------------------------------------------------------------------------------------------------------------------
又思考了一下，请老师帮忙看一下理解的对不对：
buffer pool里维护着一个脏页列表，假设现在redo log 的 checkpoint 记录的 LSN 为 10，
现在内存中的一干净页有修改，修改后该页的LSN为12，大于 checkpoint 的LSN，则在写redo log的同时，该页也会被标记为脏页记录到脏页列表中。
现在内存不足，该页需要被淘汰掉，该页会被刷到磁盘，磁盘中该页的LSN为12，该页也从脏页列表中移除，
现在redo log 需要往前推进checkpoint，到LSN为12的这条log时，发现内存中的脏页列表里没有该页，且磁盘上该页的LSN也已经为12，
则该页已刷脏，已为干净页，跳过。


对的 👍
------------------------------------------------------------------------------------------------------------------------
1、“内存不够用了，要先将脏页写到磁盘“，redo log对应的空间会释放嘛？“redo log 写满了，要 flush 脏页”对应的内存页会释放嘛？

    redo log 的空间是循环使用的，无所谓释放。 对应的内存页会变成干净页。但是等淘汰的时候才会逐出内存

2、将脏页flush到磁盘上是直接将脏页数据覆盖到对应磁盘上的数据？还是从磁盘上取到数据后取根据redo log记录进行更新后再写入到磁盘？

    前者

3、redo log是怎么记录对应脏页是否已经flush了？如果断电了重启导致内存丢失，前面几章说通过redo log进行数据恢复那redo log又怎么去释放空间？

    不用记，重启了就从checkpoint 的位置往后扫。 如果已经之前刷过盘的, 不会重复应用redo log。


------------------------------------------------------------------------------------------------------------------------
很多测试人员再做压力测试的时候，出现刚开始 insert update 很快， 一会 就出现很慢，并且延迟很大.
大部分是因为redo log 设置太小 引起的，完美诠释.

👍 常见的误用场景
------------------------------------------------------------------------------------------------------------------------
flush   一般是指 刷脏页
purge   一般是指 清undo log
merge   一般是指 应用change buffer

========================================================================================================================
为什么表数据删掉一半，表文件大小不变？                             // delete  ->  逻辑删除     -> 标记
========================================================================================================================
1、为啥删除了表的一半数8据，表文文件大小没变化？

    因为 delete 命令，其实只是把 记录的位置、或者数据页，标记为了“可复用”，但磁盘文件的大小是不会变的。

    也可以认为是一种 逻辑删除
        所以物理空间没有实际释放，只是标记为可复用，表文件的大小当然不变!


2、如何才能删除表数据后，表文件大小就变小？

    重建表，消除表因为进行大量的增删改操作而产生的空洞，使用如下命令：

    1、alter table t engine=InnoDB

    2、optimize table t      (等于 recreate + analyze)

    3、truncate table t      (等于 drop     + create)

3、空洞是啥？咋产生的？

    空洞
        就是那些被标记可复用，但是还没被使用的存储空间

    使用
        delete  命令 删除数据会产生空洞，标记为可复用
        insert  新的数据，可能引起页分裂，也可能产生空洞
        update  操作，有时是一种先删后插的动作，也可能产生空洞


4、表的数据信息存在哪里？
    表数据信息可能较小也可能巨大无比，她可以存储在共享表空间里，也可以单独存储在一个以.ibd为后缀的文件里，
    由参数innodb_file_per_table来控制，
    老师建议总是作为一个单独的文件来存储，这样非常容易管理，并且在不需要的时候，使用drop table命令也能直接把对应的文件删除，
    如果存储在共享空间之中即使表删除了空间也不会释放。

5、表的结构信息存在哪里？

    首先，表结构定义占有的存储空间比较小

    在MySQL8.0之前，表结构的定义信息存在以.frm为后缀的文件里
    在MySQL8.0之后，则允许把表结构的定义信息存在系统数据表之中

    系统数据表，主要用于存储MySQL的系统数据，比如：数据字典、undo log(默认)等文件

------------------------------------------------------------------------------------------------------------------------
请问下分布式ID（雪花算法生成的ID）生成的索引会比自增长的ID性能低吗？
雪花算法生成的ID是越来越大的，但不是逐渐递增，长度用的的bitint，麻烦解答下，非常感谢。

    性能一样的，没有一定要“连续”，只要是递增
------------------------------------------------------------------------------------------------------------------------
1.truncate 会释放表空间吗？
    truncate 可以理解为 drop + create

2.重建表的时候如果没有数据更新，有没有可能产生页分裂和空洞？
    online 可以认为没有

3.页分裂是发生在索引还是数据上？
    数据也是索引哦

4.应用 row log 的过程，会不会再次产生 页分裂和空洞？
    可能会

5.不影响增删改，就是 online；相对 Server层 没有新建临时表，就是 inplace，这里怎么判断是不是相对 Server层 没有新建临时表？
    好问题，我放到明天答疑部分

------------------------------------------------------------------------------------------------------------------------
1、是不是 5.6 之后 所有的 alter 操作(增删字段、增删索引等)都是支持 online ddl
    不是哦，我文章里说的加 全文索引 就不online

2、如果 alter 都是 online ddl，那么是不是如果 alter操作 获取到 MDL写锁 时， 后面的查询需要 MDL读锁 会暂时阻塞，
    但是MDL会马上降为读锁 ，后面的操作会继续进行不会堵塞。等再升到写锁，后面操作又会暂时阻塞。

    对，这两个暂时，都是时间很短的

3、当 alter 降到 DML读锁 时 ， 这时候可以新增数据么 ， DML表级读锁 不会影响到 insert 或者 update的行锁么
    是，DML语句加的是MDL读锁，读读不冲突

4、如果将 alter 操作显式的放到事务里，事务不提交，另一个事务查询的时候会查询到alter 操作后的表结构，比如新增了一个字段。
    这个是什么原因 ，是否打破了 MVCC 的定义呢

    alter table 语句会默认提交前面的事务，然后自己独立执行😄
    --------------------------------------------------
    在事务里面用alter会有隐式提交，因为要保持事务一致性

------------------------------------------------------------------------------------------------------------------------
这里针对空洞提下问题：
1.删除有空洞，是因为标记了已删除可复用的节点位置，不会释放。
2.随机插入有空洞，是因为数据页分裂造成。
3.但更新有空洞，有点费解，我个人理解是更新是结合删除和插入的一个合并操作。
    删除后产生的空洞，在插入时不是应该就马上被复用了吗，毕竟主键是一致的。所以为什么更新会产生空洞呢？

    可以这么想下，如果1，2，3，4，5
    然后 update 把2改成6，如果原地修改，这个索引就不是“有序”的了


------------------------------------------------------------------------------------------------------------------------
我以前负责的一个系统就出现过这种情况，
突然有个表的sql执行很慢，后来觉得是此表增删的数据很多，碎片很多，就执行了optimize table，立马就好了。
看来就是老师文中说的，删除和增加都是空洞造成。

    👍，找到正主了😆
------------------------------------------------------------------------------------------------------------------------
既然mysql支持了打包数据排序模式，能够更紧凑的分配内存进行排序，那定义表结构的时候，
varchar(10)存储hello 和 varchar(100)存储hello的优势在哪里呢？

    以前不支持紧凑排序的时候有区别，现在 没啥差别了，小于256都差不多!

------------------------------------------------------------------------------------------------------------------------
一个机制
在重建表的时候，InnoDB 不会把整张表占满，每个页留了 1/16 给后续的更新用。
也就是说，其实重建表之后不是“最”紧凑的。


========================================================================================================================
count(*)
========================================================================================================================
count(字段) < count(主键 id) < count(1) ≈ count(*)

-------------------------------------------------------------------------
count(字段）       遍历整张表，需要取值，判断 字段 != null，按行累加；
count(id)         遍历整张表，需要取ID，判断 id  != null，按行累加；
count(1)          遍历整张表，【不需要】取值，返回的每一行放一个数字1，按行累加；
count(*)         【不需要取字段】，count(*)，按行累加；


------------------------------------------
MySQL官方给出的统计方式  ->  count(*)

    MySQL 对 count(*)做了针对性的优化
        对于count(*)来说，并不会把全部字段取出来，而是专门做了优化，不取值。
        count(*) 肯定不是 NULL，按行累加。

------------------------------------------
count(*)和count(1)   ->  不取字段值

减少  引擎层 -> server层   的数据返回

所以比 count(字段/id)   需要 返回值 的性能好

------------------------------------------
count(1) 执行得要比 count(字段/id) 快

    从引擎层 返回字段/id 给Server层，会涉及到  ->  解析数据行、以及拷贝字段值 的操作
------------------------------------------------------------------------------------------------------------------------
count（id）和count（这段）都是要把每一行的该字段值取出来，然后判断是否为空，那为什么count（id）的效率要高？

    count(id)可能会选择 最小的索引 来遍历
    而count(字段)的话，如果字段上没有索引，就只能选 主键索引

------------------------------------------------------------------------------------------------------------------------
1、值返回           // 引擎层  ->  Server层                 Server层要什么数据，引擎层就返回什么 原始数据
2、NULL校验         // Server层   处理数据                  Server层 对原始数据 做二次处理(check NULL + 统计)

------------------------------------------------------------------------------------------------------------------------

------------------------------------------------------------------------------------------------------------------------
1、请问计数用这个 MySQL + redis 方案如何：
    1、开启事务（程序中的事务）
    2、MySQL插入数据
    3、原子更新redis计数
    4、如果redis更新成功提交事务，如果redis更新失败回滚事务


    还是没解决我们说的一致性问题
    如果在3、4之间插入了 session-B 的逻辑呢

    ----------------------------------------
    最关键的地方是：
        Redis的更新和MySQL的插入，不是原子的。
        解决这个问题，可以加分布式锁，但是这样并行数就是1了，非常影响性能


2、 .net、java程序代码的事务 和 MySQL事务 是什么关系，有什么相关性？

    我估计就是
    启动事务（执行begin)，结束时提交（执行commit）吧
    没有了解过所有框架，不确定哈


------------------------------------------------------------------------------------------------------------------------
我看老师的例子事务级别应该都是 RR ，我偶然看到我们公司事务隔离级别是 RC 。
我比较惊讶，就去问 DBA 为什么是 RC 而不是默认的 RR 。 她说一般都是用的 RC ，我想问现在公司一般都是 RC 么， 请问老师现在用的隔离级别是什么 ？？
在我的印象里 ，RR 保证事务的隔离性会更好一些吧 。 我google了一下， RC 会不会在某些场景下出现一些问题，但是没有查出来相关结果。
老师能不能讲解一下，RC 的话会在哪些场景下会踩坑么 。 （我之前码代码都是按照 RR 级别下的思维码的代码）


    嗯，RC用得挺多的，                             // RDS -> 默认 RC
    使用RC，可能有问题，也可能没问题。
    RC本身的问题，其实前面我们说过一些，比如 不是一致性读。

    但是我觉得DBA不知道为什么这么选，这个是问题。可能只是因为“以前是这么用的”。

------------------------------------------------------------------------------------------------------------------------

两阶段提交
    就是为了给所有人一个机会，当每个人都说“我 ok”的时候，再一起提交！


------------------------------------------------------------------------------------------------------------------------
幻读的意思是
    在一个事务里面，后一个请求看到的 比 之前相同请求看到的，多了记录出来

------------------------------------------------------------------------------------------------------------------------
事务开启后，可能产生锁等待的更新语句 放到最后。减少锁等待时间的影响!


------------------------------------------------------------------------------------------------------------------------
MySQL 怎么知道 binlog 是完整的？

    一个事务的 binlog 是有完整格式的：
        statement 格式的 binlog，最后会有 COMMIT；
        row 格式的 binlog，最后会有一个 XID event。

    另外，在 MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog 内容的正确性。
    对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL 可以通过校验 checksum 的结果来发现。
    所以，MySQL 还是有办法验证事务 binlog 的完整性的。
------------------------------------------------------------------------------------------------------------------------
改帐均须动笔。纵为不变之帐，仍需覆写之

必须覆写,

事务1 update同一时刻, 事务2也update,
事务1, 2都必须抢锁, 才能执行各自的update逻辑,
不管update逻辑是什么, 都必须抢锁再update.
------------------------------------------------------------------------------------------------------------------------

========================================================================================================================
order by
========================================================================================================================
1、这种无条件查列表页除了全表扫还有其他建立索引的办法么？

    无条件查询如果只有order by create_time,即便create_time上有索引,也不会使用到。
        因为优化器认为走二级索引再去回表成本比全表扫描排序更高。
        所以选择走全表扫描,然后根据老师讲的两种方式选择一种来排序

    无条件查询但是是order by create_time limit m.如果m值较小,是可以走索引的.
        因为优化器认为根据索引有序性去回表查数据,然后得到m条数据,就可以终止循环,那么成本比全表扫描小,则选择走二级索引。
        即便没有二级索引,mysql针对order by limit也做了优化,采用堆排序。这部分老师明天会讲

2、如果加入 group by，数据该如何走？

    1、如果是group by a，a上不能使用索引的情况：
        是走 rowid排序

    2、如果是group by limit，不能使用索引的情况：
        是走 堆排序

    3、如果是只有group by a，a上有索引的情况：
        又根据选取值不同，索引的扫描方式又有不同

        select * from t group by a ———— 走的是 索引全扫描，至于这里为什么选择走索引全扫描，还需要老师解惑下
        select a from t group by a ———— 走的是 索引松散扫描，也就说只需要扫描每组的第一行数据即可，不用扫描每一行的值

3、老师之后的文章会有讲解 bigint(20) 、 tinyint(2) 、varchar(32) 这种后面带数字与不带数字有何区别的文章么？
    每次建字段都会考虑长度 ，但实际却不知道他有何作用？

    1、bigint 和 int

        加不加数字，都不影响能存储的值     ->   建议不加

        bigint(1) 和 bigint(19) 都能存储2^64-1范围内的值，int是2^32-1，只是有些前端会根据括号里来截取显示而已。

    2、varchar()   ->    就必须带

        因为varchar()括号里的数字，代表能存多少字符。

        假设varchar(2)，就只能存两个字符，不管是中文还是英文。
        目前来看varchar()这个值可以设得稍稍大点，因为内存是按照 实际的大小来分配 内存空间的，不是按照(n)值来预分配的。

    -----------------------------------------------
    回答得很好，需要注意的是255这个边界。
    小于255都需要一个字节记录长度，超过255就需要两个字节


------------------------------------------------------------------------------------------------------------------------
1、我还是想在确认之前问的问题。一个长连接，一条sql申请了sort_buffer_size等一系列的会话级别的内存，sql成功执行完，该连接变为sleep状态。
    这些内存只是内容会被清空，但是占用的内存空间不会释放？

    排序相关的内存在排序后，就free掉还给系统了

2、假设要给a值加1，执行器先找引擎取a=1的行，然后执行器给a+1，在调用接口写入a+1了数据。
    那么加锁不应该是在执行器第一次去取数据时，引擎层就加该加的锁？
    为什么要等到第二次调用写入数据时，才加锁。第一次和第二次之间，难道不会被其他事务修改吗？如果没有锁保证

    读的时候加了写锁的

3、始终没太明白堆排序是采用的什么算法，使得只需要对limit的数据进行排序就可以，而不是排序所有的数据再取前m条？

    堆排序要读所有行的，只读一次，我估计你已经理解对了😄


------------------------------------------------------------------------------------------------------------------------
基于早上知道的sort_buffer是在server层，我重新理解了下rowid排序的过程：
    1、执行器查看表定义，发现name、city、age字段的长度之和 超过 max_length_for_sort_data，所以初始化sort_buffer的时候只放入id和name字段。
    2、执行器调用存储引擎的读数据接口，依次获取满足条件的数据的id和name，存入sort_buffer。
    3、排序
    4、执行器根据limit条件筛选出id，再次调用引擎读数据的接口获取相应的数据，返回客户端。

整个过程实际上是被执行器拆成了两次查询，共调用两次存储层的读数据接口，所以总的扫描行数需要相加。（@b-@a=5000）
但是对于using index condition的场景，执行器只调用了一次查询接口，回表是由存储层来完成的，所以扫描行数只算一次，即只算走索引搜索的过程中扫描的行数。（@b-@a只会是4000）
不知道这么理解对不对？

    不仅对，而且非常好！👍👍
    把两个知识点连起来了。

    是的：
        1、rows_examined 就是“server层调用引擎取一行的时候”加1；
        2、引擎内部自己调用，读取行，不加1；

    再补充一个例子：
        加索引的时候，也要扫描全表，但如果是 inplace DDL（@第13篇），你会看到扫描行数是0，也是因为这些扫描动作都是引擎内部自己调用的。

------------------------------------------------------------------------------------------------------------------------
老师，有道面试题困扰了很久，求指教！
题目是这样的，a表有100条记录，b表有10000条记录，两张表做关联查询时，是将a表放前面效率高，还是b表放前面效率高？
网上各种答案，但感觉都没有十分的说服力，期待老师的指点！


    (这题目改成100万 和 10000万比较好)

    结论：自然是 小表驱动大表

    如果是考察语句写法
        这两个表谁放前面都一样，优化器会调整顺序选择合适的驱动表；

    如果是考察优化器怎么实现的
        你可以这么想，每次在树搜索里面做一次查找都是log(n)
        所以对比的是 100*log(10000) 和 10000*log(100) 哪个小
        显然是前者，所以结论应该是让 小表驱动大表。

========================================================================================================================
函数  ->  索引失效
========================================================================================================================
SQL逻辑相同，性能差异较大的，通过老师所讲学习到的，和平时碰到的，大概有以下几类：

    一、字段发生了转换,导致本该使用索引而没有用到索引
        1.条件字段函数操作
        2.隐式类型转换
        3.隐式字符编码转换
        （如果驱动表的字符集比被驱动表得字符集小，关联列就能用到索引，如果更大，需要发生隐式编码转换，则不能用到索引，latin < gbk < utf8 <utf8mb4）

    二、嵌套循环，驱动表与被驱动表选择错误
        1、连接列上没有索引,导致大表驱动小表,或者小表驱动大表(但是大表走的是全表扫描) --连接列上建立索引
        2、连接列上虽然有索引,但是驱动表任然选择错误。--通过straight_join强制选择关联表顺序
        3、子查询导致先执行外表在执行子查询,也是驱动表与被驱动表选择错误。
            - 可以考虑把子查询改写为内连接,或者改写内联视图(子查询放在from后组成一个临时表,在于其他表进行关联)
        4、只需要内连接的语句,但是写成了左连接或者右连接。比如select * from t left join b on t.id=b.id where b.name='abc'驱动表被固定,大概率会扫描更多的行,导致效率降低.
            - 根据业务情况或sql情况,把左连接或者右连接改写为内连接

    三、索引选择不同，造成性能差异较大
        1、select * from t where aid= and create_name > '' order by id limit 1;
            选择走id索引或者选择走(aid,create_time)索引,性能差异较大.结果集都有可能不一致
            - 这个可以通过where条件过滤的值多少来大概判断,该走哪个索引

    四、其它一些因素
        1、比如之前学习到的是否有 MDL X锁
        2、innodb_buffer_pool设置得太小,innodb_io_capacity设置得太小,刷脏速度跟不上
        3、是否是对表做了DML语句之后,马上做select,导致change buffer收益不高
        4、是否有数据空洞
        5、select选取的数据是否在buffer_pool中
        6、硬件原因,资源抢占

    原因多种多样，还需要慢慢补充。

------------------------------------------------------------------------------------------------------------------------
感觉 要使用索引， 就不能“破坏”索引原有的顺序。

    函数操作、隐式转换，都“破坏”了原有的顺序。

    ------------------------------------------------------------------------------------
    前一节的
    select * from t where city in (“杭州”, "苏州") order by name limit 100;
    同样是破坏了 (city, name) 联合索引的递增顺序，类似的还有使用联合索引，一个字段DESC，一个ASC。

    ----------------------
    “顺势而查”才能用上索引😆

------------------------------------------------------------------------------------------------------------------------
之前遇到过按时间范围查询大表不走索引的情况，如果缩小时间范围，又会走索引，
记得在一些文章中看到过结果数据超过全表的30%就会走全表扫描，但是前面说的时间范围查询大表，这个时间范围绝对是小于30%的情况，
想请教下老师，这个优化器都是在什么情况下会放弃索引呢？

    总体来说就是，哪种方式消耗更小，选哪种

------------------------------------------------------------------------------------------------------------------------
多表连接时，mysql是怎么选择驱动表和被驱动表的？

    在join那章节有讲到，主要看后面的筛选条件，筛选条件之后 数据更少的 会被作为驱动表。

------------------------------------------------------------------------------------------------------------------------
当主键是 整数类型，条件是 字符串 时，会走索引。

    字符串和数字 比较时：
        会把 字符串 -> 数字，所以隐式转换不会应用到字段上，而是应用在入参上，所以可以走索引。

    另外，select 'a' = 0 ; 的结果是1，说明无法转换成数字的字符串都被转换成0来处理了。

    ----------------------------------------------------------------
    select int_a = '0'          // 入参 '0' -> 0

    select 'a' = 0              // 'a'无法转换为数字，则统一转换为了 0

    ----------------------------------------------------------------
    同理，select "13m456" = 13，结果为 1

        说明为截断式的转换，遇到一个不能转换的停止转换，并且返回前面已经转换成功的数字作为结果
------------------------------------------------------------------------------------------------------------------------
为啥只查一行的语句，也执行这么慢？

    1、MySQL数据库本身被堵住了，比如：系统或网络资源不够
    2、SQL语句被堵住了，比如：表锁，行锁等，导致存储引擎不执行对应的SQL语句
    3、确实是索引使用不当，没有走索引
    4、是表中数据的特点导致的，走了索引，但回表次数庞大

------------------------------------------------------------------------------------------------------------------------

------------------------------------------------------------------------------------------------------------------------

========================================================================================================================
幻读  ->  间隙锁
========================================================================================================================
1、什么是幻读？

    幻读是指在同一个事务中，存在前后两次查询同一个范围的数据，但是第二次查询却看到了第一次查询没看到的行。

    注意，幻读出现的场景
        1、事务的隔离级别为可重复读，且是当前读
        2、幻读仅专指 新插入的行

2、幻读带来的问题？
    1、对行锁语义的破坏
    2、破坏了数据一致性

3、怎么避免幻读？
    存储引擎 采用 加间隙锁 的方式来避免出现幻读

4、为啥会出现幻读？
    行锁只能锁定存在的行，针对新插入的操作没有限定

5、间隙锁是啥？它怎么避免出现幻读的？它引入了什么新的问题？

    间隙锁，是专门用于解决幻读这种问题的锁，它锁的了行与行之间的间隙，能够阻塞新插入的操作

    间隙锁的引入也带来了一些新的问题，比如：并发度降低，可能导致死锁。

    注意，读读不互斥，读写/写读/写写是互斥的
    但是间隙锁之间是不冲突的，间隙锁会阻塞插入操作
    另外，间隙锁在可重复读级别下才是有效的             // Serializable 也有间隙锁

------------------------------------------------------------------------------------------------------------------------
什么是幻读?
    幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。
    （幻读在当前读下才会出现；幻读仅专指 新插入的行）

如何解决幻读?
    间隙锁（gap lock）:（两个值之间的锁）
    间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。
    间隙锁为开区间
    next-key-lock为 前开后闭区间

间隙锁引入什么问题？
    可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。

    间隙锁在RR级别下才有效，RC级别下无间隙锁。

不使用间隙锁方法:
    使用 读提交隔离级别 + binlog_format=row 组合

------------------------------------------------------------------------------------------------------------------------
1、在第六章MDL锁的时候，您说给大表增加字段和增加索引的时候要小心，
之前做过测试，给一个一千万的数据增加索引有时需要40分钟，但是增加索引不会对表增加MDL锁吧。
除了增加索引慢，还会对数据库有什么影响吗？
我问我们dba，他说就开始和结束的时候上一下锁，没什么影响，我个人是持怀疑态度的。

    在锁方面你们dba说的基本是对的。一开始和结束有写锁，执行中间40分钟只有读锁。
    但是1000万的表要做40分钟，可能意味着系统压力大（或者配置偏小），这样可能不是没影响，比较这个操作还是要吃IO和CPU的


2、老师讲到表锁除了MDL锁，还有显示命令lock table的命令的表锁，
老师我可以认为，在MySQL中如果不显示使用lock table表锁的话，那么MySQL是永远不会使用表锁的，
如果锁的条件没有索引，使用的是 锁住行锁+间隙 控制并发。

    嗯，innodb引擎是这样的。
------------------------------------------------------------------------------------------------------------------------
看了@令狐少侠 提出的问题，对锁有了新的认识：
    对于非索引字段进行update或select .. for update操作，代价极高。所有记录上锁，以及所有 间隔的锁。
    对于索引字段进行上述操作，代价一般。只有 索引字段本身 和 附近的间隔 会被加锁。

这次终于明白，为什么说update语句的代价高！

    是的
    update、delete语句 用不上索引是很恐怖的😄

------------------------------------------------------------------------------------------------------------------------
1、 我在事务1中，执行 begin; select * from t where c=5 for update; 事务未提交
    然后事务2中，begin; update t set c=5 where id=0; 执行阻塞
    替换成 update t set c=11 where id=0; 执行不阻塞

我觉得原因是事务1 执行时产生next-key lock范围是(0,5]、(5,10]，我想问下update set操作c=xxx是会加锁吗？以及加锁的原理。

    你可以理解为要在

        索引c B+树   ->   新insert一行  ->  c=5,id=0
        --------------------------------------------------------------------
        索引c上，新插入一个(c=5,id=0)这一行，是落在(0,5]、(5,10]里面的，11可以对吧


2、一直以为gap只会在二级索引上，看了你的死锁案例，发现主键索引上也会有gap锁？

    嗯
    主键索引 的间隙上也要有gap lock保护的
------------------------------------------------------------------------------------------------------------------------
可重复读隔离级别下，经试验：

SELECT * FROM t where c>=15 and c<=20 for update;
会加如下锁：
    next-key lock:(10, 15], (15, 20]
    gap lock:(20, 25)

SELECT * FROM t where c>=15 and c<=20 order by c desc for update;
会加如下锁：
    next-key lock:(5, 10], (10, 15], (15, 20]
    gap lock:(20, 25)

session C 被锁住的原因就是根据 索引c 逆序排序后多出的 next-key lock:(5, 10]

同时我有个疑问：加不加 next-key lock:(5, 10]，好像都不会影响到 session A 可重复读的语义，那么为什么要加这个锁呢？


    - 是的，这个其实就是为啥总结规则有点麻烦，有时候只是因为代码是这么写的😓

------------------------------------------------------------------------------------------------------------------------
由于字数限制，正序及无排序的日志无法帖出

倒序日志比这两者，多了范围  next-key lock -> 索引锁c（5，10]
-------------------------------------------------------------
个人理解是，加锁分两次：
    第一次，即正序的锁

    第二次，为倒序的锁，即多出的(5,10]，在RR隔离级别

--------------------------------------------------------------
innodb在加锁的过程中会  ->  默认 向后锁一个记录，加上 next-key lock

    第一次加锁的时候10已经在范围，由于倒序，向后，即向5再加 next-key lock，即多出的(5,10]范围

------------------------------------------------------------------------------------------------------------------------
这样，当你执行 select * from t where d=5 for update 的时候，就不止是给数据库中已有的 6 个记录加上了行锁，
还同时加了 7 个间隙锁
---------------------------------------------------------------
老师这句话没看太明白，数据库只有一条d=5的记录，为什么会给6个记录加上行锁呢？

    - 因为d上没有索引，这个语句要走 全表扫描


========================================================================================================================
间隙锁 的加锁规则
========================================================================================================================

我总结的加锁规则里面，包含了 2个“原则”、2个“优化”、1个“bug”：

    原则1：加锁的基本单位是 next-key lock     // next-key lock 是 前开后闭区间   -> (5,10]

    原则2：查找过程中 访问到的对象 才会加锁

    优化1：索引上的 等值查询，给 唯一索引 加锁的时候，next-key lock 退化为行锁

    优化2：索引上的 等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁

    一个bug：唯一索引上的 范围查询，会访问到不满足条件的第一个值为止                   // 唯一索引范围锁的bug 在 8.0.18已经修复!




delete 语句加锁的逻辑，跟 select ... for update 是类似的



------------------------------------------------------------------------------------------------------------------------
总结：

    1、锁是加在 索引 上               // 这是 InnoDB 的一个基础设定

    2、查询过程中访问到的对象才会加锁，加锁的基本单位是next-key lock（前开后闭）；             // next-key lock  =  行锁 + 间隙锁

    3、等值查询 上MySQL的优化：

        索引上的等值查询

            1、如果是唯一索引，next-key lock会退化为行锁

            2、如果不是唯一索引，需要访问到第一个不满足条件的值，此时最后一个 next-key lock 会退化为间隙锁；


    4、范围查询：

        无论是否是唯一索引，范围查询都需要访问到 不满足条件的第一个值 为止；

    5、非索引查询

        全表查询   ->  全表遍历 主键B+树     ===>   “全表锁” 主键B+树    ->  所有记录加 行锁 + 间隙锁


    6、回表

        拿到ID 回表  ->  主键B+树   ->  加 行锁


------------------------------------------------------------------------------------------------------------------------
原则 2：查找过程中访问到的对象才会加锁。

对于原则2 我有个疑问，访问到的对象，还应该包含 其影响到的索引。

老师的例子中某些隐含了这些东西，其他同学的留言中也表明了这点，望老师指点

比如 一个表t（id ，c,d,e）
    id是主键 ，其他列都有非唯一索引。
    执行insert 需要获取所有索引上的锁；
    执行delete（即使根据id删除）也需要获取其他索引的锁；
    执行update（即使where条件使用id）如果更新的有索引列，也需要获取上面的锁

因为更新操作肯定会导致索引树的修改，如果不更改，会导致索引搜索时返回的数据和实际不一样；如果更改的话，肯定需要防止并发就需要加锁

不知道理解的是否正确


    对的
    要update和delete的时候，要“先读后写”，这个读就开始加锁了。
    insert的时候要有插入意向锁（就是会跟gap lock冲突的那个）
------------------------------------------------------------------------------------------------------------------------
加锁是一行一行加的

next-key lock 也是 间隙锁、行锁 分开加的

------------------------------------------------------------------------------------------------------------------------
begin;
select * from t where c>=15 and c<=20 order by c desc lock in share mode;

锁的范围是这样的：
    普通索引c 上     ->      next-key lock:    (5，10],(10,15],(15,20]
    主键索引id上     ->      行锁:              id=15 和 id=20

------------------------------------------------------------------------------------------------------------------------

------------------------------------------------------------------------------------------------------------------------



========================================================================================================================
redo log、binlog    写入机制
========================================================================================================================
1、执行一个 update 语句以后，我再去执行 hexdump 命令直接查看 ibd 文件内容，为什么没有看到数据有改变呢？

    这可能是因为 WAL 机制的原因。
    update 语句执行完成后，InnoDB 只保证写完了 redo log、内存，可能还没来得及将数据写到磁盘。

2、为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？

    MySQL 这么设计的主要原因是：

        binlog 是不能“被打断的”
            一个事务的 binlog 必须连续写，因此要整个事务完成后，再一起写到文件里。

        而 redo log 并没有这个要求
            中间有生成的日志可以写到 redo log buffer 中
            redo log buffer 中的内容还能“搭便车”，其他事务提交的时候可以被一起写到磁盘中。

3、事务执行期间，还没到提交阶段，如果发生 crash 的话，redo log 肯定丢了，这会不会导致主备不一致呢？

    不会。
    因为这时候 binlog 也还在 binlog cache 里，没发给备库。
    crash 以后 redo log 和 binlog 都没有了，从业务角度看这个事务也没有提交，所以数据是一致的。

4、如果 binlog 写完盘以后发生 crash，这时候还没给客户端答复就重启了。等客户端再重连进来，发现事务已经提交成功了，这是不是 bug？

    不是。
    你可以设想一下更极端的情况，整个事务都提交成功了，redo log commit 完成了，备库也收到 binlog 并执行了。
    但是主库和客户端网络断开了，导致事务成功的包返回不回去，这时候客户端也会收到“网络断开”的异常。
    这种也只能算是事务成功的，不能认为是 bug。

    实际上数据库的 crash-safe 保证的是：
        1、如果客户端收到事务成功的消息，事务就一定持久化了；
        2、如果客户端收到事务失败（比如主键冲突、回滚等）的消息，事务就一定失败了；
        3、如果客户端收到“执行异常”的消息，应用需要重连后，通过查询当前状态来继续后续的逻辑。
            此时数据库只需要保证内部（数据和日志之间，主库和备库之间）一致就可以了。


------------------------------------------------------------------------------------------------------------------------
为什么binlog 是不能“被打断的”的呢？主要出于什么考虑？

    我觉得一个比较重要的原因是，一个线程只能同时有一个事务在执行。

    由于这个设定，所以每当执行一个 begin/start transaction 的时候，就会默认提交上一个事务；
    这样如果一个事务的binlog被拆开的时候，在备库执行就会被当做多个事务分段自行，这样破坏了原子性，是有问题的。

------------------------------------------------------------------------------------------------------------------------
事务A是当前事务，这时候事务B提交了。
事务B的redo log持久化时候，会顺道把A产生的redo log也持久化，这时候A的redo log状态是prepare状态么？


    不是。

    说明一下哈，所谓的 redo log prepare，是“当前事务提交”的一个阶段。

    也就是说，在事务A “提交” 的时候，我们才会走到 事务A的 “redo log prepare” 这个阶段。

    事务A在提交前，有一部分redo log被事务B提前持久化，但是事务A 还没有进入 提交阶段，是无所谓 “redo log prepare” 的。

------------------------------------------------------------------------------------------------------------------------
这两个「提交」的含义是不一样的。

MySQL 事务中执行 commit 命令是第一种「提交」，也就是我们常说的事务的提交。

但是当你执行了 commit 命令之后，MySQL 是不是要确保这个事务结束？
    也就是要写入 redo log 和 binlog。

    为了保证 crash-safe 和数据一致等问题，redo log 和 binlog 的写入使用了两阶段提交协议，
        redo log 会有 prepare 和 committed 两种状态，
        redo log 提交后会从 prepare 状态进入 committed 状态，
    这就是第二种「提交」。

总结来说，第一种「提交」就是一条表示事务结束命令，而第二种「提交」是 MySQL 底层的一种机制。


------------------------------------------------------------------------------------------------------------------------
sync_binlog 和 binlog_group_commit_sync_no_delay_count 的最大区别主要在于，数据的丢失与否吧？

    sync_binlog = N

        每个事务write后就响应客户端了，刷盘是N次事务后刷盘。
        N次事务之间宕机，数据丢失。

    binlog_group_commit_sync_no_delay_count = N

        必须等到N个后才能提交
        换言之，会增加响应客户端的时间。
        但是一旦响应了，那么数据就一定持久化了。
        宕机的话，数据是不会丢失的。


    - 你的理解很到位


========================================================================================================================
主备
========================================================================================================================

主库 A 从本地读取 binlog，发给从库 B；
请问这里的本地是指文件系统的 page cache还是disk呢？


    是这样的，对于A的线程来说，就是“读文件”

        1、如果这个文件现在还在 page cache中，那就最好了，直接读走

        2、如果不在page cache里，就只好去磁盘读

    这个行为是文件系统控制的，MySQL只是执行 “读文件” 这个操作



------------------------------------------------------------------------------------------------------------------------
老师，我想问下双M架构下，主从复制，是不是一方判断自己的数据比对方少就从对方复制，判断依据是什么？

    一开始创建主备关系的时候

        是由 备库 指定的

        比如 基于位点 的主备关系，备库说“我要从binlog文件A的位置P”开始同步，主库就从这个指定的位置开始往后发

    而主备复制关系搭建完成以后

        是 主库 来决定 “要发数据给备库” 的

        主库有生成新的日志，就会发给备库。
------------------------------------------------------------------------------------------------------------------------
问个备份问题，假如周日23点做了备份，周二20点需要恢复数据，那么在用binlog恢复时，如何恰好定位到周日23点的binlog,谢谢。

    MySQL binlog 有个参数 —stop-datetime

------------------------------------------------------------------------------------------------------------------------
我之前理解是，mysql 每执行一条事务所产生的binlog准备写到 binlog file时，
都会先判断当前文件写入这条binlog之后是否会超过设置的max_binlog_size值。
如果超过，则rotate 自动生成下个binlog flie 来记录这条binlog信息。

那如果 事务所有产生的binlog 大于 max_binlog_size 值呢？ 那不是永久地rotate吗？ mysql是如何处理的？


    一个事务的binlog日志，不会被拆到两个binlog文件！

    所以会等到 这个事务的日志写完 再rotate，

    所以你会看见 超过配置大小上限 的binlog 文件！




========================================================================================================================
大查询 不会把内存打爆                 ->  边读边发    +   LRU淘汰
========================================================================================================================

1、是一行一行的扔给socket send buffer，还是把net_buffer 里的内容 一下子全部扔给 socket send buffer ？

    net_buffer 写满，一起发，然后清空net_buffer，组装下一批。


2、对于一个查询，执行器拿到的所有结果，如果可以一次性放入net_buffer, 对于执行器来说是不是意味着“全都写出去了”，也就不会有 sending to client 状态？

    是的

3、只有当查询的结果，不能够全部放入net_buffer，需要 等net_buffer里的内容清空后 再继续放入后续的结果，这时候状态才是显示 sending to client ？

    是的

4、当查询结果可以全部放入net_buffer, 执行器也不管 net_buffer 是否发送给 socket send buffer，都认为执行完了 ？

    是的

5、对buffer pool，当通过 LRU 淘汰数据页 的时候，如果此时 该页的内容是新的（也就是磁盘上的内容是老的），
    是不是需要 强制先走一个刷脏页 的流程，等脏页刷完了，然后才能淘汰该数据页？

    对
    这个就是我们其他文章中介绍的，“带着邻居节点一起刷” 的那个阶段。




========================================================================================================================
join
========================================================================================================================


如果要使用 join，应该选择大表做驱动表还是选择小表做驱动表？

    1、如果是 Index Nested-Loop Join 算法，应该选择小表做驱动表；

    2、如果是 Block Nested-Loop Join 算法：

        在 join_buffer_size 足够大的时候，是一样的；

        在 join_buffer_size 不够大的时候（这种情况更常见），应该选择小表做驱动表。


    结论就是：总是应该使用小表做驱动表。


========================================================================================================================
group by
========================================================================================================================

如果只需要去重，不需要执行聚合函数，distinct 和group by那种效率高一些呢？

    只需要去重的话，如果没有limit，是一样的；
    有limit的话，distinct 快些。






========================================================================================================================
自增ID 、 row_id 、 Xid 、 Innodb trx_id 、 thread_id
========================================================================================================================

针对 max_trx_id的bug，有一个疑问：
    假设事物都提交了，后续的新的事物 从 0开始增长， 不应该也都和新的一样了么（就象一个新的mysql），
    只有处于那种边界的事物（快要溢出前，还没有提交的事物）才会出现这个问题吧。


    不会
    因为max_trx_id定义是8个字节，超过2^48之后还会继续涨；
    只是写到数据里面的trx_id是取最低6个而已，才看上去是从0开始的





也就是说 只读事物 也会占用一个xid，即便 这个事物不写入binlog，也不写入redolog，也会分配xid，这样理解对吗？

    是的
    这个“分配”其实是“赋值”，
    query_id 是分配出来的， xid只是从query_id 赋值过去的

========================================================================================================================
混记
------------------------------------------------------------------------------------------------------------------------
我是从Oracle转到MySQL来的，
先接触的Oracle再看MySQL就经常喜欢拿两者对比，包括：表数据存储结构、二级索引的异同、redo log、binlog、锁机制、以及默认隔离级别

研究锁后，根据自己的理解得出一个结论：

    MySQL默认隔离级别选为RR也是无奈之举！

    因为当时binlog还是语句格式，为了保证binlog事务顺序正确就得有 gap lock 和 next-key lock

    而对开发人员来说，他们未必清楚事务隔离级别，且大多数开发都是从Oracle转向MySQL的，故果断将隔离级别全部调整为RC。



    是的，以前有很多Oracle专家，然后大家就觉得RC够用。
    不过他们不是“以为够用”，他们是真的分析过业务场景，分析业务的用法，确认够用。
    这种是很好的实践！
------------------------------------------------------------------------------------------------------------------------
RR隔离级别下，为保证binlog记录顺序，非索引更新会锁住全表记录，且事务结束前不会对不符合条件记录有逐步释放的过程。
------------------------------------------------------------------------------------------------------------------------
问一下：索引扫描与全表扫描，有什么异同点？

    一般说 全表扫描，默认是值 扫描“主键索引”

------------------------------------------------------------------------------------------------------------------------
一致性读为啥还要处理别的事务回滚日志？一致性读不是直接返回视图里的值吗？undo log在没有事务使用的时候会清除掉？

    你再看下08篇哈
    简单说，一致性视图只是 数组 + 高水位，是要靠 undo log 来获取老版本的数据的
------------------------------------------------------------------------------------------------------------------------
b+树索引结构的层次和表数据量的关系是怎么样的？也就是说15万的数据量是三层结构？达到多少数据量是四层次？
一般在线服务中一个表的数据量一般多大合适？

    你可以这么理解， N层放不下的时候，就增加一层来放。

    这个行为是由页分裂触发的
    在线服务最好不要让索引树超过4层        // 一般也不会超过


------------------------------------------------------------------------------------------------------------------------





------------------------------------------------------------------------------------------------------------------------
前提：
    1、但凡聊锁，必先提隔离级别！

    2、所有的规则 都是 随着版本的升级 动态变更的！

        MySQL innoDB 间隙锁的实现，随着版本的迭代，可能会变更，并不是一定一成不变的！

------------------------------------------------------------------------------------------------------------------------
最佳实践

    1、尽量将业务逻辑写在业务代码中，让数据库只做“读写数据”的事情！

    2、表设计，都是针对具体场景的



------------------------------------------------------------------------------------------------------------------------
有些语句和连接“kill 不掉”的情况

    这些“kill 不掉”的情况，其实是因为发送 kill 命令的客户端，并没有强行停止目标线程的执行，而只是设置了个状态，并唤醒对应的线程。
    而被 kill 的线程，需要执行到判断状态的“埋点”，才会开始进入终止逻辑阶段。并且，终止逻辑本身也是需要耗费时间的。



========================================================================================================================
MySQL 命令
========================================================================================================================
show table status
show processlist                  // 查看当前语句处于什么状态
show engine innodb status
------------------------------
重建索引
------------------------------
analyze table t

force index(idx)

    select * from t force index(a) where a between 10000 and 20000;

------------------------------
重建表 -> 消除空洞
------------------------------
alter table t engine=InnoDB

optimize table t        (recreate + analyze)

truncate table t        (drop     + create)


------------------------------
锁信息
------------------------------
设置参数：set global innodb_status_output_locks=1;
然后使用 show engine innodb status ，查看 TRANSACTIONS 相关的信息下，就能看到锁信息。

------------------------------------------------------------------------------------------------------------------------
Extra                            - https://dev.mysql.com/doc/refman/5.7/en/explain-output.html#explain-extra-information

Using where                 ->  WHERE                           ->  筛选过滤
Using index                 ->  index                           ->  索引覆盖
Using index condition       ->  index                           ->  索引下推
Using filesort              ->  排序                            ->  非自然有序，需借助外部排序(内存/文件)
Using temporary             ->  临时表

------------------------------------------------------------------------------------------------------------------------
Using filesort          本次查询语句中有 order by，且排序依照的字段不在本次使用的索引中，不能自然有序，需要进行额外的排序工作。

Using index             使用了 覆盖索引 ———— 即本次查询所需的所有信息字段，都可以从利用的索引上取得，无需回表。

Using index condition   使用了索引下推技术ICP

                        虽然本次查询所需的数据，不能从利用的索引上完全取得，还是需要回表去主索引获取。
                        但在回表前，充分利用索引中的字段，根据where条件进行过滤，提前排除了不符合查询条件的列。
                        这样就减少了回表的次数，提高了效率。


Using where             表示本次查询要进行筛选过滤


------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------
读/写行k

    1、先查缓存
        先在 缓存(buffer pool) 中找，找到 行k-所在的数据页，直接写内存、redo log

    2、再查磁盘

        走 磁盘IO 查找：

            1、索引树 -> 主键ID
            2、主键树 -> 行k - 所在的数据页m
            3、数据页m -> 内存buffer pool

            4、写内存、redo log


数据页 -> 行
    数据页(结点)内部是链表，存储 行数据(元素)

------------------------------------------------------------------------------------------------------------------------

广义上：
    1、先查内存
    2、再查磁盘，同时放入缓存


狭义上：

    1、先查缓存

    2、再查磁盘

        正常查询：
            1、普通索引树  --O(logn)-->  索引所在页 -> 遍历


