

1、



2、



3、削峰




在网站面临大流量冲击时 进行请求的削峰，并主要介绍了削峰的 3 种处理方式：

    1、排队

        通过 队列 来缓冲请求，即控制请求的发出

        --------
        MQ队列异步消费   ->   客户端 获取秒杀结果：

            1、小米抢购（用户体验不太好）

                用户点击抢购   ->   答题   ->   前置校验（抢购资格、库存cache校验）   ->   成功发起抢购请求  ->   进入抢购队列

                ==>   前端页面 进入一个抢购中 页面（动画页面 ->  抢购中ing）

                服务端异步消费

                -----------
                获取结果：

                    1、客户端 与 服务端 建立 websocket连接，服务端消费完成  ->   push抢购结果 给用户

                    2、提供结果轮询接口  ->   前端定时1s轮询获取结果

                    3、用户请求加入队列后   ->   设置超时等待，开始进入阻塞状态   ->   等待消费完成/超时  ->   返回用户 抢购结果

        --------------
        除了消息队列，类似的排队方式还有很多，例如：

            1、利用线程池加锁等待也是一种常用的排队方式

            2、先进先出、先进后出 等常用的 内存排队算法 的实现方式

            3、把请求序列化到文件中，然后再顺序地读文件（例如基于 MySQL binlog 的同步机制）来恢复请求等方式


        --------------
        “一步的操作”  --变成-->  “两步的操作”

            其中增加的一步操作，用来起到 缓冲 的作用


    2、答题

        通过答题来   ->   延长请求发出的时间（拉平峰值）

        在请求发出后承接请求时进行控制，最后再对不符合条件的请求进行过滤

        --------------------
        增加购买的复杂度：

            1、防止秒杀器

            2、延缓请求（拉平峰值）

                把峰值的下单请求拉长，1s 之内延长到 2s~10s

                -----------------
                请求峰值基于时间分片，会大大减轻压力

                    1、大大减轻 顺时高并发压力（峰值 由1s  分散到 2~10s）

                    2、请求具有先后顺序，越往后的请求，越是无效请求

                        在 库存cache 前置校验环节，基本都被拦截掉

                        根本到不了最后的下单步骤，真正的并发写就非常有限了


        --------------------
        除了答题，类似的方式还有：

            支付宝的“咻一咻”
            微信的“摇一摇”

            -----------
            凡是在并发场景下，增加 一个额外的动作 基本都是类似的，拉平峰值 的思路




    3、分层过滤

        最后一种是对请求进行分层过滤

        ----------
        分层过滤非常适合 交易性的写请求

            比如 减库存 或者 拼车 这种场景

            在读的时候需要知道还有没有库存或者是否还有剩余空座位

            但是由于库存和座位又是不停变化的



            所以读的数据是否一定要非常准确呢？

                其实不一定，你可以放一些请求过去

                然后在真正减的时候再做强一致性保证

                这样既过滤一些请求，又解决了强一致性读的瓶颈



        ----------
        CDN（静态数据，减轻服务器的压力）

        ->   前台系统 动态数据访问cache（库存，基于库存cache 拦截部分请求）

        ->   后台系统（数据的二次检验、对系统做好保护和限流   ->   数据量和请求就进一步减少）

        ->   DB层（最后在数据层完成数据的 强一致性校验）

        -------------------
        像漏斗一样，尽量把数据量和请求量一层一层地过滤和减少了

        分层过滤的核心思想是：

            在不同的层次尽可能地过滤掉无效请求，让“漏斗”最末端的才是有效请求。




            -------------
            分层校验的基本原则：

                1、将动态请求的读数据缓存（Cache）在 Web 端，过滤掉无效的数据读

                2、对读数据不做强一致性校验，减少因为一致性校验产生瓶颈的问题

                3、对写数据进行基于时间的合理分片，过滤掉过期的失效请求

                4、对写请求做限流保护，将超出系统承载能力的请求过滤掉

                5、对写数据进行强一致性校验，只保留最后有效的数据

            -----------
            目的：

                在 读 系统中

                    尽量减少由于一致性校验带来的系统瓶颈

                    但是尽量将不影响性能的检查条件提前，如：

                        用户是否具有秒杀资格、商品状态是否正常、用户答题是否正确、秒杀是否已经结束、是否非法请求、营销等价物是否充足等


                在 写 数据系统中

                    主要对 写的数据（如“库存”）做一致性检查

                    最后在 数据库层  保证数据的最终准确性（如“库存”不能减为负数）



    ---------------------
    4、业务手段  ->  分流


        不过，在削峰的处理方式上除了采用技术手段，其实还可以采用业务手段来达到一定效果

            例如在零点开启大促的时候由于流量太大导致支付系统阻塞

            这个时候可以采用发放优惠券、发起抽奖活动等方式

            将一部分流量分散到其他地方

            这样也能起到缓冲流量的作用




4、性能


    ---------------------------------------------------------------
    除了本文提供的方式外，还可从考虑从以下方面进行调整：
        1、提升硬件条件：CPU核数、主频、内存、磁盘I/O、SSD、网卡等
        2、JVM性能调优
        3、缓存


    ---------------------------------------------------------------
    性能优化的核心就一个字 -> 减

        如果还继续减的

        1、异步化    - 减少等待响应的时间
        2、降日志    - 减本地磁盘的交互
        3、多级缓存  - 再减少获取数据路径
        4、减功能    - 非核心功能或后补功能去掉





5、减库存



    减库存方式：

        1、下单 减库存

            更多适用 抢购场景           // 一般抢购的商品，都是买到即赚到   ->   用户下完单，付款的概率基本 100%


            ---------
            流程：

                1、下单（预占库存）

                2、设置付款超时时间

                    秒杀商品（1分钟）

                    日常活动商品（5~10分钟）

                    日常普通商品（10~30分钟）


            ---------
            恶意：

                下完单（占用库存）   ->   不付款

                -----------
                1、针对用户恶意行为，打标

                2、限制购买数量

                3、限制下单（预占库存），超时后重复下单次数




        2、付款 减库存

            高并发情况下，大量的用户 付款完成后   ->   发现库存为0（已经被其他用户 抢购完了）   ->   抢购失败   // 用户体验非常差


        3、预扣 库存

            更多适用于 普通商品 购买场景


        ------------------------
        防止超卖：

            1、一种是在应用程序中通过事务来判断，即保证减后库存不能为负数，否则就回滚

            2、另一种办法是直接设置数据库的字段数据为无符号整数，这样减后库存字段值小于零时会直接执行 SQL 语句来报错

            3、再有一种就是使用 CASE WHEN 判断语句

                UPDATE item SET inventory = CASE WHEN inventory >= xxx THEN inventory-xxx ELSE inventory END



        ------------------------
        减库存 性能优化

            1、在 Redis（开启AOF持久化） 中减库存

                适合场景：

                    减库存逻辑单一，没有复杂的 SKU 库存和总库存这种联动关系

                不合适场景：

                    有比较复杂的减库存逻辑

                    或需要使用事务

                    ===>   你还是必须在 数据库 中完成减库存


            2、InnoDB 行锁竞争 优化   ->   防止 0.01% 的商品影响 99.99% 的商品的售卖        // 锁竞争   ->   rt增加   ->   DB吞吐量下降


                1、热点商品 和 普通商品 隔离

                    DB隔离、服务隔离


                        1、维护成本太大

                        2、并没有解决 根本性的问题   ->   锁竞争


                2、排队

                    1、应用层 排队

                        商品ID 维度   ->   路由到 多个 内存队列   ->   顺序执行   ==>   每个内存队列 ->  有独立的 work线程

                        ===>

                            1、降低锁竞争

                            2、秒杀商品、普通商品 都有机会被执行


                    2、DB层   排队

                        Mysql定制化（阿里 InnoDB patch补丁）   ->   在数据库层上 对单行记录做到 并发排队





6、兜底方案

    1、降级

        当 系统的容量 达到一定程度时

            限制或关闭  系统的某些 非核心功能

            把有限的资源  保留给  更核心的业务


        -------------------------
        降级方案可以这样设计：

            当秒杀流量达到 5w/s 时，把成交记录的获取从展示 20 条降级到只展示 5 条。

            “从 20 改到 5”这个操作由一个开关来实现，也就是设置一个能够从开关系统动态获取的系统参数。


        ------------------------------
        执行降级无疑是在  系统性能  和  用户体验  之间选择了前者

            降级后肯定会影响一部分用户的体验

            降级的核心目标是：

                牺牲次要的功能 和 用户体验   ->   来保证核心业务流程的稳定

                是一个不得已而为之的举措



    2、限流

        1、客户端限流

            好处：

                可以限制请求的发出，通过减少发出无用请求从而减少对系统的消耗

            缺点：

                客户端比较分散时，没法设置合理的限流阈值：

                    如果阈值设的太小，会导致服务端没有达到瓶颈时客户端已经被限制

                    而如果设的太大，则起不到限制的作用


        2、服务端限流

            好处：

                可以根据服务端的性能设置合理的阈值

            缺点：

                被限制的请求都是无效的请求，处理这些无效的请求本身也会消耗服务器资源      // 这些无效请求，没有在客户端进行拦截，已经发送过来 进入到了服务端，浪费了服务器资源

            -------------------------

            基于 QPS 和 线程数 的限流应用最多


                qps   ->    提前压测


                线程数限流   ->   在客户端比较有效

                    在远程调用时我们设置连接池的线程数，超出这个并发线程请求，就将线程进行 排队 或者 直接超时丢弃。




    3、拒绝服务

        如果限流还不能解决问题，最后一招就是直接拒绝服务了


            当系统负载达到一定阈值时

                如：CPU 使用率达到 90% 或者 系统 load 值达到 2*CPU 核数时   ->   系统直接拒绝所有请求，

            这种方式是最暴力但也最有效的系统保护方式。


            -----------------------
            例如秒杀系统，我们在如下几个环节设计过载保护：

                在最前端的 Nginx 上设置过载保护，当机器负载达到某个值时直接拒绝 HTTP 请求并返回 503 错误码

                在 Java 层同样也可以设计过载保护



        ----------------
        拒绝服务可以说是一种 不得已的兜底方案   ->   用以 防止最坏情况 发生

            防止因把服务器压跨而长时间彻底无法提供服务。


            像这种系统过载保护虽然在过载时无法提供服务

            但是系统仍然可以运作，当负载下降时又很容易恢复，

            所以每个系统和每个环节都应该设置这个兜底方案，对系统做最坏情况下的保护



7、细节

    1、应用层排队

        1、请求排队

            根据入队的先后顺序   ->   先到先得

            缺点：

                没有惊喜感？

                体验较差（异步  +  页面倒计时 获取结果）


        2、获取 队列 异步结果

            1、轮询

                1s一次轮询

                场景：
                    支付场景（支持页面 轮询获取 第三方支付结果）


                缺点：
                    服务端的 请求数 会增加

            2、主动push

                1、建立webSocket连接
                2、服务端 处理完成   ->   结果 推送给 客户端


                缺点：

                    服务端的 连接数 会增加



        3、处理失败 怎么办？？


            秒杀场景：

                失败   ->   直接丢去即可   ->   返回 抢购失败

                ----------
                对秒杀来说，如果失败了直接丢弃就好了，最坏的结果就是这个人没有抢到而已。


            普通场景：

                你非要纠结的话，就要做 异步消息的持久化 以及 重试机制

                ----------
                要保证异步请求的最终正确处理   ->   一般都要借助 消息系统       // 消息的最终可达

                    消息中间件是能承诺只要客户端消息发送成功，那么消息系统一定会保证消息最终被送到目的地，即消息不会丢。

                    因为客户端只要成功发送一条消息，下游消费方就一定会消费这条消息，所以也就不存在消息发送失败的问题了。



    2、hash分组


        热点商品、普通商品 hash分组

            防止 热点商品流量 到达时，占满了服务器资源   ->   影响 普通商品 购买流程




    3、缓存失效策略            // 缓存失效  ->  保证 数据的一致性


        商详缓存

            ----------
            商详数据

                商品基础信息（spu/sku）

                运费服务

                营销活动

                库存服务

                履约服务

                    发货方式、口岸

                仓网服务

                    发货时效

                价格服务



            --------------------
            1、多线程 并行调用   ->   提升性能


            2、顺序性问题     ->     服务调用前后 有顺序依赖关系

                1、CompletableFuture

                    thenApply      // 相关的方法是 R apply(T t);        既能 接收参数, 也支持 返回值

                    thenAccept     // 相关的方法是 void accept(T t);    虽然支持参数，但却不支持回值

                    thenRun        // 方法里的参数是 Runnable           既 不能接收参数，也 不支持 返回值

                    thenCompose    // thenCompose 系列方法，这个系列的方法会新创建出一个子流程，最终结果和 thenApply 系列是相同的


                2、共享变量                                  - https://blog.csdn.net/u010013573/article/details/101108979

                    共享变量     volatile int totalNum   // 计数器、有序集合

                    条件变量    wait/notify


                    ------------------------
                    条件变量

                        synchronized             ->  wait()、notify()、notifyAll()            // 1个条件变量

                        Lock - Condition         ->  await()、signal()、signalAll()           // n个条件变量



                3、有序队列

                    挨个顺序消费

            ----------
            商详缓存

                1、本地缓存（一级缓存）

                    5s  被动失效

                    失效后   ->   从 Redis 中更新本地缓存


                2、Redis缓存（二级缓存）

                    30分钟 被动失效

                    binlog监听   ->   insert/delete/update   ->   主动更新缓存




        数据一致性

            库存   ->   DB层 保证最终一致性







