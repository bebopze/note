## 1. 并发理论基础


#### 1.1 可见性、原子性和有序性问题：并发编程Bug的源头

```

    并发编程bug的源头：
    
        缓存      导致的 可见性 问题
        
        线程切换   带来的 原子性 问题
        
        编译优化   带来的 有序性 问题
        
        
    
    
    并发程序幕后的故事：
    
        这些年，我们的 CPU、内存、I/O设备 都在不断迭代，不断朝着更快的⽅向努⼒。
        
        但是，在这个快速发展的过程中，
        
        有⼀个核⼼⽭盾⼀直存在：
        
            就是 这三者 的 速度差异！！！
            
            
            CPU和内存 的速度差异可以形象地描述为：
            
                CPU 是天上⼀天，内存是地上⼀年（假设 CPU执⾏⼀条 普通指令 需要⼀天，那么 CPU读写内存 得等待⼀年的时间）。
                
                
            内存和I/O设备 的速度差异就更⼤了：
            
                内存是天上⼀天，I/O设备是地上⼗年。
        
        
        程序⾥⼤部分语句都要访问内存，有些还要访问 I/O：
        
            根据⽊桶理论（⼀只⽔桶能装多少⽔取决于它最短的那块⽊板），
        
            程序整体的性能取决于最慢的操作——读写	I/O 设备，
        
            也就是说 单⽅⾯提⾼ CPU 性能 是⽆效的。
        
        
        为了合理利⽤ CPU 的⾼性能，平衡这三者的速度差异：
        
            计算机体系机构、操作系统、编译程序 都做出了贡献，主要体现为：
        
                1. CPU 增加了缓存，以均衡CPU与内存的速度差异；
                2. 操作系统增加了进程、线程，以 分时复⽤CPU，进⽽ 均衡 CPU 与 I/O设备 的速度差异；
                3. 编译程序优化指令执⾏次序，使得缓存能够得到更加合理地利⽤。   
        
        
    
    1、缓存 导致的 可见性 问题：
        
        ⼀个线程对共享变量的修改，另外⼀个线程能够⽴刻看到，我们称为可⻅性。
        
        
        多核时代：
            
            每颗 CPU 都有⾃⼰的缓存，这时 CPU缓存 与 内存 的 数据⼀致性 就没那么容易解决了，
            
            当 多个线程 在 不同的CPU上 执⾏时，这些线程 操作的是 不同的 CPU缓存。
            
            
            
            ⽐如，线程A 操作的是 CPU-1 上的缓存，⽽ 线程B 操作的是 CPU-2 上的缓存，
            
            很明显：
            
                这个时候 线程A 对 变量V 的操作 对于 线程B ⽽⾔，就不具备 可⻅性 了。
                
                这个就属于 硬件程序员 给 软件程序员 挖的“坑”。    
                
                
    2、线程切换 带来的 原子性 问题：
        
        多进程：
        
            由于 IO 太慢，早期的操作系统 就发明了 多进程，
            
            即便在单核的 CPU 上我们也可以⼀边听着歌，⼀边写 Bug，这个就是多进程的功劳。
         
           
        时间⽚：
            
            操作系统允许某个进程执⾏⼀⼩段时间，例如	50毫秒，
            
            过了	50毫秒 操作系统就会重新选择⼀个进程来执⾏（我们称为“任务切换”），
            
            这个 50毫秒 称为 “时间⽚”。    
    
        
        
        
        多进程分时复⽤：
            
            
            提高 CPU 的使⽤率：
            
                在⼀个时间⽚内，如果⼀个进程进⾏⼀个	IO 操作，
                
                例如读个⽂件，这个时候该进程可以把⾃⼰标记为“休眠状态”并出让 CPU 的使⽤权，
                
                待⽂件读进内存，操作系统会把这个休眠的进程唤醒，唤醒后的进程就有机会重新获得 CPU 的使⽤权了。
                
                
                这⾥的进程 在 等待IO 时 之所以会释放 CPU 使⽤权，是为了让 CPU 在这段等待时间⾥可以做别的事情，
                
                这样⼀来 CPU 的使⽤率就上来了；
            
            
            提高 IO 的使⽤率：
             
                此外，如果这时有另外⼀个进程也读⽂件，读⽂件的操作就会排队，
                
                磁盘驱动在完成⼀个进程的读操作后，发现有排队的任务，就会⽴即启动下⼀个读操作，
                
                这样 IO 的使⽤率也上来了。
            
            
            是不是很简单的逻辑？
            
                但是，虽然看似简单，⽀持 多进程 分时复⽤ 在操作系统的发展史上却具有⾥程碑意义，
                
                Unix 就是因为解决了这个问题⽽名噪天下的。
        
        
        
        早期的操作系统 基于 进程 来调度 CPU：
        
            不同进程 间是 不共享内存 空间的：
            
                所以 进程 要做 任务切换 就要 切换内存 映射地址，
            
            ⽽ ⼀个进程 创建的 所有线程：
            
                都是共享⼀个内存空间的，
            
                所以线程做任务切换成本就很低了。
            
            
        现代的操作系统 都基于 更轻量的 线程 来调度：
        
            现在我们提到的“任务切换”：
                
                都是指 “线程切换”
                
                
        
                
        Java 并发程序 任务切换：        
            
            Java 并发程序 都是基于 多线程 的，⾃然也会涉及到 任务切换
            
            
            任务切换 的时机 ⼤多数是在 时间⽚结束 的时候
            
            
            
            ⾼级语⾔ ⾥ ⼀条语句 往往需要 多条 CPU 指令完成：
             
                我们现在基本都使⽤ ⾼级语⾔ 编程，⾼级语⾔ ⾥ ⼀条语句 往往需要 多条 CPU 指令完成.
                
                
                例如 count += 1，⾄少需要三条 CPU 指令：
                
                    指令 1：⾸先，需要把变量 count 从内存加载到	CPU 的寄存器
                    指令 2：之后，在寄存器中执⾏ +1 操作
                    指令 3：最后，将结果写⼊内存（缓存机制导致可能写⼊的是 CPU缓存 ⽽不是内存）
                    
                
            
            
            操作系统做任务切换，可以发⽣在 任何⼀条CPU 指令执⾏完：
            
                是的，是 CPU 指令，⽽不是 ⾼级语⾔ ⾥的 ⼀条语句。
                
                对于上⾯的三条指令来说，
                
                我们假设 count=0，如果线程	A 在指令 1 执⾏完后做线程切换，线程 A 和线程 B 按照下图的序列执⾏，
                
                那么我们会发现两个线程都执⾏了 count+=1 的操作，但是得到的结果不是我们期望的 2，⽽是 1。
            
            
            直觉-潜意识：
            
                我们潜意识⾥⾯觉得 count+=1 这个操作是⼀个不可分割的整体：
            
                    就像⼀个原⼦⼀样，线程的切换可以发⽣在 count+=1 之前，也可以发⽣在	count+=1 之后，
                
                    但就是不会发⽣在中间。
                
                
                我们把⼀个或者多个操作 在 CPU执⾏的过程中 不被中断 的特性称为 原⼦性：
                
                    CPU 能保证的原⼦操作是 CPU指令级别 的，⽽不是 ⾼级语⾔ 的操作符，
                
                    这是违背我们直觉的地⽅。
                
                    因此，很多时候 我们需要在 ⾼级语⾔层⾯ 保证操作的 原⼦性。
                
    
    
    
    3、编译优化 带来的 有序性 问题：
    
        那并发编程⾥还有没有其他有违直觉容易导致诡异 Bug 的技术呢？
        
            有的，就是有序性
            
            顾名思义，有序性 指的是 程序按照代码的 先后顺序 执⾏
            
            编译器 为了 优化性能，有时候 会改变 程序中 语句 的 先后顺序
            
            
            例如程序中：
            
                “a=6; b=7;”  编译器优化后可能变成“b=7; a=6;”，
            
            
            在这个例⼦中，编译器调整了语句的顺序，但是不影响程序的最终结果。
            
            不过有时候编译器及解释器的优化可能导致意想不到的 Bug。
        
        
        
        在 Java	领域⼀个经典的案例就是 利⽤双重检查 创建单例对象：
            
            这看上去⼀切都很完美，⽆懈可击，
            
            但实际上这个 getInstance() ⽅法并不完美。问题出在哪⾥呢？
            
            
                出在 new 操作上，我们以为的 new 操作应该是：
                    
                    1. 分配⼀块 内存M
                    2. 在 内存M 上初始化 Singleton 对象
                    3. 然后 M 的地址赋值给 instance 变量
                    
                    
                但是实际上优化后的执⾏路径却是这样的：
                                
                    1. 分配⼀块 内存M
                    2. 将 M 的地址赋值给 instance 变量
                    3. 最后在 内存M 上初始化 Singleton	对象
                    
                    
             
             
            优化后会导致什么问题呢？
            
                我们假设 线程A 先执⾏ getInstance() ⽅法，
                
                当执⾏完 指令2 时恰好发⽣了 线程切换，切换到了 线程B 上；
                
                如果此时 线程B 也执⾏ getInstance() ⽅法，
                
                那么 线程B 在执⾏第⼀个判断时会发现 instance != null ，所以直接返回 instance，
                
                ⽽此时的	instance 是没有初始化过的，如果我们这个时候访问 instance 的成员变量 就可能触发 空指针异常。     
                
                
                
            
    
    总结：
    
        要写好并发程序，⾸先要知道并发程序的问题在哪⾥：
        
            只有确定了“靶⼦”，才有可能把问题解决，毕竟所有的解决⽅案都是针对问题的。
        
        并发程序经常出现的诡异问题看上去⾮常⽆厘头，但是深究的话：
        
            ⽆外乎就是 直觉 欺骗了 我们
        
        只要我们能够 深刻理解：
         
            可⻅性、原⼦性、有序性 在并发场景下的原理，很多并发 Bug 都是可以理解、可以诊断的。
        
        在介绍可⻅性、原⼦性、有序性的时候，特意提到：
        
            缓存导致的可⻅性问题，线程切换带来的原⼦性问题，编译优化带来的有序性问题，
            
            其实 缓存、线程、编译优化 的⽬的 和 我们写并发程序 的⽬的 是相同的，都是提⾼程序性能。
        
        但是技术在解决⼀个问题的同时，必然会带来另外⼀个问题：
        
            所以在采⽤⼀项技术的同时，⼀定要清楚它带来的问题是什么，以及如何规避。
    
    
    
    思考：
        
        Q： 常听⼈说，在 32 位的机器上对 long 型变量进⾏加减操作存在并发隐患，到底是不是这样呢？
        
        A： long类型64位，所以在32位的机器上，对long类型的数据操作通常需要多条指令组合出来，
        
            无法保证原子性，所以并发的时候会出问题🌝🌝🌝
            
        
        Q： 文章中讲的 优化指令 的 执行次序 使得 缓存 能够 更加合理的利用 是什么意思？
        
        A： 比如第1行：a=8
            第1000行：a=a*2;
            这个时候，把他们放到一起执行，是不是就能更好的利用缓存了
        
        
        
        
        ------可见性问题------
        对于可见性那个例子我们先看下定义:
        可见性:一个线程对共享变量的修改，另外一个线程能够立刻看到
         
        并发问题往往都是综合征，这里即使是单核CPU，只要出现线程切换就会有原子性问题。但老师的目的是为了让大家明白什么是可见性
        或许我们可以把线程对变量的读可写都看作时原子操作，也就是cpu对变量的操作中间状态不可见，这样就能更加理解什么是可见性了。
         
        ------CPU缓存刷新到内存的时机------
        cpu将缓存写入内存的时机是不确定的。除非你调用cpu相关指令强刷
         
        ------双重锁问题------
        如果A线程与B线程如果同时进入第一个分支，那么这个程序就没有问题
         
        如果A线程先获取锁并出现指令重排序时，B线程未进入第一个分支，那么就可能出现空指针问题，这里说可能出现问题是因为当把内存地址赋值给共享变量后，CPU将数据写回缓存的时机是随机的
         
        ------ synchronized------
        线程在synchronized块中，发生线程切换，锁是不会释放的
         
        ------指令优化------
        除了编译优化,有一部分可以通过看汇编代码来看，但是CPU和解释器在运行期也会做一部分优化，所以很多时候都是看不到的，也很难重现。
         
        ------JMM模型和物理内存、缓存等关系------
        内存、cpu缓存是物理存在，jvm内存是软件存在的。
        关于线程的工作内存和寄存器、cpu缓存的关系 大家可以参考这篇文章
        https://blog.csdn.net/u013851082/article/details/70314778/
         
        ------IO操作------
        io操作不占用cpu，读文件，是设备驱动干的事，cpu只管发命令。发完命令，就可以干别的事情了。
         
         
        ------寄存器切换------ 
        寄存器是共用的，A线程切换到B线程的时候，寄存器会把操作A的相关内容会保存到内存里，切换回来的时候，会从内存把内容加载到寄存器。
        可以理解为每个线程有自己的寄存器
        
            
                        
```




#### 1.2 Java内存模型：看 Java 如何解决 可见性 和 有序性 问题

```
    
    Java 内存模型：
    
        导致 可⻅性 的原因是 缓存，导致 有序性 的原因是 编译优化
        
        那解决 可⻅性、有序性 最直接的办法就是：
        
            禁⽤ 缓存 和 编译优化
            
            但是这样问题虽然解决了，我们程序的性能可就堪忧了
        
            
        合理的方案应该是：
        
            按需禁用 缓存以及编译优化！      ==> 重点：按需！！！
            
            
        
        那么，如何做到“按需禁用”呢？
        
            对于并发程序，何时禁用 缓存以及编译优化 只有程序员知道，
            
            
            那所谓“按需禁用” 其实就是：
            
                指按 照程序员的要求 来禁用：
                
                
            所以，为了解决 可见性 和 有序性 问题，只需要提供给程序员：
                    
                按需禁用 缓存和编译优化 的 方法即可。  ---> JVM内存模型
        
        
        Java 内存模型 是个 很复杂的规范，可以从不同的视角来解读，站在我们这些程序员的视角，
        
        本质上可以理解为：
            
            Java内存模型 规范了 JVM 如何提供 按需禁用缓存 和 编译优化的方法。
            
            具体来说，这些方法包括：
             
                volatile、synchronized 和 final 三个关键字，
            
                以及六项 Happens-Before 规则。
        
     
    
    
       
        
    
    
    Happens-Before 规则：
    
        Happens-Before 并不是说 前面一个操作发生在后续操作的前面，
        
        它真正要表达的是：
        
            前面一个操作的 结果 对 后续操作 是可见的。
        
                划重点：可见！！！ 
                        
                    这里重点是 前面的结果 对后面 可见!!!   ✅   
                    
                        至于中间(各版本的)JVM怎么去实现，并不关心，我这里只提供规范！！！你尽管去实现即可！！！
                    
                    
                    不能按直觉 错误的理解为 简单的操作顺序，          ❌
                   
                    因为：错误的理解 强调的是 发生顺序，但是 发生并 != 可见 ！！！  
                    
                    不要被直觉所欺骗!!!
        
        
        
        和程序员相关的规则一共有如下六项，都是关于可见性的：
        
        
            1. 程序的顺序性规则         // 同一个线程中
            
                这条规则是指：
                
                    在⼀个线程中，按照程序顺序，前⾯的操作 Happens-Before 于后续的任意操作。        ==>  在 ⼀个线程 中 ❗❗❗
                
                这还是⽐较容易理解的，
                
                ⽐如刚才那段示例代码，按照程序的顺序，第6⾏代码 “x = 42;” Happens-Before 于 第7⾏代码 “v = true;”，
                
                这就是 规则1 的内容，也⽐较符合单线程⾥⾯的思维：
                
                    程序前⾯对某个变量的修改⼀定是对后续操作可⻅的。
        
            
            2. volatile 变量规则：
            
                这条规则是指：
                
                    对⼀个 volatile变量 的 写操作， Happens-Before 于 后续对这个 volatile变量 的 读操作
                    
                    ==>  volatile变量 - 写 Happens-Before 读
                    
                
                这个就有点费解了：
                
                    对⼀个 volatile变量 的 写操作 相对于 后续对这个 volatile变量 的 读操作可⻅，
                
                    这怎么看都是禁⽤缓存的意思啊，貌似和	1.5 版本以前的语义没有变化啊？
                
                    如果单看这个规则，的确是这样，但是如果我们关联⼀下规则	3，就有点不⼀样的感觉了。
            
                
            3. 传递性：
            
                这条规则是指：
                
                    如果 A Happens-Before B，且 B Happens-Before C，那么 A Happens-Before C   
                    
                    ==> A >> B , B >> C   -->   A >> C
                    
                    
                    
            4. 管程中锁的规则：
            
                这条规则是指：
                    
                    对⼀个 锁的解锁 Happens-Before 于 后续对 这个锁的加锁。
                    
                    
                要理解这个规则，就⾸先要了解“管程指的是什么”：
                
                    管程 是⼀种 通⽤的 同步原语，
                    
                    在 Java 中指的就是 synchronized：
                        
                        synchronized 是 Java ⾥对管程的实现。
                
                        管程中的 锁 在Java⾥是隐式实现的
                            
                        
                例如下⾯的代码，在进⼊同步块之前，会⾃动加锁，
                
                ⽽在代码块执⾏完会⾃动释放锁，加锁以及释放锁都是编译器帮我们实现的。
                
                    synchronized (this) { // 此处自动加锁
                      // x 是共享变量, 初始值 =10
                      if (this.x < 12) {
                        this.x = 12; 
                      }  
                    } // 此处自动解锁

                
                
            5. 线程 start() 规则
            
                这条是关于 线程启动 的
                
                它是指：
                
                    主线程A 启动 ⼦线程B 后，⼦线程	B 能够看到 主线程在启动 ⼦线程B 前的操作。
                    
                    
                    换句话说就是：
                    
                        如果 线程A 调⽤ 线程B 的 start() ⽅法（即在线程A 中启动 线程B），
                    
                        那么该 start()操作 Happens-Before 于 线程B中的任意操作。
                        
                        
                    具体可参考下⾯示例代码：
                    
                        Thread B = new Thread(()->{
                          // 主线程调用 B.start() 之前
                          // 所有对共享变量的修改，此处皆可见
                          // 此例中，var==77
                        });
                        // 此处对共享变量 var 修改
                        var = 77;
                        // 主线程启动子线程
                        B.start();

                
                
                
            6. 线程 join() 规则
            
                这条是关于 线程等待 的
                
                它是指：
                    
                    主线程A 等待 ⼦线程B 完成（主线程A 通过调⽤ ⼦线程B 的join() ⽅法实现），
                    
                    当 ⼦线程B 完成后（主线程	A 中 join() ⽅法返回），主线程 能够看到 ⼦线程的操作。
                    
                    当然所谓的“看到”，指的是：
                        
                        对共享变量的操作
                    
                    
                    换句话说就是：
                        
                        如果在 线程A 中，调⽤ 线程B 的 join() 并成功返回，
                        
                        那么 线程B 中的 任意操作 Happens-Before 于该 join() 操作的返回。
                    
                       
                    具体可参考下⾯示例代码：
                    
                        Thread B = new Thread(()->{
                          // 此处对共享变量 var 修改
                          var = 66;
                        });
                        // 例如此处对共享变量修改，
                        // 则这个修改结果对线程 B 可见
                        // 主线程启动子线程
                        B.start();
                        B.join()
                        // 子线程所有对共享变量的修改
                        // 在主线程调用 B.join() 之后皆可见
                        // 此例中，var==66
                        
                    

                
                
                
        
    
    
    
    被我们忽视的 final：
        
        前⾯我们讲 volatile 为的是 禁⽤缓存以及编译优化，
        
        我们再从另外⼀个⽅⾯来看，有没有办法告诉编译器优化得更好⼀点呢？
        
            这个可以有，就是 final 关键字
        
        
        final 修饰变量时，初衷是告诉编译器：
        
            这个变量 ⽣⽽不变，可以 可劲⼉优化
            
            
            Java编译器 在 1.5 以前的版本的确优化得很努⼒，以⾄于都优化错了：
        
                问题类似于上⼀期提到的 利⽤双重检查⽅法创建单例，
                
                构造函数的错误重排 导致 线程可能看到 final变量的值会变化
                
        
                
                在 1.5 以后 Java内存模型 对 final类型变量的重排 进⾏了约束
                
                现在只要我们提供正确构造函数，没有“逸出”，就不会出问题了
                
                
        
        “逸出”有点抽象，举个例⼦：
        
            在下⾯例⼦中，在构造函数⾥⾯将 this 赋值给了全局变量global.obj，这就是“逸出”，
            
            线程通过 global.obj 读取 x 是有可能读到 0 的。
            
            因此我们⼀定要避免“逸出”。
            
            
            // 以下代码来源于【参考 1】
            final int x;
            // 错误的构造函数
            public FinalFieldExample() { 
              x = 3;
              y = 4;
              // 此处就是讲 this 逸出，
              global.obj = this;
            }
        
            
            
    volatile：
        
        volatile 关键字并不是 Java语⾔ 的特产，古⽼的 C语⾔ ⾥也有
        
            它最原始的意义：
            
                就是 禁⽤ CPU 缓存
                
                
            例如，我们声明⼀个 volatile 变量 volatile int x = 0，
            
            它表达的是：
            
                告诉编译器，对这个变量的读写，不能使⽤ CPU 缓存，必须 从内存中 读取或写⼊
            
            这个语义看上去相当明确，但是在实际使⽤的时候却会带来困惑 
        
        
        
        Java 内存模型 在 1.5 版本对 volatile 语义进⾏了增强：
        
            通过 ⼀项 Happens-Before 规则
                
                对⼀个 volatile变量 的 写操作， Happens-Before 于 后续对这个 volatile变量 的 读操作
                                    
                    ==>  volatile变量 - 写 Happens-Before 后续 读
    
    
    
    
    
    总结：
    
        Java 的 内存模型 是 并发编程领域 的 ⼀次重要创新，
        
        之后	C++、C#、Golang 等⾼级语⾔都开始⽀持内存模型
        
        Java内存模型⾥⾯，最晦涩的部分就是 Happens-Before 规则了，
        
        Happens-Before规则最初是在⼀篇叫做 Time, Clocks, and the Ordering of Events in a Distributed System 的论⽂中提出来的，
        
        在这篇论⽂中，Happens-Before 的语义是：
            
            ⼀种因果关系
        
        
        Happens-Before 语义 的 现实理解：
        
            如果 A事件 是导致 B事件 的 起因，那么 A事件 ⼀定是先于（Happens-Before） B事件 发⽣的
            
            
        在 Java 语⾔⾥⾯：
        
            Happens-Before 的语义 
                本质上是一种  可见性❗❗❗
            
            A Happens-Before B
                意味着 A事件 对 B事件 来说是可⻅的，⽆论 A事件 和 B事件 是否发⽣在同⼀个线程⾥
            
                例如 A事件 发⽣在 线程1 上，B事件 发⽣在 线程2 上，Happens-Before 规则保证 线程2 上也能看到	A事件 的发⽣
            
            
        Java 内存模型 主要分为两部分：
            
            ⼀部分 ⾯向你我这种编写并发程序的应⽤开发⼈员
            
            另⼀部分 是⾯向 JVM 的实现⼈员
        
           
        我们可以重点关注前者，也就是和编写并发程序相关的部分：
        
            这部分内容的核⼼就是：
            
                Happens-Before 规则
            
        
        
    
    
    
    
    
    思考：
            
        Q： 第一章里提到程序中x=5；x=6可能被重排。可是今天第一个规则里提到，同一个线程里，是顺序的。这两个不就矛盾了吗？
        
        A： 可以重排，但是要保证 符合 Happens-Before 规则。
        
            Happens-Before 规则 关注的是 可见性❗️❗️❗️
        
            
            示例：
                 
               x=5;
               y=6;
               z=x+y;
               
               上面的代码重排成这样：
               
               y=6;
               x=5;
               z=x+y;
               
               也是可以的
            
            
            所谓顺序：
                
                指的是 你可以用 顺序的方式 推演 程序的执行，但是 程序的执行 不一定是 完全顺序的
            
            编译器保证：
                
                结果一定  ==  顺序方式 推演的结果
                
                
            这几条规则，都是告诉你：
                
                可以按照 这个规则 推演 程序的执行❗️❗️❗️
                
                但是 编译器 怎么优化，那就百花齐放了❗️❗️❗️
            
        
            
            
    
    ------还差两个规则------
    还差两个规则，分别是：
    
        线程中断规则：
        
            对线程interrupt()方法的调用 先行发生于 被中断线程的代码检测到中断事件 的发生，
            
            可以通过Thread.interrupted()方法检测到是否有中断发生。
            
        对象终结规则：
        
            一个对象的初始化完成(构造函数执行结束) 先行发生于 它的 finalize()方法 的开始。
    
    
    
    
    ------个人对于Java内存模型总结------
    
    个人对于Java内存模型总结：
    
        1. 为什么定义Java内存模型？
            
            现代计算机体系大部是采用的对称多处理器的体系架构。
            
            每个处理器均有独立的寄存器组和缓存，多个处理器可同时执行同一进程中的不同线程，这里称为处理器的乱序执行。
            
            在Java中，不同的线程可能访问同一个共享或共享变量。
            
            如果任由编译器或处理器对这些访问进行优化的话，很有可能出现无法想象的问题，这里称为编译器的重排序。
            
            除了处理器的乱序执行、编译器的重排序，还有内存系统的重排序。
            
            因此Java语言规范引入了Java内存模型，通过定义多项规则对编译器和处理器进行限制，主要是针对 可见性和有序性。
            
            
        2. 三个基本原则：
            
            原子性、可见性、有序性。
            
        
        3. Java内存模型涉及的几个关键词：
        
            锁、volatile字段、final修饰符 与 对象的安全发布。
            
            第一是锁：
            
                锁操作是具备happens-before关系的，解锁操作happens-before之后对同一把锁的加锁操作。
            
                实际上，在解锁的时候，JVM需要强制刷新缓存，使得当前线程所修改的内存对其他线程可见。
            
            
            第二是volatile字段：
            
                volatile字段 可以看成是一种 不保证原子性的同步，但保证可见性的特性，其性能往往是优于锁操作的。
                
                但是，频繁地访问 volatile字段也会出现因为不断地强制刷新缓存而影响程序的性能的问题。
            
                
            第三是final修饰符：
            
                final修饰的实例字段则是涉及到新建对象的发布问题。
                
                当一个对象包含final修饰的实例字段时，其他线程能够看到已经初始化的final实例字段，这是安全的。
                
                
        4. Happens-Before的7个规则：
            
            (1) 程序次序规则：
                
                在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。
                
                准确地说，应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。
                
            (2) 管程锁定规则：
                
                一个unlock操作先行发生于后面对同一个锁的lock操作。
                
                这里必须强调的是同一个锁，而"后面"是指时间上的先后顺序。
                
            (3) volatile变量规则：
            
                对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的"后面"同样是指时间上的先后顺序。
                
            (4) 线程启动规则：
            
                Thread对象的start()方法先行发生于此线程的每一个动作。
                
            (5) 线程终止规则：
                
                线程中的所有操作都先行发生于对此线程的终止检测，
                
                我们可以通过 Thread.join() 方法结束、Thread.isAlive() 的返回值等手段检测到线程已经终止执行。
                
            (6) 线程中断规则：
            
                对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，
                
                可以通过Thread.interrupted()方法检测到是否有中断发生。
                
            (7) 对象终结规则：
            
                一个对象的初始化完成(构造函数执行结束)先行发生于它的finalize()方法的开始。
            
            
        5. Happens-Before的1个特性：
        
            传递性
        
        
        6. Java内存模型底层怎么实现的？
        
            主要是通过 内存屏障(memory barrier) 禁止重排序的，
            
            即时编译器 根据 具体的 底层体系架构：
                
                将这些 内存屏障 替换成 具体的 CPU 指令。
            
            
            对于编译器而言：
                
                内存屏障将限制它所能做的重排序优化。
            
            而对于处理器而言：
                
                内存屏障将会导致缓存的刷新操作。
            
            
            比如，对于volatile：
                
                编译器将在volatile字段的读写操作前后各插入一些内存屏障。
        
        
        
            
             
    -- Java 内存模型 规范了 JVM 如何提供 按需禁用缓存 和 编译优化 的方法
        
            Happens-Before 约束了编译器的优化行为，虽允许编译器优化，但是要求编译器优化后一定遵守Happens-Before 规则。
        
        
            这是说一点我自己的理解：
            
                既然 JVM 需要遵循 Java内存模型 的 Happens-Before 规则！！！
                
                那么我大致推导一下：
             
                    假如现在只有A、B两个操作，那么 JVM 可能只需遵守 Happens-Before 规则1、2                  ---> 此时称为 编译优化1
                     
                    而假如现在有A、B、C三个操作，那么 JVM 可能就需遵守 Happens-Before 规则1、2、3、4          ---> 此时称为 编译优化2
                     
                    那么，这里的 编译优化1 就可能 == 编译优化2，也可能 != 编译优化2  ！！！
                     
                    这样，我觉得就全部都通了！！！    
                 
        
```


#### 1.3 xx

```
    
    
    
```

   