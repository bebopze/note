## 1. 并发理论基础


#### 1.1 可见性、原子性和有序性问题：并发编程Bug的源头

```

    并发编程bug的源头：
    
        缓存      导致的 可见性问题
        
        线程切换   带来的 原子性问题
        
        编译优化   带来的 有序性问题
        
        
    
    
    并发程序幕后的故事：
    
        这些年，我们的 CPU、内存、I/O 设备都在不断迭代，不断朝着更快的⽅向努⼒。
        
        但是，在这个快速发展的过程中，
        
        有⼀个核⼼⽭盾⼀直存在：
        
            就是 这三者 的 速度差异！！！
            
            
            CPU 和内存的速度差异可以形象地描述为：
            
                CPU 是天上⼀天，内存是地上⼀年（假设 CPU 执⾏⼀条普通指令需要⼀天，那么CPU 读写内存得等待⼀年的时间）。
                
                
            内存和 I/O 设备的速度差异就更⼤了：
            
                内存是天上⼀天，I/O设备是地上⼗年。
        
        
        程序⾥⼤部分语句都要访问内存，有些还要访问 I/O：
        
            根据⽊桶理论（⼀只⽔桶能装多少⽔取决于它最短的那块⽊板），
        
            程序整体的性能取决于最慢的操作——读写	I/O 设备，
        
            也就是说 单⽅⾯提⾼ CPU 性能 是⽆效的。
        
        
        为了合理利⽤ CPU 的⾼性能，平衡这三者的速度差异：
        
            计算机体系机构、操作系统、编译程序 都做出了贡献，主要体现为：
        
                1. CPU 增加了缓存，以均衡与内存的速度差异；
                2. 操作系统增加了进程、线程，以分时复⽤	CPU，进⽽均衡	CPU 与 I/O 设备的速度差异；
                3. 编译程序优化指令执⾏次序，使得缓存能够得到更加合理地利⽤。   
        
        
    
    可⻅性：
        
        ⼀个线程对共享变量的修改，另外⼀个线程能够⽴刻看到，我们称为可⻅性。
        
        
        多核时代：
            
            每颗 CPU 都有⾃⼰的缓存，这时 CPU缓存 与 内存 的 数据⼀致性 就没那么容易解决了，
            
            当 多个线程 在 不同的CPU上 执⾏时，这些线程 操作的是 不同的 CPU缓存。
            
            
            
            ⽐如，线程A 操作的是 CPU-1 上的缓存，⽽线程 B 操作的是 CPU-2 上的缓存，
            
            很明显：
            
                这个时候线程	A 对变量V 的操作对于线程 B ⽽⾔就不具备可⻅性了。
                
                这个就属于硬件程序员给软件程序员挖的“坑”。    
                
                
    线程切换带来的原子性问题：
        
        多进程：
        
            由于 IO 太慢，早期的操作系统 就发明了 多进程，
            
            即便在单核的 CPU 上我们也可以⼀边听着歌，⼀边写 Bug，这个就是多进程的功劳。
         
           
        时间⽚：
            
            操作系统允许某个进程执⾏⼀⼩段时间，例如	50 毫秒，
            
            过了	50 毫秒操作系统就会重新选择⼀个进程来执⾏（我们称为“任务切换”），
            
            这个 50 毫秒称为“时间⽚”。    
    
        
        
        
        多进程分时复⽤：
            
            
            提高 CPU 的使⽤率：
            
                在⼀个时间⽚内，如果⼀个进程进⾏⼀个	IO 操作，
                
                例如读个⽂件，这个时候该进程可以把⾃⼰标记为“休眠状态”并出让 CPU 的使⽤权，
                
                待⽂件读进内存，操作系统会把这个休眠的进程唤醒，唤醒后的进程就有机会重新获得 CPU 的使⽤权了。
                
                
                这⾥的进程 在 等待IO 时 之所以会释放 CPU 使⽤权，是为了让 CPU 在这段等待时间⾥可以做别的事情，
                
                这样⼀来 CPU 的使⽤率就上来了；
            
            
            提高 IO 的使⽤率：
             
                此外，如果这时有另外⼀个进程也读⽂件，读⽂件的操作就会排队，
                
                磁盘驱动在完成⼀个进程的读操作后，发现有排队的任务，就会⽴即启动下⼀个读操作，
                
                这样 IO 的使⽤率也上来了。
            
            
            是不是很简单的逻辑？
            
                但是，虽然看似简单，⽀持多进程分时复⽤在操作系统的发展史上却具有⾥程碑意义，
                
                Unix 就是因为解决了这个问题⽽名噪天下的。
        
        
        
        早期的操作系统 基于 进程 来调度 CPU：
        
            不同进程 间是 不共享内存 空间的：
            
                所以 进程 要做 任务切换 就要 切换内存 映射地址，
            
            ⽽ ⼀个进程 创建的 所有线程：
            
                都是共享⼀个内存空间的，
            
                所以线程做任务切换成本就很低了。
            
            
        现代的操作系统 都基于 更轻量的 线程 来调度：
        
            现在我们提到的“任务切换”：
                
                都是指 “线程切换”
                
                
        
                
    Java 并发程序：        
        
        Java 并发程序都是基于多线程的，⾃然也会涉及到任务切换，
        
        也许你想不到，任务切换竟然也是并、发编程⾥诡异 Bug 的源头之⼀。
        
        
        任务切换的时机⼤多数是在时间⽚结束的时候
        
        
        
        ⾼级语⾔ ⾥ ⼀条语句 往往需要 多条 CPU 指令完成：
         
            我们现在基本都使⽤⾼级语⾔编程，⾼级语⾔⾥ ⼀条语句 往往需要 多条 CPU 指令完成，
            
            
            例如 count += 1，⾄少需要三条 CPU 指令：
            
                指令 1：⾸先，需要把变量 count 从内存加载到	CPU 的寄存器；
                指令 2：之后，在寄存器中执⾏ +1 操作；
                指令 3：最后，将结果写⼊内存（缓存机制导致可能写⼊的是	CPU 缓存⽽不是内存）。   
                
        
        
```
