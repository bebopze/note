## 1. 并发理论基础


#### 1.1 可见性、原子性和有序性问题：并发编程Bug的源头

```

    并发编程bug的源头：
    
        缓存      导致的 可见性问题
        
        线程切换   带来的 原子性问题
        
        编译优化   带来的 有序性问题
        
        
    
    
    并发程序幕后的故事：
    
        这些年，我们的 CPU、内存、I/O 设备都在不断迭代，不断朝着更快的⽅向努⼒。
        
        但是，在这个快速发展的过程中，
        
        有⼀个核⼼⽭盾⼀直存在：
        
            就是 这三者 的 速度差异！！！
            
            
            CPU 和内存的速度差异可以形象地描述为：
            
                CPU 是天上⼀天，内存是地上⼀年（假设 CPU 执⾏⼀条普通指令需要⼀天，那么CPU 读写内存得等待⼀年的时间）。
                
                
            内存和 I/O 设备的速度差异就更⼤了：
            
                内存是天上⼀天，I/O设备是地上⼗年。
        
        
        程序⾥⼤部分语句都要访问内存，有些还要访问 I/O：
        
            根据⽊桶理论（⼀只⽔桶能装多少⽔取决于它最短的那块⽊板），
        
            程序整体的性能取决于最慢的操作——读写	I/O 设备，
        
            也就是说 单⽅⾯提⾼ CPU 性能 是⽆效的。
        
        
        为了合理利⽤ CPU 的⾼性能，平衡这三者的速度差异：
        
            计算机体系机构、操作系统、编译程序 都做出了贡献，主要体现为：
        
                1. CPU 增加了缓存，以均衡与内存的速度差异；
                2. 操作系统增加了进程、线程，以分时复⽤	CPU，进⽽均衡	CPU 与 I/O 设备的速度差异；
                3. 编译程序优化指令执⾏次序，使得缓存能够得到更加合理地利⽤。   
        
        
    
    可⻅性：
        
        ⼀个线程对共享变量的修改，另外⼀个线程能够⽴刻看到，我们称为可⻅性。
        
        
        多核时代：
            
            每颗 CPU 都有⾃⼰的缓存，这时 CPU缓存 与 内存 的 数据⼀致性 就没那么容易解决了，
            
            当 多个线程 在 不同的CPU上 执⾏时，这些线程 操作的是 不同的 CPU缓存。
            
            
            
            ⽐如，线程A 操作的是 CPU-1 上的缓存，⽽线程 B 操作的是 CPU-2 上的缓存，
            
            很明显：
            
                这个时候线程	A 对变量V 的操作对于线程 B ⽽⾔就不具备可⻅性了。
                
                这个就属于硬件程序员给软件程序员挖的“坑”。    
                
                
    线程切换带来的原子性问题：
        
        多进程：
        
            由于 IO 太慢，早期的操作系统 就发明了 多进程，
            
            即便在单核的 CPU 上我们也可以⼀边听着歌，⼀边写 Bug，这个就是多进程的功劳。
         
           
        时间⽚：
            
            操作系统允许某个进程执⾏⼀⼩段时间，例如	50 毫秒，
            
            过了	50 毫秒操作系统就会重新选择⼀个进程来执⾏（我们称为“任务切换”），
            
            这个 50 毫秒称为“时间⽚”。    
    
        
        
        
        多进程分时复⽤：
            
            
            提高 CPU 的使⽤率：
            
                在⼀个时间⽚内，如果⼀个进程进⾏⼀个	IO 操作，
                
                例如读个⽂件，这个时候该进程可以把⾃⼰标记为“休眠状态”并出让 CPU 的使⽤权，
                
                待⽂件读进内存，操作系统会把这个休眠的进程唤醒，唤醒后的进程就有机会重新获得 CPU 的使⽤权了。
                
                
                这⾥的进程 在 等待IO 时 之所以会释放 CPU 使⽤权，是为了让 CPU 在这段等待时间⾥可以做别的事情，
                
                这样⼀来 CPU 的使⽤率就上来了；
            
            
            提高 IO 的使⽤率：
             
                此外，如果这时有另外⼀个进程也读⽂件，读⽂件的操作就会排队，
                
                磁盘驱动在完成⼀个进程的读操作后，发现有排队的任务，就会⽴即启动下⼀个读操作，
                
                这样 IO 的使⽤率也上来了。
            
            
            是不是很简单的逻辑？
            
                但是，虽然看似简单，⽀持多进程分时复⽤在操作系统的发展史上却具有⾥程碑意义，
                
                Unix 就是因为解决了这个问题⽽名噪天下的。
        
        
        
        早期的操作系统 基于 进程 来调度 CPU：
        
            不同进程 间是 不共享内存 空间的：
            
                所以 进程 要做 任务切换 就要 切换内存 映射地址，
            
            ⽽ ⼀个进程 创建的 所有线程：
            
                都是共享⼀个内存空间的，
            
                所以线程做任务切换成本就很低了。
            
            
        现代的操作系统 都基于 更轻量的 线程 来调度：
        
            现在我们提到的“任务切换”：
                
                都是指 “线程切换”
                
                
        
                
    Java 并发程序：        
        
        Java 并发程序 都是基于 多线程 的，⾃然也会涉及到 任务切换，
        
        也许你想不到，任务切换 竟然也是并发编程⾥诡异 Bug 的源头之⼀。
        
        
        任务切换 的时机 ⼤多数是在 时间⽚结束 的时候
        
        
        
        ⾼级语⾔ ⾥ ⼀条语句 往往需要 多条 CPU 指令完成：
         
            我们现在基本都使⽤ ⾼级语⾔ 编程，⾼级语⾔ ⾥ ⼀条语句 往往需要 多条 CPU 指令完成.
            
            
            例如 count += 1，⾄少需要三条 CPU 指令：
            
                指令 1：⾸先，需要把变量 count 从内存加载到	CPU 的寄存器；
                指令 2：之后，在寄存器中执⾏ +1 操作；
                指令 3：最后，将结果写⼊内存（缓存机制导致可能写⼊的是	CPU 缓存⽽不是内存）。
                
            
        
        
        操作系统做任务切换，可以发⽣在 任何⼀条CPU 指令执⾏完：
        
            是的，是 CPU 指令，⽽不是 ⾼级语⾔ ⾥的 ⼀条语句。
            
            对于上⾯的三条指令来说，
            
            我们假设 count=0，如果线程	A 在指令 1 执⾏完后做线程切换，线程 A 和线程 B 按照下图的序列执⾏，
            
            那么我们会发现两个线程都执⾏了 count+=1 的操作，但是得到的结果不是我们期望的 2，⽽是 1。
        
        
        直觉-潜意识：
        
            我们潜意识⾥⾯觉得 count+=1 这个操作是⼀个不可分割的整体：
        
                就像⼀个原⼦⼀样，线程的切换可以发⽣在 count+=1 之前，也可以发⽣在	count+=1 之后，
            
                但就是不会发⽣在中间。
            
            
            我们把⼀个或者多个操作 在 CPU执⾏的过程中 不被中断 的特性称为 原⼦性：
            
                CPU 能保证的原⼦操作是 CPU指令级别 的，⽽不是 ⾼级语⾔ 的操作符，
            
                这是违背我们直觉的地⽅。
            
                因此，很多时候 我们需要在 ⾼级语⾔层⾯ 保证操作的 原⼦性。
                
    
    
    
    编译优化带来的有序性问题：
    
        那并发编程⾥还有没有其他有违直觉容易导致诡异 Bug 的技术呢？
        
            有的，就是有序性。
            
            顾名思义，有序性指的是 程序按照代码的先后顺序执⾏。
            
            编译器为了 优化性能，有时候 会改变 程序中 语句 的 先后顺序，
            
            
            例如程序中：
            
                “a=6; b=7;”  编译器优化后可能变成“b=7; a=6;”，
            
            
            在这个例⼦中，编译器调整了语句的顺序，但是不影响程序的最终结果。
            
            不过有时候编译器及解释器的优化可能导致意想不到的 Bug。
        
        
        
        在 Java	领域⼀个经典的案例就是 利⽤双重检查 创建单例对象：
            
            这看上去⼀切都很完美，⽆懈可击，
            
            但实际上这个 getInstance() ⽅法并不完美。问题出在哪⾥呢？
            
            
                出在 new 操作上，我们以为的 new 操作应该是：
                    
                    1. 分配⼀块 内存M；
                    2. 在 内存M 上初始化 Singleton 对象；
                    3. 然后 M 的地址赋值给 instance 变量。
                    
                    
                但是实际上优化后的执⾏路径却是这样的：
                                
                    1. 分配⼀块 内存M；
                    2. 将 M 的地址赋值给 instance 变量；
                    3. 最后在 内存M 上初始化 Singleton	对象。
                    
                    
             
             
            优化后会导致什么问题呢？
            
                我们假设 线程A 先执⾏ getInstance() ⽅法，
                
                当执⾏完 指令2 时恰好发⽣了 线程切换，切换到了 线程B 上；
                
                如果此时 线程B 也执⾏ getInstance() ⽅法，
                
                那么 线程B 在执⾏第⼀个判断时会发现 instance != null ，所以直接返回 instance，
                
                ⽽此时的	instance 是没有初始化过的，如果我们这个时候访问 instance 的成员变量 就可能触发 空指针异常。     
                
                
                
            
            
            
                
            
    
    
    
    总结：
    
        要写好并发程序，⾸先要知道并发程序的问题在哪⾥：
        
            只有确定了“靶⼦”，才有可能把问题解决，毕竟所有的解决⽅案都是针对问题的。
        
        并发程序经常出现的诡异问题看上去⾮常⽆厘头，但是深究的话：
        
            ⽆外乎就是 直觉 欺骗了 我们
        
        只要我们能够 深刻理解：
         
            可⻅性、原⼦性、有序性 在并发场景下的原理，很多并发 Bug 都是可以理解、可以诊断的。
        
        在介绍可⻅性、原⼦性、有序性的时候，特意提到：
        
            缓存导致的可⻅性问题，线程切换带来的原⼦性问题，编译优化带来的有序性问题，
            
            其实 缓存、线程、编译优化 的⽬的 和 我们写并发程序 的⽬的 是相同的，都是提⾼程序性能。
        
        但是技术在解决⼀个问题的同时，必然会带来另外⼀个问题：
        
            所以在采⽤⼀项技术的同时，⼀定要清楚它带来的问题是什么，以及如何规避。
    
    
    
    思考：
        
        Q： 常听⼈说，在 32 位的机器上对 long 型变量进⾏加减操作存在并发隐患，到底是不是这样呢？
        
        A： long类型64位，所以在32位的机器上，对long类型的数据操作通常需要多条指令组合出来，
        
            无法保证原子性，所以并发的时候会出问题🌝🌝🌝
            
        
        Q： 文章中讲的 优化指令 的 执行次序 使得 缓存 能够 更加合理的利用 是什么意思？
        
        A： 比如第1行：a=8
            第1000行：a=a*2;
            这个时候，把他们放到一起执行，是不是就能更好的利用缓存了？
        
        
        
        
        ------可见性问题------
        对于可见性那个例子我们先看下定义:
        可见性:一个线程对共享变量的修改，另外一个线程能够立刻看到
         
        并发问题往往都是综合证，这里即使是单核CPU，只要出现线程切换就会有原子性问题。但老师的目的是为了让大家明白什么是可见性
        或许我们可以把线程对变量的读可写都看作时原子操作，也就是cpu对变量的操作中间状态不可见，这样就能更加理解什么是可见性了。
         
        ------CPU缓存刷新到内存的时机------
        cpu将缓存写入内存的时机是不确定的。除非你调用cpu相关指令强刷
         
        ------双重锁问题------
        如果A线程与B线程如果同时进入第一个分支，那么这个程序就没有问题
         
        如果A线程先获取锁并出现指令重排序时，B线程未进入第一个分支，那么就可能出现空指针问题，这里说可能出现问题是因为当把内存地址赋值给共享变量后，CPU将数据写回缓存的时机是随机的
         
        ------ synchronized------
        线程在synchronized块中，发生线程切换，锁是不会释放的
         
        ------指令优化------
        除了编译优化,有一部分可以通过看汇编代码来看，但是CPU和解释器在运行期也会做一部分优化，所以很多时候都是看不到的，也很难重现。
         
        ------JMM模型和物理内存、缓存等关系------
        内存、cpu缓存是物理存在，jvm内存是软件存在的。
        关于线程的工作内存和寄存器、cpu缓存的关系 大家可以参考这篇文章
        https://blog.csdn.net/u013851082/article/details/70314778/
         
        ------IO操作------
        io操作不占用cpu，读文件，是设备驱动干的事，cpu只管发命令。发完命令，就可以干别的事情了。
         
         
        ------寄存器切换------ 
        寄存器是共用的，A线程切换到B线程的时候，寄存器会把操作A的相关内容会保存到内存里，切换回来的时候，会从内存把内容加载到寄存器。可以理解为每个线程有自己的寄存器    
        
        
        
        
                        
```

