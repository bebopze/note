##### 3、互斥
 
 ```
 所谓互斥，指的是同一时刻，只允许一个线程访问共享变量。
 
 并发程序里还有一部分是关于正确性的，用专业术语叫“线程安全”。
 而导致不确定的主要源头是可见性问题、有序性问题和原子性问题，
 为了解决这三个问题，Java 语言引入了内存模型，
 内存模型提提供了一系列的规则，利用这些规则，我们可以避免可见性问题、有序性问题，
 但是还不足以完全解决线程安全问题。  --> 原子性问题！！！  解决线程安全问题的核心方案还是互斥。---> 锁🔐
 ```

#####   原子性
 ```
 我们潜意识里面觉得 
 count+=1 这个操作是一个不可分割的整体，就像一个原子一样，线程的切换
 可以发生在 count+=1 之前，也可以发生在 count+=1 之后，但就是不会发生在中间。
 我们把一个或者多个操作在 CPU 执行的过程中不被中断的特性称为原子性。
 CPU 能保证的原子操作是 CPU 指令级别的，而不是高级语言的操作符，这是违背我们直觉的地方。
 因此，很多时候我们需要在高级语言层面保证操作的原子性。
 


 Java 并发程序都是基于多线程的，自然也会涉及到任务切换，也许你想不到，任务切换竟然也是并
 发编程里诡异 Bug 的源头之一。任务切换的时机大多数是在时间片结束的时候，我们现在基本都使
 用高级语言编程，高级语言里一条语句往往需要多条 CPU 指令完成，例如上面代码中的count +=1，至少需要三条 CPU 指令。
 
 
     指令 1：首先，需要把变量 count 从内存加载到 CPU 的寄存器；
     指令 2：之后，在寄存器中执行 +1 操作；
     指令 3：最后，将结果写入内存（缓存机制导致可能写入的是 CPU 缓存而不是内存）。
 
 操作系统做任务切换，可以发生在任何一条CPU 指令执行完，是的，是 CPU指令，而不是高级语言里的一条语句。
 
 
 
 要写好并发程序，首先要知道并发程序的问题在哪里，只有确定了“靶子”，才有可能把问题解决，
 毕竟所有的解决方案都是针对问题的。并发程序经常出现的诡异问题看上去非常无厘头，但是深究
 的话，无外乎就是直觉欺骗了我们，只要我们能够深刻理解可见性、原子性、有序性在并发场景下
 的原理，很多并发 Bug 都是可以理解、可以诊断的。
 ```


##### 导致并发bug的原因

```
导致可见性的原因是 缓存
导致有序性的原因是 编译优化
导致原子性的原因是 CPU指令级别的任务切换

```

##### Java 内存模型

```

合理的方案应该是 按需禁用 缓存以及编译优化！      ==> 重点：按需！！！

那么，如何做到“按需禁用”呢？对于并发程序，何时禁用缓存以及编译优化只有程序员知道，
那所谓“按需禁用”其实就是指按照程序员的要求来禁用。
所以，为了解决可见性和有序性问题，只需要提供给程序员按需禁用缓存和编译优化的方法即可。---> JVM内存模型


Java 内存模型是个很复杂的规范，可以从不同的视角来解读，站在我们这些程序员的视角，本质上
可以理解为，Java 内存模型规范了 JVM 如何提供按需禁用缓存和编译优化的方法。
具体来说，这些方法包括 volatile、synchronized 和 final 三个关键字，
以及六项 Happens-Before 规则。

```


###### Happens-Before 规则
      
```


Happens-Before 并不是说前面一个操作发生在后续操作的前面，
它真正要表达的是：前面一个操作的结果对后续操作是可见的。


-- Java 内存模型规范了 JVM 如何提供按需禁用缓存和编译优化的方法。


这是说一点我自己的理解：既然 JVM 需要遵循 JVM内存模型 的 Happens-Before 规则！！！
 
 那么我大致推导一下：
 
 假如现在只有A、B两个操作，那么 JVM 可能只需遵守 Happens-Before 规则1、2                  ---> 此时称为 编译优化1
 
 而假如现在有A、B、C三个操作，那么 JVM 可能就需遵守 Happens-Before 规则1、2、3、4          ---> 此时称为 编译优化2
 
 那么，这里的 编译优化1 就可能 == 编译优化2，也可能 !=编译优化2  ！！！
 
 这样，我觉得就全部都通了！！！
 
```



###### 原子性

``` 

“同一时刻只有一个线程执行” 这个条件非常重要，我们称之为互斥。

如果我们能够保证对共享变量的修改是互斥的，那么，无论是单核 CPU 还是多核 CPU，就都能保证原子性了。


解决原子性问题，是要保证中间状态对外不见。


```


####### 锁

``` 

锁和锁要保护的资源是有对应关系的，
比如你用你家的锁保护你家的东西，我用我家的锁保护我家的东西。
在并发编程世界里，锁和资源也应该有这个关系。

千万不要出现，锁自家门来保护他家资产的事情！！！


受保护资源和锁之间合理的关联关系应该是 N:1 的关系
也就是说可以用一把锁来保护多个资源，但是不能用多把锁来保护一个资源


synchronized：
当修饰静态方法的时候，锁定的是当前类的 Class 对象，
当修饰非静态方法的时候，锁定的是当前实例对象 this。


加锁本质就是在锁对象的对象头中写入当前线程id

对 synchronized的理解，它并不能改变CPU时间片切换的特点，只是当其他线程要访问这个资源时，发现锁还未释放，所以只能在外面等待


可变对象不能作为锁！！！

```

######## 细粒度锁
```
用一把锁有个问题，就是性能太差，会导致取款、查看余额、修改密码、查看密码这四个操作都是串行的。
而我们用两把锁，取款和修改密码是可以并行的。
用不同的锁对受保护资源进行精细化管理，能够提升性能。
这种锁还有个名字，叫细粒度锁。


用细粒度锁来锁定多个资源时，要注意死锁的问题！！！


class Account {
  private int balance;
  // 转账
  synchronized void transfer(Account target, int amt){
    if (this.balance > amt) {
      this.balance -= amt;
      target.balance += amt;
    }
  } 
}

在这段代码中，临界区内有两个资源，分别是转出账户的余额 this.balance 和转入账户的余额target.balance，
并且用的是一把锁 this，符合我们前面提到的，多个资源可以用一把锁来保护，
这看上去完全正确呀。真的是这样吗？可惜，这个方案仅仅是看似正确，为什么呢？

问题就出在 this 这把锁上，this 这把锁可以保护自己的余额 this.balance，却保护不了别人的余额target.balance，
就像你不能用自家的锁来保护别人家的资产，也不能用自己的票来保护别人的座位一样。

```

######## 等待 - 通知机制
```

Java 语言是如何支持等待 - 通知机制的。

一个完整的等待 - 通知机制：
线程首先获取互斥锁，当线程要求的条件不满足时，释放互斥锁，进入等待状态；
当要求的条件满足时，通知等待的线程，重新获取互斥锁。


用 synchronized 实现等待 - 通知机制：

在 Java 语言里，等待 - 通知机制可以有多种实现方式，
比如 Java 语言内置的 synchronized 配合wait()、notify()、notifyAll() 这三个方法就能轻松实现。


wait()  -->  进入等待  并且会释放锁🔐！！！

在并发程序中，当一个线程进入临界区后，由于某些条件不满足，需要进入等待状态。

当调用 wait() 方法后，当前线程就会被阻塞，并且进入到等待队列中，这个等待队列也是互斥锁的等待队列。

线程在进入等待队列的同时，会释放持有的互斥锁，线程释放锁后，其他线程就有机会获得锁，并进入临界区了。


notify() / notifyAll()  -->  唤醒等待中的线程  并重新去尝试获取锁！

当条件满足时调用 notify()，会通知等待队列（互斥锁的等待队列）中的线程，告诉它条件曾经满足过。


notify() 是会随机地通知等待队列中的一个线程，而 notifyAll() 会通知等待队列中的所有线程。


实际上使用 notify() 也很有风险，它的风险在于可能导致某些线程永远不会被通知到。    类似 --> 死锁！！！   相互交错通知，相互永久等待！！！
除非经过深思熟虑，否则尽量使用 notifyAll()。

                                        
   wait与sleep区别在于：
       1. wait会释放所有锁而sleep不会释放锁资源.
       2. wait只能在同步方法和同步块中使用，而sleep任何地方都可以.
       3. wait无需捕捉异常，而sleep需要.
       
       4. sleep是Thread的方法，而wait是Object类的方法
       5. sleep方法调用的时候必须指定时间
       
   两者相同点：都会让渡CPU执行时间，等待再次调度！                                     
                                        
                                                                                       
```


#### 并发编程中我们需要注意的问题：安全性问题、活跃性问题、性能问题。

```

并发编程中我们需要注意的问题有很多，很庆幸前人已经帮我们总结过了，

主要有三个方面，分别是：安全性问题、活跃性问题和性能问题。


并发 Bug 的三个主要源头：

    原子性问题、可见性问题和有序性问题。

    也就是说，理论上线程安全的程序，就要避免出现原子性问题、可见性问题和有序性问题。
    
    
    
那是不是所有的代码都需要认真分析一遍是否存在这三个问题呢？
    
    当然不是，其实只有一种情况需要：存在共享数据并且该数据会发生变化，
    
    通俗地讲就是有多个线程会同时读写同一数据。
    
    
那如果能够做到不共享数据或者数据状态不发生变化，不就能够保证线程的安全性了嘛。
有不少技术方案都是基于这个理论的，例如线程本地存储（Thread Local Storage，TLS）、不变模式等等。


竞态条件（Race Condition）。所谓竞态条件，指的的是程序的执行结果依赖线程执行的顺序。

    例如上面的例子，如果两个线程完全同时执行，那么结果是 1；如果两个线程是前后执行，那么结果就是 2。
    在并发环境里，线程的执行顺序是不确定的，如果程序存在竞态条件问题，那就意味着程序执行的结果是不确定的，
    而执行结果不确定这可是个大 Bug。



"活锁" -->  解决办法：等待一个随机时间！！！  简单有效



"饥饿" --> 解决方案很简单，有三种方案：一是保证资源充足，二是公平地分配资源，三就是避免持有锁的线程长时间执行。

    所谓“饥饿”指的是线程因无法访问所需资源而无法执行下去的情况。
    “不患寡，而患不均”，
    如果线程优先级“不均”，在 CPU 繁忙的情况下，优先级低的线程得到执行的机会很小，就可能发生线程“饥饿”；
    持有锁的线程，如果执行的时间过长，也可能导致“饥饿”问题。
    
    
    方案二的适用场景相对来说更多一些。  -->  公平锁🔐
    
    
    
    
    第一，既然使用锁会带来性能问题，那最好的方案自然就是使用无锁的算法和数据结构了。
        在这方面有很多相关的技术，例如线程本地存储 (Thread Local Storage, TLS)、写入时复制 (Copy-onwrite)、乐观锁等；
        Java 并发包里面的原子类也是一种无锁的数据结构；
        Disruptor 则是一个无锁的 内存队列，性能都非常好
    
    第二，减少锁持有的时间。
        互斥锁本质上是将并行的程序串行化，所以要增加并行度，一定要减少持有锁的时间。
        这个方案具体的实现技术也有很多，例如使用细粒度的锁，一个典型的例子就是Java 并发包里的 ConcurrentHashMap，它使用了所谓分段锁的技术；
        还可以使用读写锁，也就是读是无锁的，只有写的时候才会互斥。
        
        
性能方面的度量指标有很多，我觉得有三个指标非常重要，就是：吞吐量、延迟和并发量。

        1. 吞吐量：指的是单位时间内能处理的请求数量。吞吐量越高，说明性能越好。
        2. 延迟：指的是从发出请求到收到响应的时间。延迟越小，说明性能越好。
        3. 并发量：指的是能同时处理的请求数量，一般来说随着并发量的增加、延迟也会增加。
           所以延迟这个指标，一般都会是基于并发量来说的。例如并发量是 1000 的时候，延迟是 50 毫秒。
    
```




###### 安全性问题

###### 活跃性问题

###### 性能问题




##### 管程

```

所谓管程，指的是管理共享变量以及对共享变量的操作过程，让他们支持并发。


什么是管程？
    不知道你是否曾思考过这个问题：
    为什么 Java 在 1.5 之前仅仅提供了 synchronized 关键字及wait()、notify()、notifyAll() 这三个看似从天而降的方法？

    在刚接触 Java 的时候，我以为它会提供信号量这种编程原语，因为操作系统原理课程告诉我，用信号量能解决所有并发问题，结果我发现不是。
    后来我找到了原因：Java 采用的是管程技术，synchronized 关键字及 wait()、notify()、notifyAll() 这三个方法都是管程的组成部分。
    而管程和信号量是等价的，所谓等价指的是用管程能够实现信号量，也能用信号量实现管程。
    但是管程更容易使用，所以 Java 选择了管程。
    
    管程，对应的英文是 Monitor，很多 Java 领域的同学都喜欢将其翻译成“监视器”，这是直译。
    操作系统领域一般都翻译成“管程”，这个是意译，而我自己也更倾向于使用“管程”。
    
    所谓管程，指的是管理共享变量以及对共享变量的操作过程，让他们支持并发。
    翻译为 Java 领域的语言，就是管理类的成员变量和成员方法，让这个类是线程安全的。那管程是怎么管的呢？
    
    
    
Java 内置的管程方案（synchronized）使用简单，
    synchronized 关键字修饰的代码块，在编译期会自动生成相关加锁和解锁的代码，但是仅支持一个条件变量；
    而 Java SDK 并发包实现的管程支持多个条件变量，不过并发包里的锁，需要开发人员自己进行加锁和解锁操作。

并发编程里两大核心问题——互斥和同步，都可以由管程来帮你解决。
    学好管程，理论上所有的并发问题你都可以解决，并且很多并发工具类底层都是管程实现的，
    所以学好管程，就是相当于掌握了一把并发编程的万能钥匙。

```

##### 通用的线程生命周期

```

通用的线程生命周期基本上可以用下图这个“五态模型”来描述。

这五态分别是：初始状态、可运行状态、运行状态、休眠状态和终止状态。


    在 Java 领域，实现并发程序的主要手段就是多线程。线程是操作系统里的一个概念，
    虽然各种不同的开发语言如 Java、C# 等都对其进行了封装，但是万变不离操作系统。
    Java 语言里的线程本质上就是操作系统的线程，它们是一一对应的。
    
    在操作系统层面，线程也有“生老病死”，专业的说法叫有生命周期。对于有生命周期的事物，
    要学好它，思路非常简单，只要能搞懂生命周期中各个节点的状态转换机制就可以了。


这“五态模型”的详细情况如下所示。
    1. 初始状态，指的是线程已经被创建，但是还不允许分配 CPU 执行。这个状态属于编程语言特有的，
    不过这里所谓的被创建，仅仅是在编程语言层面被创建，而在操作系统层面，真正的线程还没有创建。
    2. 可运行状态，指的是线程可以分配 CPU 执行。在这种状态下，真正的操作系统线程已经被成功
    创建了，所以可以分配 CPU 执行。
    3. 当有空闲的 CPU 时，操作系统会将其分配给一个处于可运行状态的线程，被分配到 CPU 的线程
    的状态就转换成了运行状态。
    4. 运行状态的线程如果调用一个阻塞的 API（例如以阻塞方式读文件）或者等待某个事件（例如条
    件变量），那么线程的状态就会转换到休眠状态，同时释放 CPU 使用权，休眠状态的线程永远
    没有机会获得 CPU 使用权。当等待的事件出现了，线程就会从休眠状态转换到可运行状态。
    5. 线程执行完或者出现异常就会进入终止状态，终止状态的线程不会切换到其他任何状态，进入终
    止状态也就意味着线程的生命周期结束了。

```

##### Java 中线程的生命周期

```

介绍完通用的线程生命周期模型，想必你已经对线程的“生老病死”有了一个大致的了解。
那接下来我们就来详细看看 Java 语言里的线程生命周期是什么样的。

    Java 语言中线程共有六种状态，分别是：
        1. NEW（初始化状态）
        2. RUNNABLE（可运行 / 运行状态）
        3. BLOCKED（阻塞状态）
        4. WAITING（无时限等待）
        5. TIMED_WAITING（有时限等待）
        6. TERMINATED（终止状态）
        
    这看上去挺复杂的，状态类型也比较多。
    但其实在操作系统层面，Java 线程中的 BLOCKED、WAITING、TIMED_WAITING 是一种状态，即前面我们提到的休眠状态。
    也就是说只要 Java 线程处于这三种状态之一，那么这个线程就永远没有 CPU 的使用权。
    
    
  stop() 和 interrupt() 方法的主要区别是什么呢？
  
      stop() 方法会真的杀死线程，不给线程喘息的机会，
      如果线程持有 ReentrantLock 锁，被 stop() 的 线程并不会自动调用 ReentrantLock 的 unlock() 去释放锁，
      那其他线程就再也没机会获得ReentrantLock 锁，
      这实在是太危险了。所以该方法就不建议使用了，
      类似的方法还有 suspend()和 resume() 方法，这两个方法同样也都不建议使用了，所以这里也就不多介绍了。
      
      而 interrupt() 方法就温柔多了，interrupt() 方法仅仅是通知线程，线程有机会执行一些后续操作，同时也可以无视这个通知。
      被 interrupt 的线程，是怎么收到通知的呢？一种是异常，另一种是主动检测。
      
      
          还有一种是主动检测，如果线程处于 RUNNABLE 状态，并且没有阻塞在某个 I/O 操作上，
          例如中断计算圆周率的线程 A，这时就得依赖线程 A 主动检测中断状态了。
          如果其他线程调用线程 A 的interrupt() 方法，那么线程 A 可以通过 isInterrupted() 方法，检测是不是自己被中断了。
          
          
          
          
          
          可能出现无限循环，线程在sleep期间被打断了，抛出一个InterruptedException异常，
          try catch捕捉此异常，应该重置一下中断标示，因为抛出异常后，中断标示会自动清除掉！
          
          Thread th = Thread.currentThread();
          while(true) {
            if(th.isInterrupted()) {
              break;
            }
            // 省略业务代码无数
            try {
              Thread.sleep(100);
            }catch (InterruptedException e)｛
               // try catch捕捉此异常，应该重置一下中断标示，因为抛出异常后，中断标示会自动清除掉！
              Thread.currentThread().interrupt();
              e.printStackTrace();
            }
          }
    
```


##### 创建多少线程才是合适的？

```

我们所谓提升性能，从度量的角度，主要是：降低延迟，提高吞吐量。

    一个方向是优化算法，                  -->  算法范畴
    另一个方向是将硬件的性能发挥到极致。    -->  并发编程领域       硬件：一个是 I/O，一个是 CPU
    
    
    简言之，在并发编程领域，提升性能本质上就是提升硬件的利用率，再具体点来说，就是提升 I/O 的利用率和 CPU 的利用率。
    
    


```